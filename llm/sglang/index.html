<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title id="head-title">index.html</title>
<style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
</head>
<body>
<h1 id="title">index.html</h1>
<p>Report generated on 02-May-2025 at 11:16:28 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
<div id="environment-header">
<h2>Environment</h2>
</div>
<table id="environment"></table>
<!-- TEMPLATES -->
<template id="template_environment_row">
<tr>
<td></td>
<td></td>
</tr>
</template>
<template id="template_results-table__body--empty">
<tbody class="results-table-row">
<tr id="not-found-message">
<td colspan="4">No results found. Check the filters.
</td></tr>
</tbody></template>
<template id="template_results-table__tbody">
<tbody class="results-table-row">
<tr class="collapsible">
</tr>
<tr class="extras-row">
<td class="extra" colspan="4">
<div class="extraHTML"></div>
<div class="media">
<div class="media-container">
<div class="media-container__nav--left">&lt;</div>
<div class="media-container__viewport">
<img src=""/>
<video controls="">
<source src="" type="video/mp4"/>
</video>
</div>
<div class="media-container__nav--right">&gt;</div>
</div>
<div class="media__name"></div>
<div class="media__counter"></div>
</div>
<div class="logwrapper">
<div class="logexpander"></div>
<div class="log"></div>
</div>
</td>
</tr>
</tbody>
</template>
<!-- END TEMPLATES -->
<div class="summary">
<div class="summary__data">
<h2>Summary</h2>
<div class="additional-summary prefix">
</div>
<p class="run-count">18 tests ran in 933 seconds</p>
<p class="filter">(Un)check the boxes to filter the results.</p>
<div class="summary__reload">
<div class="summary__reload__button hidden" onclick="location.reload()">
<div>There are still tests running. <br/>Reload this page to get the latest results!</div>
</div>
</div>
<div class="summary__spacer"></div>
<div class="controls">
<div class="filters">
<input checked="true" class="filter" data-test-result="failed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="failed">0 Failed,</span>
<input checked="true" class="filter" data-test-result="passed" name="filter_checkbox" type="checkbox"/>
<span class="passed">18 Passed,</span>
<input checked="true" class="filter" data-test-result="skipped" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="skipped">0 Skipped,</span>
<input checked="true" class="filter" data-test-result="xfailed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xfailed">0 Expected failures,</span>
<input checked="true" class="filter" data-test-result="xpassed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xpassed">0 Unexpected passes,</span>
<input checked="true" class="filter" data-test-result="error" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="error">0 Errors,</span>
<input checked="true" class="filter" data-test-result="rerun" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="rerun">0 Reruns</span>
</div>
<div class="collapse">
<button id="show_all_details">Show all details</button> / <button id="hide_all_details">Hide all details</button>
</div>
</div>
</div>
<div class="additional-summary summary">
</div>
<div class="additional-summary postfix">
</div>
</div>
<table id="results-table">
<thead id="results-table-head">
<tr>
<th class="sortable" data-column-type="result">Result</th>
<th class="sortable" data-column-type="testId">Test</th>
<th class="sortable" data-column-type="duration">Duration</th>
<th>Links</th>
</tr>
</thead>
</table>
</body>
<footer>
<div data-jsonblob='{"environment": {"Python": "3.11.12", "Platform": "Linux-5.15.0-131-generic-x86_64-with-glibc2.35", "Packages": {"pytest": "8.0.0", "pluggy": "1.5.0"}, "Plugins": {"timeout": "2.3.1", "asyncio": "0.23.8", "metadata": "3.1.1", "xdist": "3.5.0", "anyio": "4.9.0", "html": "4.1.1"}, "CI": "true"}, "tests": {"reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]", "duration": "00:06:58", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:06:58&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stderr setup -----------------------------\nINFO:integration_tests.llm.model_management:Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO:integration_tests.llm.model_management:Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO:integration_tests.llm.model_management:Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 4\nINFO:integration_tests.llm.model_management:Running export command: python -m sharktank.examples.export_paged_llm_v1 --use-attention-mask --block-seq-stride=16 --gguf-file=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/meta-llama-3.1-8b-instruct.f16.gguf --output-mlir=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir --output-config=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json --bs-prefill=4 --bs-decode=4\nINFO:integration_tests.llm.model_management:Export succeeded.\nINFO:integration_tests.llm.model_management:Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO:integration_tests.llm.model_management:Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO:integration_tests.llm.model_management:Running compiler command: iree-compile /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir -o /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb --iree-hal-target-device=hip --iree-hip-target=gfx942\nINFO:integration_tests.llm.model_management:Compilation succeeded\nINFO:integration_tests.llm.model_management:Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n[2025-05-02 11:12:19] Started server process [4299]\n[2025-05-02 11:12:19] Waiting for application startup.\n[2025-05-02 11:12:22] Application startup complete.\n[2025-05-02 11:12:22] Uvicorn running on http://0.0.0.0:32893 (Press CTRL+C to quit)\n[2025-05-02 11:12:22] 127.0.0.1:59308 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n------------------------------ Captured log setup ------------------------------\nINFO     integration_tests.llm.model_management:model_management.py:263 Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO     integration_tests.llm.model_management:model_management.py:385 Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO     integration_tests.llm.model_management:model_management.py:452 Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 4\nINFO     integration_tests.llm.model_management:model_management.py:480 Running export command: python -m sharktank.examples.export_paged_llm_v1 --use-attention-mask --block-seq-stride=16 --gguf-file=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/meta-llama-3.1-8b-instruct.f16.gguf --output-mlir=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir --output-config=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json --bs-prefill=4 --bs-decode=4\nINFO     integration_tests.llm.model_management:model_management.py:486 Export succeeded.\nINFO     integration_tests.llm.model_management:model_management.py:493 Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO     integration_tests.llm.model_management:model_management.py:499 Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO     integration_tests.llm.model_management:model_management.py:510 Running compiler command: iree-compile /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir -o /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb --iree-hal-target-device=hip --iree-hip-target=gfx942\nINFO     integration_tests.llm.model_management:model_management.py:515 Compilation succeeded\nINFO     integration_tests.llm.model_management:model_management.py:522 Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_none-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 10.9M/642M [00:00&amp;lt;00:05, 114MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 22.0M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258c         | 33.1M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 44.3M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u258a         | 55.4M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 66.5M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 77.6M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 88.7M/642M [00:00&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 99.8M/642M [00:00&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 111M/642M [00:01&amp;lt;00:04, 116MB/s] \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u2589        | 122M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 133M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 144M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258d       | 155M/642M [00:01&amp;lt;00:04, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  26%|\u2588\u2588\u258c       | 167M/642M [00:01&amp;lt;00:04, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 177M/642M [00:01&amp;lt;00:04, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  29%|\u2588\u2588\u2589       | 189M/642M [00:01&amp;lt;00:04, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588       | 200M/642M [00:01&amp;lt;00:04, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 211M/642M [00:01&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  35%|\u2588\u2588\u2588\u258d      | 222M/642M [00:02&amp;lt;00:03, 113MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258b      | 233M/642M [00:02&amp;lt;00:03, 114MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 244M/642M [00:02&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  40%|\u2588\u2588\u2588\u2589      | 256M/642M [00:02&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  42%|\u2588\u2588\u2588\u2588\u258f     | 267M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  43%|\u2588\u2588\u2588\u2588\u258e     | 278M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  45%|\u2588\u2588\u2588\u2588\u258c     | 289M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 300M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  48%|\u2588\u2588\u2588\u2588\u258a     | 311M/642M [00:02&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  50%|\u2588\u2588\u2588\u2588\u2588     | 322M/642M [00:02&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 333M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 345M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 356M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 367M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 378M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 389M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 400M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 411M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 422M/642M [00:03&amp;lt;00:01, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 434M/642M [00:03&amp;lt;00:01, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 445M/642M [00:04&amp;lt;00:01, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 456M/642M [00:04&amp;lt;00:01, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 467M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 478M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 489M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 500M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 511M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 523M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 534M/642M [00:04&amp;lt;00:00, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 545M/642M [00:04&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 556M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 567M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 578M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 589M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 600M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 612M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 623M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 634M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:05&amp;lt;00:00, 116MB/s]\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:12:36] 127.0.0.1:59688 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:12:38] 127.0.0.1:59690 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:38] 127.0.0.1:59704 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:40] 127.0.0.1:59714 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:40] 127.0.0.1:59728 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:40] 127.0.0.1:59730 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:40] 127.0.0.1:59734 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:40] 127.0.0.1:59740 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:21,  2.44s/it][2025-05-02 11:12:41] 127.0.0.1:59742 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.13s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:04,  1.49it/s][2025-05-02 11:12:41] 127.0.0.1:59758 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:41] 127.0.0.1:59760 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:04,  1.38it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:06&amp;lt;00:08,  1.62s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:07&amp;lt;00:05,  1.41s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:08&amp;lt;00:03,  1.12s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:10&amp;lt;00:02,  1.46s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:11&amp;lt;00:01,  1.39s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:15&amp;lt;00:00,  2.09s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:15&amp;lt;00:00,  1.54s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     7         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  15.39     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1383      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1986      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    161       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.45      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          89.85     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         129.02    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          218.87    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.35      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   7363.86   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7772.35   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          174.23    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        68.47     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           364.37    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.46     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        24.69     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           31.60     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           25.34     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.77     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.71     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 31.2504780292511 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 15.392542453482747\nINFO:sglang_benchmarks.utils:COMPLETED: 7\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1383\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1986\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 161\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4547656776750462\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 89.8487046035127\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 129.02351940894883\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 7363.862611220351\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7772.349051199853\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3469.6314116984718\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12845.442499667404\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 174.22920292509454\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 68.47157701849937\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 142.71137073830377\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 364.3677909485996\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.456785682598756\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 24.690571756318157\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.7092053115737977\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 31.60145208529204\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 25.338676865029733\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.76652180403471\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 18.50481792465355\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.71105779334903\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.3488319706975584\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 31.2504780292511 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 15.392542453482747\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 7\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1383\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1986\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 161\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4547656776750462\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 89.8487046035127\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 129.02351940894883\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 7363.862611220351\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7772.349051199853\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3469.6314116984718\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12845.442499667404\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 174.22920292509454\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 68.47157701849937\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 142.71137073830377\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 364.3677909485996\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.456785682598756\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 24.690571756318157\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.7092053115737977\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 31.60145208529204\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 25.338676865029733\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.76652180403471\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 18.50481792465355\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.71105779334903\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.3488319706975584\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]", "duration": "00:00:16", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:16&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_none-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:12:57] 127.0.0.1:55708 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:12:58] 127.0.0.1:55722 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:58] 127.0.0.1:55732 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:59] 127.0.0.1:55738 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:59] 127.0.0.1:55752 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:59] 127.0.0.1:55766 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:59] 127.0.0.1:55768 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:12:59] 127.0.0.1:55770 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.30s/it][2025-05-02 11:13:00] 127.0.0.1:55784 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:13:00] 127.0.0.1:55792 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:01&amp;lt;00:02,  2.35it/s][2025-05-02 11:13:00] 127.0.0.1:55800 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:01&amp;lt;00:02,  2.73it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:02&amp;lt;00:02,  2.28it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:05,  1.41s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:03,  1.04s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.11s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:10&amp;lt;00:01,  1.73s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.49s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.14s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.43     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    146       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          83.37     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         143.21    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          226.59    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.43      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6529.88   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6445.93   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          234.13    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        237.92    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           453.47    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.35     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.92     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.79     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.39     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.75     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 16.37271213531494 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.43058614525944\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 146\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5249074652648811\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 83.37280239957194\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 143.21225343976838\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6529.875141258041\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6445.931897033006\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2919.1751698371977\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10214.768619509414\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 234.12955241898695\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 237.92384518310428\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 156.67636265198922\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 453.46596646122634\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.35379566864102\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.921589245029892\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.1168020313306695\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.79162610444378\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.073416175952246\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.3886561319232\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.338805903178082\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.75479131191969\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.4275802088939153\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 16.37271213531494 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.43058614525944\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 146\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5249074652648811\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 83.37280239957194\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 143.21225343976838\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6529.875141258041\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6445.931897033006\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2919.1751698371977\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10214.768619509414\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 234.12955241898695\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 237.92384518310428\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 156.67636265198922\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 453.46596646122634\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.35379566864102\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.921589245029892\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.1168020313306695\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.79162610444378\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.073416175952246\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.3886561319232\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.338805903178082\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.75479131191969\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.4275802088939153\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]", "duration": "00:00:17", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:17&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_none-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:13:13] 127.0.0.1:46004 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:13:15] 127.0.0.1:46016 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:15] 127.0.0.1:46030 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:15] 127.0.0.1:46042 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:15] 127.0.0.1:46056 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:15] 127.0.0.1:46072 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:16] 127.0.0.1:46076 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:16] 127.0.0.1:46088 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:13:16] 127.0.0.1:46094 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:07,  1.21it/s][2025-05-02 11:13:16] 127.0.0.1:46108 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:13:16] 127.0.0.1:46120 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  2.86it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.02s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:05&amp;lt;00:02,  1.26it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.24s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:09&amp;lt;00:01,  1.49s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.50s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.14s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.40     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    136       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.53      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          83.61     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         143.61    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          227.22    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.42      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6504.69   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6407.54   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          260.38    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        332.74    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           436.16    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.80     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.32     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.88     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.30     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.70     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 16.579389333724976 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.398572909645736\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 136\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5263816837038136\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 83.60695742828906\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 143.6144693705238\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6504.694127167265\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6407.542718574405\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3120.6227852557254\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10737.13218867779\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 260.38132266451913\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 332.74243818596005\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 157.21097065246934\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 436.15816603414714\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.79596475244029\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.07469658534357\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 6.9935811498892555\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.320886649580906\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.88362633882952\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.304510205984116\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.965352087260754\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.699891708791256\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.423951846636613\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 16.579389333724976 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.398572909645736\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 136\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5263816837038136\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 83.60695742828906\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 143.6144693705238\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6504.694127167265\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6407.542718574405\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3120.6227852557254\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10737.13218867779\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 260.38132266451913\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 332.74243818596005\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 157.21097065246934\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 436.15816603414714\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.79596475244029\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.07469658534357\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 6.9935811498892555\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.320886649580906\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.88362633882952\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.304510205984116\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.965352087260754\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.699891708791256\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.423951846636613\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]", "duration": "00:00:27", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:27&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_none-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:13:40] 127.0.0.1:54526 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:13:41] 127.0.0.1:54538 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54546 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54560 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54570 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54578 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54582 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:13:41] 127.0.0.1:54592 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.21it/s][2025-05-02 11:13:41] 127.0.0.1:54596 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:13:41] 127.0.0.1:54612 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:13:42] 127.0.0.1:54624 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00&amp;lt;00:00, 10.21it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:04,  1.03s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:05&amp;lt;00:02,  1.07it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.26s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:07&amp;lt;00:00,  1.02it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.98s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.26s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  12.58     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    139       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.48      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          75.78     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         130.17    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          205.96    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.09      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6471.45   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6610.75   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          284.07    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        373.10    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           430.08    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          22.60     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        21.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           28.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.67     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.41     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.99     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 27.41649580001831 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 12.575434762053192\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 139\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.477120681195469\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 75.782668196547\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 130.17442585283047\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6471.453602425754\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6610.752030741423\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3443.2582394775077\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12048.577377619224\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 284.0719907544553\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 373.10267286375165\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 167.93452465599682\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 430.07736024446785\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 22.595878585009746\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 21.819285332668024\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.0365357943661033\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 28.68150278532828\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.673814643968623\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.40827537328005\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.596361117178317\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.98729167133569\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.087664351114248\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 27.41649580001831 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 12.575434762053192\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 139\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.477120681195469\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 75.782668196547\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 130.17442585283047\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6471.453602425754\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6610.752030741423\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3443.2582394775077\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12048.577377619224\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 284.0719907544553\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 373.10267286375165\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 167.93452465599682\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 430.07736024446785\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 22.595878585009746\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 21.819285332668024\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.0365357943661033\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 28.68150278532828\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.673814643968623\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.40827537328005\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.596361117178317\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.98729167133569\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.087664351114248\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]", "duration": "00:00:26", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:26&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_none-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:14:07] 127.0.0.1:46922 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:14:09] 127.0.0.1:46928 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46938 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46948 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46962 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46970 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46980 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:09] 127.0.0.1:46988 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:01,  6.32it/s][2025-05-02 11:14:09] 127.0.0.1:47000 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:14:09] 127.0.0.1:47012 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:14:09] 127.0.0.1:47022 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.30it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:04,  1.00s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:04,  1.41s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.15s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.08it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.39s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.07s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  10.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    131       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.56      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          88.70     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         152.36    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          241.05    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.71      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6636.46   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7600.10   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          285.52    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        390.44    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           419.97    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.28     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        25.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           37.20     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.28     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.87     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.64     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 25.643810510635376 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 10.744483910501003\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 131\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5584260770436787\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 88.6966752371043\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 152.3572480200837\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6636.46441573898\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7600.0971854664385\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2923.503933837203\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10464.819508884104\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 285.5229911704858\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 390.43609611690044\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 169.39266547320972\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 419.970476673916\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.278379026558422\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 25.255034524782136\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 6.66687195732916\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 37.20365997698525\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.275835268317778\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.87458113580942\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.518639142404473\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.63509251922368\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.705974789121088\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 25.643810510635376 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 10.744483910501003\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 131\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5584260770436787\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 88.6966752371043\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 152.3572480200837\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6636.46441573898\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7600.0971854664385\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2923.503933837203\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10464.819508884104\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 285.5229911704858\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 390.43609611690044\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 169.39266547320972\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 419.970476673916\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.278379026558422\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 25.255034524782136\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 6.66687195732916\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 37.20365997698525\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.275835268317778\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.87458113580942\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.518639142404473\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.63509251922368\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.705974789121088\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]", "duration": "00:00:21", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:21&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:32893&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_none-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:14:28] 127.0.0.1:35900 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:14:29] 127.0.0.1:35916 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35922 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35936 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35946 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35948 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35952 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:29] 127.0.0.1:35954 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:14:29] 127.0.0.1:35968 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:14:29] 127.0.0.1:35984 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:00&amp;lt;00:00, 29.80it/s][2025-05-02 11:14:29] 127.0.0.1:35996 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:03,  1.10it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:06&amp;lt;00:01,  1.07it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:09&amp;lt;00:01,  1.31s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.48s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.14s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.45     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    143       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          83.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         143.01    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          226.27    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.41      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6508.19   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6171.13   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          261.87    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        364.27    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           380.48    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.67     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        24.09     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.17     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.89     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.53     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.46     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 21.179033994674683 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.44640848878771\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5241818869104032\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 83.25755637093572\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 143.0142914787217\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6508.188129713138\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6171.13018874079\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3218.556783443756\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 11268.966712243855\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 261.8664442561567\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 364.26992574706674\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 155.59288348415572\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 380.4788470733911\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.667284334883647\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 24.094847140533332\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 6.634483551753946\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.16968238512373\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.892870034546878\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.52887512743473\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 13.894729577858865\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.45746721327304\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.4114743342009213\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:32893\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 21.179033994674683 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.44640848878771\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5241818869104032\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 83.25755637093572\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 143.0142914787217\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6508.188129713138\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6171.13018874079\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3218.556783443756\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 11268.966712243855\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 261.8664442561567\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 364.26992574706674\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 155.59288348415572\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 380.4788470733911\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.667284334883647\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 24.094847140533332\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 6.634483551753946\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.16968238512373\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.892870034546878\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.52887512743473\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 13.894729577858865\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.45746721327304\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.4114743342009213\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]", "duration": "00:00:25", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:25&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stderr setup -----------------------------\n[2025-05-02 11:14:41] Shutting down\n[2025-05-02 11:14:41] Waiting for application shutdown.\n[2025-05-02 11:14:41] Application shutdown complete.\n[2025-05-02 11:14:41] Finished server process [4299]\n[2025-05-02 11:14:42] Started server process [5321]\n[2025-05-02 11:14:42] Waiting for application startup.\n[2025-05-02 11:14:46] Application startup complete.\n[2025-05-02 11:14:46] Uvicorn running on http://0.0.0.0:52859 (Press CTRL+C to quit)\n[2025-05-02 11:14:46] 127.0.0.1:35156 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_trie-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:14:49] 127.0.0.1:35162 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:14:51] 127.0.0.1:35166 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:51] 127.0.0.1:35180 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:52] 127.0.0.1:35196 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:52] 127.0.0.1:35204 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:53] 127.0.0.1:35214 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:53] 127.0.0.1:35224 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:53] 127.0.0.1:35240 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:21,  2.44s/it][2025-05-02 11:14:53] 127.0.0.1:35254 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:08,  1.12s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:04,  1.45it/s][2025-05-02 11:14:54] 127.0.0.1:35268 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:14:54] 127.0.0.1:35284 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:04,  1.39it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:06&amp;lt;00:07,  1.59s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:07&amp;lt;00:05,  1.46s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:08&amp;lt;00:03,  1.12s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:10&amp;lt;00:02,  1.45s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:12&amp;lt;00:01,  1.59s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:14&amp;lt;00:00,  1.85s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:14&amp;lt;00:00,  1.48s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     7         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  14.84     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1383      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1986      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    155       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          93.21     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         133.85    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          227.06    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.49      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   7393.92   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7783.26   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          174.03    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        61.11     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           372.56    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.79     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        25.08     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           32.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           25.45     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.81     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            43.20     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 19.60260772705078 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 14.837780691683292\nINFO:sglang_benchmarks.utils:COMPLETED: 7\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1383\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1986\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 155\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4717686657765175\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 93.20800925270339\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 133.84751003316626\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 7393.918800699924\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7783.2589745521545\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3413.8617110666924\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12364.434268381447\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 174.02683664113283\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 61.1051544547081\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 143.4347925662549\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 372.5613368861377\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.788191784378736\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 25.079225674271584\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.984899509853942\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 32.07223763765939\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 25.446342753128253\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.813838113099337\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 18.635731474294364\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 43.197316490113735\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.4882192074661114\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 19.60260772705078 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 14.837780691683292\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 7\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1383\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1986\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 155\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4717686657765175\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 93.20800925270339\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 133.84751003316626\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 7393.918800699924\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7783.2589745521545\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3413.8617110666924\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12364.434268381447\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 174.02683664113283\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 61.1051544547081\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 143.4347925662549\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 372.5613368861377\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.788191784378736\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 25.079225674271584\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.984899509853942\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 32.07223763765939\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 25.446342753128253\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.813838113099337\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 18.635731474294364\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 43.197316490113735\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.4882192074661114\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]", "duration": "00:00:16", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:16&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_trie-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:15:09] 127.0.0.1:37122 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:15:10] 127.0.0.1:37126 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:10] 127.0.0.1:37134 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:11] 127.0.0.1:37146 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:11] 127.0.0.1:37158 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:11] 127.0.0.1:37164 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:12] 127.0.0.1:37176 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:12] 127.0.0.1:37192 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.29s/it][2025-05-02 11:15:12] 127.0.0.1:37194 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:12] 127.0.0.1:37206 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:01&amp;lt;00:02,  2.35it/s][2025-05-02 11:15:12] 127.0.0.1:37212 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:01&amp;lt;00:02,  2.73it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.57it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:05,  1.29s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:03,  1.11s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.24s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:10&amp;lt;00:01,  1.70s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.54s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.15s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.49     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    132       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.96     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         142.50    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          225.46    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.33      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6377.72   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6204.44   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          217.83    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        209.98    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           406.02    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          23.55     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.01     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           29.20     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.58     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.46     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            41.52     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 16.337078332901 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.487857857719064\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 132\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5222905849212267\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.95715457165484\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 142.49828125267467\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6377.715080510825\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6204.443000257015\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3004.4236522437996\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10262.696815282106\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 217.83417152861753\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 209.98170413076878\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 141.09981525624247\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 406.0185129754245\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 23.546202091504\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.013590281737635\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.2238344246398105\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 29.204575546784802\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.575134404058236\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.459030590951443\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.48308488809324\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 41.51714593172073\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.331020539860927\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 16.337078332901 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.487857857719064\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 132\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5222905849212267\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.95715457165484\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 142.49828125267467\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6377.715080510825\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6204.443000257015\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3004.4236522437996\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10262.696815282106\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 217.83417152861753\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 209.98170413076878\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 141.09981525624247\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 406.0185129754245\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 23.546202091504\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.013590281737635\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.2238344246398105\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 29.204575546784802\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.575134404058236\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.459030590951443\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.48308488809324\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 41.51714593172073\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.331020539860927\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]", "duration": "00:00:16", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:16&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_trie-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:15:25] 127.0.0.1:32856 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:15:27] 127.0.0.1:57942 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57944 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57952 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57962 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57964 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57978 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:27] 127.0.0.1:57986 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:05,  1.63it/s][2025-05-02 11:15:27] 127.0.0.1:58002 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:27] 127.0.0.1:58008 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:00&amp;lt;00:01,  4.57it/s][2025-05-02 11:15:27] 127.0.0.1:58020 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00&amp;lt;00:01,  5.35it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.32it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:05,  1.47s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:03,  1.22s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.27s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:10&amp;lt;00:01,  1.70s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.48s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.11s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    128       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.54      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          86.05     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         147.81    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          233.86    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.55      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6550.35   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6669.94   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          254.75    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        321.27    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           430.29    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          23.47     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.01     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           30.09     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.66     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            41.09     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 15.873088836669922 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.074777984060347\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 128\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5417715830182466\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 86.05138643606483\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 147.81334690014495\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6550.3506471092505\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6669.93905743584\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3147.710647783198\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10442.05426457338\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 254.7521684318781\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 321.2729808874428\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 151.69721141113124\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 430.2856041118503\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 23.474642172911228\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.014432882982174\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.560201629338185\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 30.086866283313615\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.07263459946571\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.655194133520126\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.761751581945992\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 41.09286710619926\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.5487938394089746\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 15.873088836669922 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.074777984060347\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 128\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5417715830182466\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 86.05138643606483\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 147.81334690014495\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6550.3506471092505\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6669.93905743584\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3147.710647783198\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10442.05426457338\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 254.7521684318781\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 321.2729808874428\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 151.69721141113124\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 430.2856041118503\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 23.474642172911228\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.014432882982174\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.560201629338185\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 30.086866283313615\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.07263459946571\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.655194133520126\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.761751581945992\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 41.09286710619926\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.5487938394089746\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]", "duration": "00:00:16", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:16&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_trie-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:15:41] 127.0.0.1:39326 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:15:43] 127.0.0.1:39338 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39344 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39352 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39358 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39366 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39380 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:43] 127.0.0.1:39386 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.22it/s][2025-05-02 11:15:43] 127.0.0.1:39388 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:43] 127.0.0.1:39402 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:43] 127.0.0.1:39404 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00&amp;lt;00:00, 10.21it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:06&amp;lt;00:05,  1.29s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:03,  1.33s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.03s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:07&amp;lt;00:00,  1.21it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.36s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.07s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  10.75     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    130       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.56      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          88.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         152.33    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          241.02    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.79      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6788.82   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7407.79   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          288.54    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        360.83    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           418.65    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          27.78     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        27.56     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.63     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            39.87     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 15.650282859802246 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 10.74613222014159\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 130\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5583404221245423\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 88.68307038078147\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 152.33387850297927\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6788.819910027087\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7407.794902101159\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2738.8044572408794\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10326.284191431478\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 288.5408280417323\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 360.8270571567118\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 147.39358092033564\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 418.645335547626\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 27.778751190578124\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 27.560510513095693\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.792897484841231\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.63478178288436\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.82355139783664\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.739719107747078\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 16.2271226105065\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 39.87001184374093\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.790472574292021\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 15.650282859802246 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 10.74613222014159\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 130\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5583404221245423\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 88.68307038078147\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 152.33387850297927\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6788.819910027087\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7407.794902101159\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2738.8044572408794\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10326.284191431478\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 288.5408280417323\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 360.8270571567118\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 147.39358092033564\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 418.645335547626\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 27.778751190578124\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 27.560510513095693\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.792897484841231\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.63478178288436\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.82355139783664\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.739719107747078\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 16.2271226105065\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 39.87001184374093\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.790472574292021\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]", "duration": "00:00:18", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:18&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_trie-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:15:57] 127.0.0.1:40136 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:15:58] 127.0.0.1:40148 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40160 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40174 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40178 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40192 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40198 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:15:58] 127.0.0.1:40210 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:01,  6.34it/s][2025-05-02 11:15:58] 127.0.0.1:40222 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:58] 127.0.0.1:40226 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:15:58] 127.0.0.1:40236 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.08it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:04,  1.01s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:05&amp;lt;00:03,  1.02s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.24s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.76s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.27s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  12.66     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    138       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          75.25     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         129.27    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          204.52    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.16      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6659.58   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6745.80   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          283.63    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        381.18    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           436.14    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.29     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.49     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           40.36     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.37     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.75     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            41.76     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 17.521810054779053 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 12.663616999983788\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.47379828369791044\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 75.25496072735145\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 129.26796506891324\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6659.577575977892\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6745.799510274082\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3363.832786143414\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12277.934284554796\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 283.625995585074\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 381.1800298281014\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 170.94099212806992\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 436.1398770939559\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.293336377142914\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.489547369532385\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.237250484007814\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 40.361002842191\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.36639924078415\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.74663883447647\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.903732270654583\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 41.7646000534296\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.1552964256514158\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 17.521810054779053 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 12.663616999983788\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.47379828369791044\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 75.25496072735145\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 129.26796506891324\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6659.577575977892\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6745.799510274082\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3363.832786143414\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12277.934284554796\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 283.625995585074\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 381.1800298281014\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 170.94099212806992\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 436.1398770939559\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.293336377142914\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.489547369532385\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.237250484007814\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 40.361002842191\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.36639924078415\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.74663883447647\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.903732270654583\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 41.7646000534296\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.1552964256514158\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]", "duration": "00:00:17", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:17&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52859&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_trie-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-02 11:16:15] 127.0.0.1:35932 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-02 11:16:17] 127.0.0.1:36848 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36860 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36868 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36876 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36888 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36890 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-02 11:16:17] 127.0.0.1:36900 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:16:17] 127.0.0.1:36908 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-02 11:16:17] 127.0.0.1:36920 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:00&amp;lt;00:00, 28.57it/s][2025-05-02 11:16:17] 127.0.0.1:36930 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.03s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:01,  1.00it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:09&amp;lt;00:01,  1.37s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.35s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.13s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.27     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    135       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.53      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          84.56     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         145.26    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          229.82    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.60      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6763.80   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6396.71   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          269.88    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        372.05    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           388.48    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        24.00     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.40     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.80     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.09     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            41.77     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 17.02488398551941 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.269753352738917\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 135\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5323985194886102\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 84.56263151210759\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 145.25606273380913\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6763.797586783767\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6396.706037689\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3210.251703010753\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 11127.504281699657\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 269.88054082418483\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 372.0525768585503\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 154.91799732508807\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 388.4813285432756\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.910932675213438\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.99909678700012\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 6.93458332443014\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.401554557011586\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.7983233245885\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.088578574359417\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.168830618421374\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 41.77446343004703\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.6010358213243117\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52859\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 17.02488398551941 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.269753352738917\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 135\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5323985194886102\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 84.56263151210759\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 145.25606273380913\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6763.797586783767\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6396.706037689\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3210.251703010753\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 11127.504281699657\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 269.88054082418483\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 372.0525768585503\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 154.91799732508807\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 388.4813285432756\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.910932675213438\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.99909678700012\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 6.93458332443014\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.401554557011586\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.7983233245885\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.088578574359417\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.168830618421374\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 41.77446343004703\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.6010358213243117\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n--------------------------- Captured stderr teardown ---------------------------\n[2025-05-02 11:16:28] Shutting down\n[2025-05-02 11:16:28] Waiting for application shutdown.\n[2025-05-02 11:16:28] Application shutdown complete.\n[2025-05-02 11:16:28] Finished server process [5321]\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]", "duration": "00:03:56", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:03:56&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 1.003242015838623 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 2.005793571472168 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 3.0083978176116943 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 4.0113842487335205 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 5.0141167640686035 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 6.016535758972168 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 7.018559694290161 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 8.021636962890625 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 9.02354383468628 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 10.02577257156372 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 11.027965068817139 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 12.030216217041016 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 13.032590866088867 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 14.035572528839111 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 15.03772497177124 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 16.03969955444336 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 17.043031454086304 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 18.047248363494873 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 19.049407720565796 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 20.051532983779907 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 21.05409598350525 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 22.056646823883057 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 23.061110973358154 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 24.063814401626587 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 25.06661629676819 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 26.06939697265625 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 27.07136631011963 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 28.074037313461304 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 29.077270984649658 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 30.079965353012085 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 31.082748413085938 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 32.0851309299469 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 33.08801746368408 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 34.090311765670776 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 35.093114614486694 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 36.09497785568237 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 37.09700870513916 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 38.099785566329956 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 39.10401725769043 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 40.108604192733765 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 41.11166739463806 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 42.115522623062134 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 43.11794352531433 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 44.120240211486816 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 45.12227487564087 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 46.12439036369324 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 47.127551555633545 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 48.12990617752075 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 49.132561683654785 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 50.13493251800537 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 51.17427635192871 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 52.1765661239624 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 53.17925786972046 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 54.18147373199463 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 55.184868574142456 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 56.1867835521698 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 57.18872690200806 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 58.19063210487366 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 59.19358205795288 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 60.195486545562744 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 61.19746017456055 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 62.19946312904358 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 63.201382637023926 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 64.20355153083801 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 65.2054443359375 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 66.2073667049408 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 67.21021795272827 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 68.21291470527649 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 69.21520972251892 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 70.21753525733948 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 71.21953797340393 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 72.22457814216614 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 73.22713136672974 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 74.22924900054932 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 75.2315263748169 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 76.23533344268799 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 77.23845338821411 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 78.2416124343872 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 79.24434685707092 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 80.24662327766418 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 81.249582529068 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 82.25266098976135 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 83.2564971446991 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 84.25917601585388 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 85.26208233833313 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 86.2645742893219 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 87.26799178123474 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 88.27089548110962 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 89.27370119094849 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 90.2766501903534 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 91.2790150642395 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 92.28213357925415 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 93.28470253944397 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 94.28802442550659 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 95.29010128974915 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 96.2921998500824 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 97.29433846473694 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 98.29681515693665 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 99.29933500289917 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 100.30246639251709 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 101.30606770515442 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 102.3081374168396 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 103.31026792526245 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 104.31252884864807 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 105.31517910957336 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 106.31732296943665 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 107.32031345367432 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 108.32324624061584 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 109.32589030265808 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 110.32814621925354 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 111.33067536354065 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 112.3332200050354 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 113.33595490455627 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 114.33842515945435 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 115.34099984169006 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 116.34358143806458 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 117.3468496799469 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 118.3492705821991 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 119.35169816017151 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 120.3540415763855 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 121.3575210571289 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 122.35940504074097 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 123.36250019073486 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 124.36458659172058 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 125.36722779273987 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 126.36917662620544 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 127.37342882156372 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 128.37603783607483 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 129.3784773349762 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 130.38103342056274 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 131.38348245620728 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 132.38636112213135 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 133.38838839530945 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 134.39045548439026 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 135.3932011127472 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 136.39602303504944 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 137.39916348457336 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 138.40152430534363 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 139.40403532981873 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 140.40746974945068 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 141.41235971450806 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 142.41540241241455 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 143.418354511261 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 144.4220495223999 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 145.42899012565613 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 146.4320192337036 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 147.43506050109863 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 148.4376699924469 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 149.44002318382263 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 150.4421739578247 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 151.44422435760498 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 152.44663977622986 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 153.4487965106964 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 154.45097088813782 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 155.45340013504028 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 156.4554283618927 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 157.45753860473633 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 158.4601652622223 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 159.4620132446289 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 160.46389317512512 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 161.46572852134705 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 162.467791557312 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 163.46976447105408 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 164.47200846672058 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 165.47424745559692 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 166.47621202468872 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 167.47845149040222 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 168.48055338859558 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 169.48314237594604 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 170.48557257652283 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 171.48757410049438 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 172.48980021476746 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 173.49187302589417 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 174.494074344635 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 175.49621438980103 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 176.4986252784729 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 177.500967502594 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 178.50300216674805 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 179.50488710403442 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 180.50680351257324 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 181.5092809200287 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 182.51176977157593 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 183.51561212539673 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 184.51818823814392 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 185.520446062088 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 186.52331137657166 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 187.5259232521057 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 188.52874064445496 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 189.53099274635315 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 190.53318524360657 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 191.53548979759216 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 192.53818011283875 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 193.54051613807678 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 194.54238486289978 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 195.54490089416504 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 196.5469605922699 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 197.5496973991394 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 198.55169010162354 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 199.5541067123413 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 200.5568675994873 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 201.55880045890808 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 202.5607886314392 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 203.56351470947266 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 204.56627917289734 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 205.56997227668762 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 206.57230973243713 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 207.57460832595825 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa60-027668af5083b26f5c90408e;a8ca4232-3c0e-478f-8291-00fe4470268e)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 10.7M/642M [00:00&amp;lt;00:05, 112MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 21.9M/642M [00:00&amp;lt;00:05, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258c         | 33.0M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 44.1M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u258a         | 55.2M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 66.3M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 77.4M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 88.5M/642M [00:00&amp;lt;00:05, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 99.9M/642M [00:00&amp;lt;00:04, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 111M/642M [00:01&amp;lt;00:04, 117MB/s] \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u2589        | 122M/642M [00:01&amp;lt;00:04, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 133M/642M [00:01&amp;lt;00:04, 113MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  23%|\u2588\u2588\u258e       | 146M/642M [00:01&amp;lt;00:04, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258d       | 157M/642M [00:01&amp;lt;00:04, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  26%|\u2588\u2588\u258b       | 169M/642M [00:01&amp;lt;00:04, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 180M/642M [00:01&amp;lt;00:04, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  30%|\u2588\u2588\u2589       | 192M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  32%|\u2588\u2588\u2588\u258f      | 203M/642M [00:01&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 214M/642M [00:01&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  35%|\u2588\u2588\u2588\u258c      | 225M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  37%|\u2588\u2588\u2588\u258b      | 236M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  39%|\u2588\u2588\u2588\u258a      | 247M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  40%|\u2588\u2588\u2588\u2588      | 258M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  42%|\u2588\u2588\u2588\u2588\u258f     | 269M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  44%|\u2588\u2588\u2588\u2588\u258e     | 280M/642M [00:02&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  45%|\u2588\u2588\u2588\u2588\u258c     | 292M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 303M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u2589     | 314M/642M [00:02&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  51%|\u2588\u2588\u2588\u2588\u2588     | 325M/642M [00:02&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 336M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 347M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 359M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 370M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 381M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 392M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 403M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 414M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 425M/642M [00:03&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 436M/642M [00:03&amp;lt;00:01, 114MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 447M/642M [00:04&amp;lt;00:01, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 458M/642M [00:04&amp;lt;00:01, 109MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 469M/642M [00:04&amp;lt;00:01, 110MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 479M/642M [00:04&amp;lt;00:01, 110MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 490M/642M [00:04&amp;lt;00:01, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 500M/642M [00:04&amp;lt;00:01, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 511M/642M [00:04&amp;lt;00:01, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 521M/642M [00:04&amp;lt;00:01, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 531M/642M [00:04&amp;lt;00:01, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 541M/642M [00:05&amp;lt;00:01, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 550M/642M [00:05&amp;lt;00:00, 103MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 561M/642M [00:05&amp;lt;00:00, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 571M/642M [00:05&amp;lt;00:00, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 582M/642M [00:05&amp;lt;00:00, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 592M/642M [00:05&amp;lt;00:00, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 602M/642M [00:05&amp;lt;00:00, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 612M/642M [00:05&amp;lt;00:00, 97.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 622M/642M [00:05&amp;lt;00:00, 95.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 631M/642M [00:05&amp;lt;00:00, 94.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 640M/642M [00:06&amp;lt;00:00, 94.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:06&amp;lt;00:00, 111MB/s] \nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:18,  2.10s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:07,  1.03it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:04,  1.51it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:04,  1.45it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:04,  1.14it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:06&amp;lt;00:05,  1.39s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:03,  1.04s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:01,  1.29it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.21it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.63it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.18it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  8.51      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.18      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          230.37    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         326.05    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          556.42    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             3.86      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3283.76   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 3568.71   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          31.61     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        27.13     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           49.69     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          11.66     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        12.06     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           13.77     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           11.77     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         12.86     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            20.86     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 20.748467683792114 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 8.507989936508238\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.175365753206814\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 230.37168762853557\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 326.04645993957024\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3283.7604762986302\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 3568.709425162524\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1899.5231816150297\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6048.402626970783\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 31.61025457084179\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 27.129035908728838\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.764025771495954\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 49.692596858367324\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 11.663759717286066\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 12.05741419268811\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.4960419618657685\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 13.765785497357847\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 11.76608241548662\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 12.862592469900846\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.0058845403878367\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 20.864776168018572\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.859619605575506\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 1.003242015838623 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 2.005793571472168 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 3.0083978176116943 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 4.0113842487335205 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 5.0141167640686035 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 6.016535758972168 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 7.018559694290161 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 8.021636962890625 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 9.02354383468628 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 10.02577257156372 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 11.027965068817139 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 12.030216217041016 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 13.032590866088867 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 14.035572528839111 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 15.03772497177124 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 16.03969955444336 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 17.043031454086304 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 18.047248363494873 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 19.049407720565796 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 20.051532983779907 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 21.05409598350525 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 22.056646823883057 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 23.061110973358154 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 24.063814401626587 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 25.06661629676819 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 26.06939697265625 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 27.07136631011963 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 28.074037313461304 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 29.077270984649658 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 30.079965353012085 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 31.082748413085938 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 32.0851309299469 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 33.08801746368408 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 34.090311765670776 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 35.093114614486694 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 36.09497785568237 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 37.09700870513916 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 38.099785566329956 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 39.10401725769043 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 40.108604192733765 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 41.11166739463806 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 42.115522623062134 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 43.11794352531433 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 44.120240211486816 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 45.12227487564087 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 46.12439036369324 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 47.127551555633545 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 48.12990617752075 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 49.132561683654785 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 50.13493251800537 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 51.17427635192871 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 52.1765661239624 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 53.17925786972046 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 54.18147373199463 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 55.184868574142456 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 56.1867835521698 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 57.18872690200806 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 58.19063210487366 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 59.19358205795288 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 60.195486545562744 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 61.19746017456055 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 62.19946312904358 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 63.201382637023926 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 64.20355153083801 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 65.2054443359375 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 66.2073667049408 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 67.21021795272827 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 68.21291470527649 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 69.21520972251892 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 70.21753525733948 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 71.21953797340393 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 72.22457814216614 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 73.22713136672974 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 74.22924900054932 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 75.2315263748169 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 76.23533344268799 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 77.23845338821411 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 78.2416124343872 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 79.24434685707092 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 80.24662327766418 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 81.249582529068 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 82.25266098976135 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 83.2564971446991 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 84.25917601585388 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 85.26208233833313 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 86.2645742893219 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 87.26799178123474 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 88.27089548110962 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 89.27370119094849 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 90.2766501903534 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 91.2790150642395 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 92.28213357925415 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 93.28470253944397 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 94.28802442550659 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 95.29010128974915 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 96.2921998500824 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 97.29433846473694 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 98.29681515693665 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 99.29933500289917 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 100.30246639251709 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 101.30606770515442 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 102.3081374168396 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 103.31026792526245 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 104.31252884864807 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 105.31517910957336 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 106.31732296943665 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 107.32031345367432 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 108.32324624061584 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 109.32589030265808 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 110.32814621925354 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 111.33067536354065 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 112.3332200050354 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 113.33595490455627 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 114.33842515945435 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 115.34099984169006 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 116.34358143806458 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 117.3468496799469 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 118.3492705821991 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 119.35169816017151 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 120.3540415763855 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 121.3575210571289 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 122.35940504074097 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 123.36250019073486 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 124.36458659172058 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 125.36722779273987 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 126.36917662620544 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 127.37342882156372 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 128.37603783607483 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 129.3784773349762 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 130.38103342056274 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 131.38348245620728 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 132.38636112213135 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 133.38838839530945 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 134.39045548439026 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 135.3932011127472 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 136.39602303504944 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 137.39916348457336 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 138.40152430534363 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 139.40403532981873 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 140.40746974945068 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 141.41235971450806 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 142.41540241241455 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 143.418354511261 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 144.4220495223999 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 145.42899012565613 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 146.4320192337036 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 147.43506050109863 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 148.4376699924469 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 149.44002318382263 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 150.4421739578247 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 151.44422435760498 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 152.44663977622986 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 153.4487965106964 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 154.45097088813782 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 155.45340013504028 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 156.4554283618927 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 157.45753860473633 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 158.4601652622223 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 159.4620132446289 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 160.46389317512512 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 161.46572852134705 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 162.467791557312 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 163.46976447105408 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 164.47200846672058 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 165.47424745559692 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 166.47621202468872 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 167.47845149040222 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 168.48055338859558 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 169.48314237594604 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 170.48557257652283 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 171.48757410049438 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 172.48980021476746 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 173.49187302589417 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 174.494074344635 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 175.49621438980103 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 176.4986252784729 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 177.500967502594 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 178.50300216674805 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 179.50488710403442 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 180.50680351257324 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 181.5092809200287 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 182.51176977157593 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 183.51561212539673 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 184.51818823814392 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 185.520446062088 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 186.52331137657166 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 187.5259232521057 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 188.52874064445496 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 189.53099274635315 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 190.53318524360657 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 191.53548979759216 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 192.53818011283875 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 193.54051613807678 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 194.54238486289978 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 195.54490089416504 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 196.5469605922699 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 197.5496973991394 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 198.55169010162354 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 199.5541067123413 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 200.5568675994873 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 201.55880045890808 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 202.5607886314392 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 203.56351470947266 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 204.56627917289734 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 205.56997227668762 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 206.57230973243713 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 207.57460832595825 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa60-027668af5083b26f5c90408e;a8ca4232-3c0e-478f-8291-00fe4470268e)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    1         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  8.51      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.18      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          230.37    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         326.05    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          556.42    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             3.86      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3283.76   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 3568.71   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          31.61     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        27.13     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           49.69     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          11.66     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        12.06     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           13.77     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           11.77     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         12.86     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            20.86     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 20.748467683792114 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 8.507989936508238\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.175365753206814\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 230.37168762853557\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 326.04645993957024\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3283.7604762986302\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 3568.709425162524\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1899.5231816150297\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6048.402626970783\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 31.61025457084179\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 27.129035908728838\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.764025771495954\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 49.692596858367324\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 11.663759717286066\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 12.05741419268811\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.4960419618657685\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 13.765785497357847\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 11.76608241548662\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 12.862592469900846\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.0058845403878367\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 20.864776168018572\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.859619605575506\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa75-0074e7e202cc641c0ae464d5;52085018-2d44-4d34-aede-3838c859d682)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.26s/it]\r 20%|\u2588\u2588        | 2/10 [00:01&amp;lt;00:04,  1.72it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:06,  1.00it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.17it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.57it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.15s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:06&amp;lt;00:01,  1.61it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.51it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.57it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.35it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.39      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.35      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          265.16    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         375.28    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          640.44    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             4.69      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3468.29   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 3870.02   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          29.42     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        25.62     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           45.51     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          12.73     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        12.58     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           14.90     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           12.44     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         12.91     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            27.39     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.648050308227539 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.391761064529419\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.3528575819349253\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 265.1600860592454\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 375.2826932287483\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3468.2874109596014\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 3870.022281538695\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1894.1133092246505\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6115.66441164352\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 29.420614428818226\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 25.617402512580156\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 9.613521635300264\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 45.50670656375587\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 12.726418193573364\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 12.584334794571088\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 0.9534966484135097\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 14.898133214480577\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 12.441615771849987\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 12.911003548651934\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.856440648301307\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 27.394029917195432\nINFO:sglang_benchmarks.utils:CONCURRENCY: 4.692098920246149\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa75-0074e7e202cc641c0ae464d5;52085018-2d44-4d34-aede-3838c859d682)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    2         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.39      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.35      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          265.16    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         375.28    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          640.44    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             4.69      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3468.29   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 3870.02   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          29.42     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        25.62     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           45.51     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          12.73     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        12.58     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           14.90     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           12.44     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         12.91     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            27.39     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.648050308227539 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.391761064529419\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.3528575819349253\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 265.1600860592454\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 375.2826932287483\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3468.2874109596014\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 3870.022281538695\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1894.1133092246505\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6115.66441164352\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 29.420614428818226\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 25.617402512580156\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 9.613521635300264\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 45.50670656375587\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 12.726418193573364\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 12.584334794571088\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 0.9534966484135097\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 14.898133214480577\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 12.441615771849987\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 12.911003548651934\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.856440648301307\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 27.394029917195432\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 4.692098920246149\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa81-3c62472a551043593481c6eb;3fbc7c6c-9cad-4bb0-b260-9ad14980d5a7)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:06,  1.31it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:03,  2.57it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:08,  1.24s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.19it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.63it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.02s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.79it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.65it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.45it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.88      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.45      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          284.71    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         402.95    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          687.66    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.20      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3578.84   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4030.34   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          27.95     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        23.42     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           46.99     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.39     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.20     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           15.50     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           12.85     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.03     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            28.40     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.377946615219116 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.884200727567077\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.452601455962204\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 284.709885368592\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 402.9516438839154\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3578.836599458009\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4030.3376149386168\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1907.4065214205082\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6199.865458160639\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 27.945813350379467\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 23.42297276481986\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.247803483874609\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 46.985466089099646\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.388279467500976\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.198182745088234\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.0480265675118563\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 15.496858177660034\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 12.846910633286933\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.028189539909363\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.728811540554708\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 28.401104668155313\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.198623255023527\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa81-3c62472a551043593481c6eb;3fbc7c6c-9cad-4bb0-b260-9ad14980d5a7)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    4         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.88      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.45      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          284.71    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         402.95    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          687.66    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.20      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3578.84   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4030.34   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          27.95     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        23.42     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           46.99     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.39     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.20     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           15.50     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           12.85     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.03     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            28.40     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.377946615219116 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.884200727567077\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.452601455962204\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 284.709885368592\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 402.9516438839154\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3578.836599458009\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4030.3376149386168\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1907.4065214205082\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6199.865458160639\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 27.945813350379467\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 23.42297276481986\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.247803483874609\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 46.985466089099646\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.388279467500976\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.198182745088234\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.0480265675118563\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 15.496858177660034\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 12.846910633286933\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.028189539909363\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.728811540554708\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 28.401104668155313\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.198623255023527\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:14", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:14&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa8d-38b3b90d6afae6201ecb587d;fd707284-b7c1-4559-b723-a9e0c72b36d4)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:04,  1.92it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  2.80it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:11,  1.61s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:04&amp;lt;00:06,  1.05s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:04,  1.24it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.06s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.72it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.49it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.29it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.73      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.29      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          253.57    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         358.88    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          612.45    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.63      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   4350.32   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4974.22   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          44.97     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        37.81     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           111.91    \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          16.84     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        16.18     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           22.74     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           15.58     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         14.26     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            31.56     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 13.195164203643799 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.7296680975705385\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.2937166090149503\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 253.5684553669303\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 358.87698734074723\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 4350.323229469359\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4974.219691939652\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2252.625122722018\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 7329.40021830611\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 44.968698639422655\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 37.8107326105237\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 27.338028894742095\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 111.90633415244521\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 16.839306002028895\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 16.18086444369758\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 2.4506251166508544\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 22.743557033687832\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 15.576506231664835\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 14.26467439159751\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 4.482927477364726\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 31.562883621081706\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.628085416548067\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa8d-38b3b90d6afae6201ecb587d;fd707284-b7c1-4559-b723-a9e0c72b36d4)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    8         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.73      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.29      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          253.57    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         358.88    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          612.45    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.63      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   4350.32   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4974.22   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          44.97     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        37.81     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           111.91    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          16.84     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        16.18     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           22.74     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           15.58     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         14.26     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            31.56     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 13.195164203643799 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.7296680975705385\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.2937166090149503\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 253.5684553669303\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 358.87698734074723\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 4350.323229469359\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4974.219691939652\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2252.625122722018\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 7329.40021830611\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 44.968698639422655\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 37.8107326105237\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 27.338028894742095\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 111.90633415244521\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 16.839306002028895\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 16.18086444369758\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 2.4506251166508544\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 22.743557033687832\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 15.576506231664835\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 14.26467439159751\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 4.482927477364726\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 31.562883621081706\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.628085416548067\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa9b-09f65d791eb3923478a4c9be;5ad381f5-a304-4994-9bb8-d9ce3f3b9891)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:03,  2.86it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.44it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.42s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.01it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.35it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.05it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05&amp;lt;00:01,  1.94it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.85it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.48it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.40it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.13      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.40      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          275.05    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         389.28    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          664.33    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.64      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   4017.68   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4552.93   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          38.42     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        36.00     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           52.79     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          15.33     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        14.82     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           19.64     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           14.40     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.58     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            18.13     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.842585325241089 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.125981969758868\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4033153665611062\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 275.0498118459768\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 389.2796826840509\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 4017.6777349784966\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4552.927904296666\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2113.1810353601722\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6877.528832657263\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 38.41979010030627\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 35.99736699834466\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.139257408396396\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 52.79424237087369\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 15.331060081645617\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 14.822753110024514\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.8143247949120407\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 19.642547465115786\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 14.396714116345589\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.577213045209646\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 4.262121589732661\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 18.133087223395705\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.6380689033857445\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aa9b-09f65d791eb3923478a4c9be;5ad381f5-a304-4994-9bb8-d9ce3f3b9891)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    16        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.13      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.40      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          275.05    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         389.28    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          664.33    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.64      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   4017.68   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4552.93   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          38.42     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        36.00     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           52.79     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          15.33     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        14.82     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           19.64     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           14.40     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.58     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            18.13     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.842585325241089 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.125981969758868\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4033153665611062\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 275.0498118459768\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 389.2796826840509\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 4017.6777349784966\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4552.927904296666\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2113.1810353601722\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6877.528832657263\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 38.41979010030627\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 35.99736699834466\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.139257408396396\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 52.79424237087369\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 15.331060081645617\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 14.822753110024514\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.8143247949120407\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 19.642547465115786\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 14.396714116345589\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.577213045209646\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 4.262121589732661\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 18.133087223395705\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.6380689033857445\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:13", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:13&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aaa8-05bb7ca062b7b1fc5d1bd840;cf9d0fd5-0cd3-4fc2-aba2-fa14acb6e592)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.56it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.97it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.41s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:06,  1.02s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:03,  1.33it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.07it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05&amp;lt;00:01,  1.99it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.89it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.50it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.42it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.04      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.42      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          278.46    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         394.11    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          672.58    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.72      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   4024.23   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4581.40   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          55.43     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        53.66     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           83.70     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.81     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        14.90     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           16.16     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           14.36     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.73     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            18.01     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 12.194754362106323 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.038588967174292\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4207393053688422\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 278.4649038522931\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 394.11308330931683\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 4024.2252744734283\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4581.396135035902\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2115.8191628328277\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6865.226473510265\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 55.43394284322858\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 53.660312201827765\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 20.810258848384777\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 83.69769443757832\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.807377450203694\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 14.898589884349732\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 0.8367887490129683\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 16.157528288150207\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 14.358847084631753\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.730351347476244\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.9683203679668733\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 18.008380150422454\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.717375021103118\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-6814aaa8-05bb7ca062b7b1fc5d1bd840;cf9d0fd5-0cd3-4fc2-aba2-fa14acb6e592)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    32        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.04      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.42      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          278.46    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         394.11    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          672.58    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.72      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   4024.23   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4581.40   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          55.43     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        53.66     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           83.70     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.81     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        14.90     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           16.16     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           14.36     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.73     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            18.01     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 12.194754362106323 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.038588967174292\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4207393053688422\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 278.4649038522931\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 394.11308330931683\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 4024.2252744734283\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4581.396135035902\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2115.8191628328277\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6865.226473510265\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 55.43394284322858\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 53.660312201827765\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 20.810258848384777\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 83.69769443757832\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.807377450203694\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 14.898589884349732\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 0.8367887490129683\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 16.157528288150207\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 14.358847084631753\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.730351347476244\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.9683203679668733\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 18.008380150422454\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.717375021103118\n\n"}]}, "renderCollapsed": ["passed"], "initialSort": "result", "title": "shortfin_index.html"}' id="data-container"></div>
<script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
</footer>
</html>