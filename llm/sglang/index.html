<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title id="head-title">index.html</title>
<style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
</head>
<body>
<h1 id="title">index.html</h1>
<p>Report generated on 01-May-2025 at 11:20:13 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
<div id="environment-header">
<h2>Environment</h2>
</div>
<table id="environment"></table>
<!-- TEMPLATES -->
<template id="template_environment_row">
<tr>
<td></td>
<td></td>
</tr>
</template>
<template id="template_results-table__body--empty">
<tbody class="results-table-row">
<tr id="not-found-message">
<td colspan="4">No results found. Check the filters.
</td></tr>
</tbody></template>
<template id="template_results-table__tbody">
<tbody class="results-table-row">
<tr class="collapsible">
</tr>
<tr class="extras-row">
<td class="extra" colspan="4">
<div class="extraHTML"></div>
<div class="media">
<div class="media-container">
<div class="media-container__nav--left">&lt;</div>
<div class="media-container__viewport">
<img src=""/>
<video controls="">
<source src="" type="video/mp4"/>
</video>
</div>
<div class="media-container__nav--right">&gt;</div>
</div>
<div class="media__name"></div>
<div class="media__counter"></div>
</div>
<div class="logwrapper">
<div class="logexpander"></div>
<div class="log"></div>
</div>
</td>
</tr>
</tbody>
</template>
<!-- END TEMPLATES -->
<div class="summary">
<div class="summary__data">
<h2>Summary</h2>
<div class="additional-summary prefix">
</div>
<p class="run-count">18 tests ran in 1255 seconds</p>
<p class="filter">(Un)check the boxes to filter the results.</p>
<div class="summary__reload">
<div class="summary__reload__button hidden" onclick="location.reload()">
<div>There are still tests running. <br/>Reload this page to get the latest results!</div>
</div>
</div>
<div class="summary__spacer"></div>
<div class="controls">
<div class="filters">
<input checked="true" class="filter" data-test-result="failed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="failed">0 Failed,</span>
<input checked="true" class="filter" data-test-result="passed" name="filter_checkbox" type="checkbox"/>
<span class="passed">18 Passed,</span>
<input checked="true" class="filter" data-test-result="skipped" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="skipped">0 Skipped,</span>
<input checked="true" class="filter" data-test-result="xfailed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xfailed">0 Expected failures,</span>
<input checked="true" class="filter" data-test-result="xpassed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xpassed">0 Unexpected passes,</span>
<input checked="true" class="filter" data-test-result="error" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="error">0 Errors,</span>
<input checked="true" class="filter" data-test-result="rerun" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="rerun">0 Reruns</span>
</div>
<div class="collapse">
<button id="show_all_details">Show all details</button> / <button id="hide_all_details">Hide all details</button>
</div>
</div>
</div>
<div class="additional-summary summary">
</div>
<div class="additional-summary postfix">
</div>
</div>
<table id="results-table">
<thead id="results-table-head">
<tr>
<th class="sortable" data-column-type="result">Result</th>
<th class="sortable" data-column-type="testId">Test</th>
<th class="sortable" data-column-type="duration">Duration</th>
<th>Links</th>
</tr>
</thead>
</table>
</body>
<footer>
<div data-jsonblob='{"environment": {"Python": "3.11.12", "Platform": "Linux-5.15.0-131-generic-x86_64-with-glibc2.35", "Packages": {"pytest": "8.0.0", "pluggy": "1.5.0"}, "Plugins": {"timeout": "2.3.1", "asyncio": "0.23.8", "metadata": "3.1.1", "xdist": "3.5.0", "anyio": "4.9.0", "html": "4.1.1"}, "CI": "true"}, "tests": {"reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]", "duration": "00:11:05", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:11:05&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stderr setup -----------------------------\nINFO:integration_tests.llm.model_management:Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO:integration_tests.llm.model_management:Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO:integration_tests.llm.model_management:Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 4\nINFO:integration_tests.llm.model_management:Running export command: python -m sharktank.examples.export_paged_llm_v1 --use-attention-mask --block-seq-stride=16 --gguf-file=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/meta-llama-3.1-8b-instruct.f16.gguf --output-mlir=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir --output-config=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json --bs-prefill=4 --bs-decode=4\nINFO:integration_tests.llm.model_management:Export succeeded.\nINFO:integration_tests.llm.model_management:Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO:integration_tests.llm.model_management:Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO:integration_tests.llm.model_management:Running compiler command: iree-compile /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir -o /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb --iree-hal-target-device=hip --iree-hip-target=gfx942\nINFO:integration_tests.llm.model_management:Compilation succeeded\nINFO:integration_tests.llm.model_management:Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n[2025-05-01 11:15:05] Started server process [4391]\n[2025-05-01 11:15:05] Waiting for application startup.\n[2025-05-01 11:15:08] Application startup complete.\n[2025-05-01 11:15:08] Uvicorn running on http://0.0.0.0:47461 (Press CTRL+C to quit)\n[2025-05-01 11:15:08] 127.0.0.1:57754 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n------------------------------ Captured log setup ------------------------------\nINFO     integration_tests.llm.model_management:model_management.py:263 Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO     integration_tests.llm.model_management:model_management.py:385 Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO     integration_tests.llm.model_management:model_management.py:452 Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 4\nINFO     integration_tests.llm.model_management:model_management.py:480 Running export command: python -m sharktank.examples.export_paged_llm_v1 --use-attention-mask --block-seq-stride=16 --gguf-file=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/meta-llama-3.1-8b-instruct.f16.gguf --output-mlir=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir --output-config=/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json --bs-prefill=4 --bs-decode=4\nINFO     integration_tests.llm.model_management:model_management.py:486 Export succeeded.\nINFO     integration_tests.llm.model_management:model_management.py:493 Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO     integration_tests.llm.model_management:model_management.py:499 Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO     integration_tests.llm.model_management:model_management.py:510 Running compiler command: iree-compile /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir -o /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb --iree-hal-target-device=hip --iree-hip-target=gfx942\nINFO     integration_tests.llm.model_management:model_management.py:515 Compilation succeeded\nINFO     integration_tests.llm.model_management:model_management.py:522 Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_none-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 92.0k/642M [00:00&amp;lt;12:21, 907kB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 357k/642M [00:00&amp;lt;06:03, 1.85MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 1.06M/642M [00:00&amp;lt;02:38, 4.23MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   1%|          | 3.35M/642M [00:00&amp;lt;00:56, 11.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   1%|          | 7.53M/642M [00:00&amp;lt;00:28, 23.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 12.0M/642M [00:00&amp;lt;00:21, 31.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 16.5M/642M [00:00&amp;lt;00:18, 36.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 20.4M/642M [00:00&amp;lt;00:17, 37.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   4%|\u258d         | 24.6M/642M [00:00&amp;lt;00:16, 39.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258d         | 29.6M/642M [00:01&amp;lt;00:14, 43.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258c         | 34.6M/642M [00:01&amp;lt;00:13, 46.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258c         | 39.7M/642M [00:01&amp;lt;00:13, 48.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 44.7M/642M [00:01&amp;lt;00:12, 49.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 49.9M/642M [00:01&amp;lt;00:12, 51.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u258a         | 55.2M/642M [00:01&amp;lt;00:11, 52.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u2589         | 60.5M/642M [00:01&amp;lt;00:11, 53.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 66.0M/642M [00:01&amp;lt;00:11, 54.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588         | 71.5M/642M [00:01&amp;lt;00:10, 55.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 76.9M/642M [00:01&amp;lt;00:10, 55.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 82.5M/642M [00:02&amp;lt;00:10, 56.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258e        | 88.0M/642M [00:02&amp;lt;00:10, 56.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258d        | 93.6M/642M [00:02&amp;lt;00:09, 57.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258c        | 99.4M/642M [00:02&amp;lt;00:09, 58.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258b        | 105M/642M [00:02&amp;lt;00:09, 58.3MB/s] \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 111M/642M [00:02&amp;lt;00:09, 58.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 117M/642M [00:02&amp;lt;00:09, 59.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u2589        | 122M/642M [00:02&amp;lt;00:09, 59.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  20%|\u2588\u2589        | 128M/642M [00:02&amp;lt;00:08, 59.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 134M/642M [00:02&amp;lt;00:08, 60.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 140M/642M [00:03&amp;lt;00:08, 60.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  23%|\u2588\u2588\u258e       | 146M/642M [00:03&amp;lt;00:08, 60.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258e       | 151M/642M [00:03&amp;lt;00:08, 60.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258d       | 157M/642M [00:03&amp;lt;00:08, 60.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258c       | 163M/642M [00:03&amp;lt;00:08, 60.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  26%|\u2588\u2588\u258b       | 169M/642M [00:03&amp;lt;00:08, 60.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 175M/642M [00:03&amp;lt;00:08, 60.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 181M/642M [00:03&amp;lt;00:07, 60.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  29%|\u2588\u2588\u2589       | 186M/642M [00:03&amp;lt;00:07, 60.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  30%|\u2588\u2588\u2589       | 192M/642M [00:03&amp;lt;00:07, 60.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588       | 198M/642M [00:04&amp;lt;00:07, 60.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  32%|\u2588\u2588\u2588\u258f      | 204M/642M [00:04&amp;lt;00:07, 60.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 210M/642M [00:04&amp;lt;00:07, 60.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  34%|\u2588\u2588\u2588\u258e      | 215M/642M [00:04&amp;lt;00:07, 60.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  34%|\u2588\u2588\u2588\u258d      | 221M/642M [00:04&amp;lt;00:07, 60.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  35%|\u2588\u2588\u2588\u258c      | 227M/642M [00:04&amp;lt;00:07, 59.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258b      | 233M/642M [00:04&amp;lt;00:07, 60.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  37%|\u2588\u2588\u2588\u258b      | 239M/642M [00:04&amp;lt;00:07, 60.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 244M/642M [00:04&amp;lt;00:06, 59.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  39%|\u2588\u2588\u2588\u2589      | 250M/642M [00:04&amp;lt;00:06, 59.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  40%|\u2588\u2588\u2588\u2589      | 256M/642M [00:05&amp;lt;00:06, 59.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  41%|\u2588\u2588\u2588\u2588      | 261M/642M [00:05&amp;lt;00:06, 59.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  42%|\u2588\u2588\u2588\u2588\u258f     | 267M/642M [00:05&amp;lt;00:06, 59.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  43%|\u2588\u2588\u2588\u2588\u258e     | 273M/642M [00:05&amp;lt;00:06, 58.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  43%|\u2588\u2588\u2588\u2588\u258e     | 278M/642M [00:05&amp;lt;00:06, 58.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  44%|\u2588\u2588\u2588\u2588\u258d     | 284M/642M [00:05&amp;lt;00:06, 58.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  45%|\u2588\u2588\u2588\u2588\u258c     | 290M/642M [00:05&amp;lt;00:06, 58.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  46%|\u2588\u2588\u2588\u2588\u258c     | 295M/642M [00:05&amp;lt;00:06, 58.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 301M/642M [00:05&amp;lt;00:06, 57.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  48%|\u2588\u2588\u2588\u2588\u258a     | 306M/642M [00:05&amp;lt;00:06, 57.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u258a     | 312M/642M [00:06&amp;lt;00:06, 57.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u2589     | 317M/642M [00:06&amp;lt;00:06, 56.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  50%|\u2588\u2588\u2588\u2588\u2588     | 322M/642M [00:06&amp;lt;00:05, 56.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  51%|\u2588\u2588\u2588\u2588\u2588     | 328M/642M [00:06&amp;lt;00:05, 56.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 333M/642M [00:06&amp;lt;00:05, 55.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 339M/642M [00:06&amp;lt;00:05, 56.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 344M/642M [00:06&amp;lt;00:05, 57.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 350M/642M [00:06&amp;lt;00:05, 57.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 356M/642M [00:06&amp;lt;00:05, 55.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 361M/642M [00:06&amp;lt;00:05, 53.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 366M/642M [00:07&amp;lt;00:05, 51.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 371M/642M [00:07&amp;lt;00:05, 49.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 376M/642M [00:07&amp;lt;00:05, 47.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 380M/642M [00:07&amp;lt;00:05, 45.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 385M/642M [00:07&amp;lt;00:06, 44.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 389M/642M [00:07&amp;lt;00:06, 42.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 393M/642M [00:07&amp;lt;00:06, 42.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 397M/642M [00:07&amp;lt;00:06, 40.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 401M/642M [00:08&amp;lt;00:06, 39.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 405M/642M [00:08&amp;lt;00:06, 38.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 408M/642M [00:08&amp;lt;00:06, 37.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 412M/642M [00:08&amp;lt;00:06, 36.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 415M/642M [00:08&amp;lt;00:06, 34.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 419M/642M [00:08&amp;lt;00:06, 33.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 422M/642M [00:08&amp;lt;00:07, 32.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 425M/642M [00:08&amp;lt;00:07, 32.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 428M/642M [00:08&amp;lt;00:07, 31.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 431M/642M [00:09&amp;lt;00:07, 29.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 434M/642M [00:09&amp;lt;00:07, 28.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 437M/642M [00:09&amp;lt;00:07, 30.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 440M/642M [00:09&amp;lt;00:06, 31.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 444M/642M [00:09&amp;lt;00:06, 32.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 447M/642M [00:09&amp;lt;00:06, 32.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 450M/642M [00:09&amp;lt;00:06, 29.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 453M/642M [00:09&amp;lt;00:07, 26.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 456M/642M [00:09&amp;lt;00:06, 28.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 459M/642M [00:10&amp;lt;00:12, 15.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 462M/642M [00:10&amp;lt;00:10, 17.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 464M/642M [00:10&amp;lt;00:09, 19.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 467M/642M [00:10&amp;lt;00:08, 21.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 470M/642M [00:10&amp;lt;00:07, 23.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 472M/642M [00:10&amp;lt;00:07, 24.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 475M/642M [00:10&amp;lt;00:06, 25.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 478M/642M [00:11&amp;lt;00:06, 26.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 480M/642M [00:11&amp;lt;00:06, 26.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 483M/642M [00:11&amp;lt;00:06, 27.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 486M/642M [00:11&amp;lt;00:05, 27.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 489M/642M [00:11&amp;lt;00:05, 28.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 492M/642M [00:11&amp;lt;00:05, 29.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 495M/642M [00:11&amp;lt;00:05, 29.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 498M/642M [00:11&amp;lt;00:05, 30.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 500M/642M [00:11&amp;lt;00:04, 29.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 504M/642M [00:11&amp;lt;00:04, 30.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 507M/642M [00:12&amp;lt;00:04, 30.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 510M/642M [00:12&amp;lt;00:04, 31.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 513M/642M [00:12&amp;lt;00:04, 31.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 516M/642M [00:12&amp;lt;00:04, 32.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 519M/642M [00:12&amp;lt;00:03, 32.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 523M/642M [00:12&amp;lt;00:03, 33.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 526M/642M [00:12&amp;lt;00:03, 33.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 529M/642M [00:12&amp;lt;00:03, 33.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 532M/642M [00:12&amp;lt;00:03, 33.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 536M/642M [00:12&amp;lt;00:03, 34.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 539M/642M [00:13&amp;lt;00:03, 34.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 542M/642M [00:13&amp;lt;00:03, 34.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 546M/642M [00:13&amp;lt;00:02, 36.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 550M/642M [00:13&amp;lt;00:03, 28.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 553M/642M [00:13&amp;lt;00:03, 29.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 556M/642M [00:13&amp;lt;00:03, 29.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 559M/642M [00:13&amp;lt;00:02, 29.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 562M/642M [00:13&amp;lt;00:02, 28.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 565M/642M [00:13&amp;lt;00:02, 27.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 567M/642M [00:14&amp;lt;00:02, 26.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 570M/642M [00:14&amp;lt;00:02, 26.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 573M/642M [00:14&amp;lt;00:02, 26.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 575M/642M [00:14&amp;lt;00:02, 25.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 578M/642M [00:14&amp;lt;00:02, 25.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 580M/642M [00:14&amp;lt;00:02, 25.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 583M/642M [00:14&amp;lt;00:02, 25.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 585M/642M [00:14&amp;lt;00:02, 25.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 587M/642M [00:14&amp;lt;00:02, 25.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 590M/642M [00:15&amp;lt;00:02, 25.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 592M/642M [00:15&amp;lt;00:02, 24.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 595M/642M [00:15&amp;lt;00:02, 24.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 597M/642M [00:15&amp;lt;00:01, 24.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 599M/642M [00:15&amp;lt;00:01, 24.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 602M/642M [00:15&amp;lt;00:01, 24.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 604M/642M [00:15&amp;lt;00:01, 23.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 606M/642M [00:15&amp;lt;00:01, 23.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 608M/642M [00:15&amp;lt;00:01, 23.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 611M/642M [00:15&amp;lt;00:01, 22.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 613M/642M [00:16&amp;lt;00:01, 22.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 615M/642M [00:16&amp;lt;00:01, 22.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 617M/642M [00:16&amp;lt;00:01, 22.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 619M/642M [00:16&amp;lt;00:01, 21.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 621M/642M [00:16&amp;lt;00:00, 21.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 623M/642M [00:16&amp;lt;00:00, 21.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 625M/642M [00:16&amp;lt;00:00, 20.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 627M/642M [00:16&amp;lt;00:00, 20.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 629M/642M [00:16&amp;lt;00:00, 20.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 631M/642M [00:17&amp;lt;00:00, 20.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 633M/642M [00:17&amp;lt;00:00, 20.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 635M/642M [00:17&amp;lt;00:00, 20.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 637M/642M [00:17&amp;lt;00:00, 20.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 639M/642M [00:17&amp;lt;00:00, 19.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 641M/642M [00:17&amp;lt;00:00, 19.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:17&amp;lt;00:00, 38.3MB/s]\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:15:35] 127.0.0.1:52384 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:15:36] 127.0.0.1:40450 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:37] 127.0.0.1:40464 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:38] 127.0.0.1:40470 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:38] 127.0.0.1:40478 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:39] 127.0.0.1:40482 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:39] 127.0.0.1:40486 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:39] 127.0.0.1:40498 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:21,  2.44s/it][2025-05-01 11:15:39] 127.0.0.1:40506 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:08,  1.12s/it][2025-05-01 11:15:39] 127.0.0.1:40518 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:05,  1.24it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:03,  1.79it/s][2025-05-01 11:15:40] 127.0.0.1:40526 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:04,  1.05it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.00it/s]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:08&amp;lt;00:04,  1.48s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:10&amp;lt;00:03,  1.71s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:12&amp;lt;00:01,  1.80s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:14&amp;lt;00:00,  1.83s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:14&amp;lt;00:00,  1.46s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     7         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  14.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1091      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2058      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    165       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.48      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          74.87     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         141.23    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          216.10    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.31      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6893.69   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6654.69   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          145.06    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        60.19     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           360.58    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.87     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.15     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           42.17     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.95     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            43.81     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 42.6451358795166 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 14.571712967939675\nINFO:sglang_benchmarks.utils:COMPLETED: 7\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1091\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2058\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 165\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4803827810361917\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 74.8710877300693\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 141.23253762464037\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6893.692650965282\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6654.685529880226\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3200.640745590212\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12045.35893652588\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 145.0639870017767\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 60.18552836030722\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 137.41011256902152\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 360.5803538672626\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.870887868952444\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.14510173252837\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.5936909202553196\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 42.16891029607504\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.95227176251851\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.677532371133566\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 13.760236799805755\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 43.81237069144846\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.3116112472794588\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 42.6451358795166 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 14.571712967939675\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 7\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1091\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2058\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 165\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4803827810361917\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 74.8710877300693\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 141.23253762464037\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6893.692650965282\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6654.685529880226\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3200.640745590212\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12045.35893652588\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 145.0639870017767\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 60.18552836030722\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 137.41011256902152\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 360.5803538672626\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.870887868952444\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.14510173252837\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.5936909202553196\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 42.16891029607504\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.95227176251851\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.677532371133566\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 13.760236799805755\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 43.81237069144846\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.3116112472794588\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]", "duration": "00:00:17", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:17&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_none-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:15:55] 127.0.0.1:50526 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:15:56] 127.0.0.1:50288 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:57] 127.0.0.1:50290 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:57] 127.0.0.1:50300 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:57] 127.0.0.1:50308 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:58] 127.0.0.1:50324 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:58] 127.0.0.1:50326 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:15:58] 127.0.0.1:50342 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.28s/it][2025-05-01 11:15:58] 127.0.0.1:50344 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:15:58] 127.0.0.1:50346 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:01&amp;lt;00:02,  2.34it/s][2025-05-01 11:15:58] 127.0.0.1:50360 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:01&amp;lt;00:02,  2.72it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:02&amp;lt;00:02,  2.27it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:05,  1.35s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:03,  1.18s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.07s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:10&amp;lt;00:01,  1.73s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.54s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.16s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.61     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    137       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.11     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         141.04    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          223.15    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.41      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6592.20   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6747.93   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          211.66    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        200.51    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           398.02    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        24.40     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           42.14     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.38     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.72     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.64     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 17.084495782852173 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.606298110447824\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 137\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5169607003803294\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.1105912437423\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 141.04411108709985\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6592.203290356944\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6747.929837554693\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2974.6336323544415\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10383.8377866894\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 211.6566151380539\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 200.5072394385934\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 137.68422609410962\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 398.0208469554782\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.908633844744568\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 24.399831995052967\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.857048294471734\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 42.14310095223339\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.383901141033206\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.71598993986845\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.086627996058603\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.63627994805574\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.407910030032437\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 17.084495782852173 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.606298110447824\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 137\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5169607003803294\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.1105912437423\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 141.04411108709985\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6592.203290356944\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6747.929837554693\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2974.6336323544415\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10383.8377866894\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 211.6566151380539\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 200.5072394385934\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 137.68422609410962\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 398.0208469554782\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.908633844744568\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 24.399831995052967\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.857048294471734\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 42.14310095223339\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.383901141033206\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.71598993986845\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.086627996058603\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.63627994805574\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.407910030032437\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]", "duration": "00:00:28", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:28&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_none-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:16:22] 127.0.0.1:50998 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:16:23] 127.0.0.1:51000 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:23] 127.0.0.1:51014 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:24] 127.0.0.1:51018 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:24] 127.0.0.1:51020 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:24] 127.0.0.1:51024 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:24] 127.0.0.1:51042 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:16:24] 127.0.0.1:51048 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:07,  1.22it/s][2025-05-01 11:16:24] 127.0.0.1:51050 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:16:24] 127.0.0.1:51038 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:24] 127.0.0.1:51062 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  2.83it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.04s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:05&amp;lt;00:02,  1.04it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.10s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:01,  1.11s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:13&amp;lt;00:00,  2.05s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:13&amp;lt;00:00,  1.30s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  13.03     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    143       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.46      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          73.16     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         125.68    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          198.84    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.06      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6639.57   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6600.52   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          257.38    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        323.29    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           430.81    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.41     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           40.13     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.39     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.83     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.86     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 28.27312970161438 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 13.02563189342618\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.46063024420551146\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 73.16343712130873\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 125.67528496073705\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6639.570119635512\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6600.519749335945\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3352.280460022692\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12215.958569990471\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 257.3817423544824\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 323.2938447035849\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 151.3234230403397\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 430.81004889681935\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.264266023125\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.406311541930293\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.194329504560006\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 40.134077535507075\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.3882674219163\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.83377430588007\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.080514697157206\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.86252327263355\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.058386805627323\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 28.27312970161438 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 13.02563189342618\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.46063024420551146\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 73.16343712130873\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 125.67528496073705\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6639.570119635512\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6600.519749335945\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3352.280460022692\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12215.958569990471\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 257.3817423544824\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 323.2938447035849\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 151.3234230403397\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 430.81004889681935\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.264266023125\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.406311541930293\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.194329504560006\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 40.134077535507075\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.3882674219163\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.83377430588007\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.080514697157206\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.86252327263355\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.058386805627323\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]", "duration": "00:00:22", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:22&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_none-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:16:45] 127.0.0.1:44326 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:16:47] 127.0.0.1:38180 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:47] 127.0.0.1:38194 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:47] 127.0.0.1:38202 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:47] 127.0.0.1:38210 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:47] 127.0.0.1:38224 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:48] 127.0.0.1:38236 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:16:48] 127.0.0.1:38250 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:16:48] 127.0.0.1:38256 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:05,  1.68it/s][2025-05-01 11:16:48] 127.0.0.1:38258 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:16:48] 127.0.0.1:38272 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.08it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.08s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:03,  1.30s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:08&amp;lt;00:02,  1.19s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.06it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.40s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10&amp;lt;00:00,  1.10s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  10.95     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    153       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.55      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          87.03     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         149.50    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          236.53    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.70      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6756.82   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7516.78   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          278.62    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        369.58    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           438.76    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          27.55     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        25.86     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           40.85     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.15     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.59     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 21.573248147964478 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 10.950045216828585\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 153\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5479429428089388\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 87.0316040828198\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 149.49709956303883\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6756.81940993915\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7516.776712145656\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2853.8828017386622\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10527.727639535442\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 278.61756924539804\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 369.57507114857435\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 163.12607646021243\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 438.76436543650925\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 27.551661485390813\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 25.859693113576775\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.665474937186062\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 40.84858774687251\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.74137313234311\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.154744386672974\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.937963659835063\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.591334730386706\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.702351511510616\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 21.573248147964478 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 10.950045216828585\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 153\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5479429428089388\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 87.0316040828198\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 149.49709956303883\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6756.81940993915\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7516.776712145656\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2853.8828017386622\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10527.727639535442\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 278.61756924539804\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 369.57507114857435\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 163.12607646021243\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 438.76436543650925\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 27.551661485390813\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 25.859693113576775\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.665474937186062\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 40.84858774687251\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.74137313234311\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.154744386672974\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.937963659835063\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.591334730386706\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.702351511510616\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]", "duration": "00:00:26", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:26&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_none-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:17:11] 127.0.0.1:48588 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:17:13] 127.0.0.1:48600 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48606 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48618 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48630 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48636 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48640 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:13] 127.0.0.1:48642 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:04,  2.10it/s][2025-05-01 11:17:13] 127.0.0.1:48652 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:17:13] 127.0.0.1:48666 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:17:13] 127.0.0.1:48682 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:00,  5.18it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.17s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:04,  1.33s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.11s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.07it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.48s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.11s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.08     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    128       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.54      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          85.97     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         147.68    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          233.65    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.63      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6707.06   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7380.20   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          265.46    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        362.11    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           401.30    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          24.40     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        21.65     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           31.95     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.61     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.77     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 25.897605657577515 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.084820066578686\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 128\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5412807753271806\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 85.97342981446717\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 147.67943820176575\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6707.058070227504\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7380.19863050431\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3056.923354465548\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10797.033706540242\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 265.45618878056604\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 362.1087339706719\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 155.11506721432127\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 401.30009297281504\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 24.402420413971434\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 21.64957762184385\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 5.054058312009412\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 31.945040708026617\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.607829452544067\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.069928839802742\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.129737573990115\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.76868791133165\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.6304015924171664\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 25.897605657577515 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.084820066578686\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 128\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5412807753271806\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 85.97342981446717\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 147.67943820176575\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6707.058070227504\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7380.19863050431\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3056.923354465548\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10797.033706540242\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 265.45618878056604\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 362.1087339706719\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 155.11506721432127\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 401.30009297281504\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 24.402420413971434\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 21.64957762184385\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 5.054058312009412\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 31.945040708026617\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.607829452544067\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.069928839802742\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.129737573990115\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.76868791133165\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.6304015924171664\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]", "duration": "00:00:24", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:24&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:47461&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_none-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:17:33] 127.0.0.1:47456 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:17:35] 127.0.0.1:47470 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47486 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47502 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47504 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47512 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47524 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:17:35] 127.0.0.1:47526 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:17:35] 127.0.0.1:47542 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:17:35] 127.0.0.1:47550 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:17:35] 127.0.0.1:47562 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:00&amp;lt;00:01,  6.95it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.14it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.22s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.21s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:01,  1.01s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.96s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.28s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  12.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    133       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          74.31     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         127.64    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          201.95    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.14      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6701.18   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6451.40   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          269.95    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        363.46    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           386.51    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        23.15     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.12     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.37     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 23.7529137134552 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 12.82497217785567\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 133\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.46783727222113924\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 74.30815340445761\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 127.64160243766749\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6701.181846360366\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6451.400618068874\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3450.353040790636\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12509.340683929622\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 269.9538449135919\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 363.45916893333197\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 144.05018535728053\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 386.51215326972306\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.25672527796922\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 23.146692652022647\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 6.756237170386513\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.11517713556045\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.56956203661008\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.91286315023899\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.213474692223356\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.36605051904917\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.1350626356590507\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:47461\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 23.7529137134552 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 12.82497217785567\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 133\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.46783727222113924\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 74.30815340445761\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 127.64160243766749\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6701.181846360366\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6451.400618068874\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3450.353040790636\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12509.340683929622\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 269.9538449135919\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 363.45916893333197\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 144.05018535728053\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 386.51215326972306\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.25672527796922\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 23.146692652022647\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 6.756237170386513\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.11517713556045\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.56956203661008\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.91286315023899\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.213474692223356\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.36605051904917\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.1350626356590507\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]", "duration": "00:00:35", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:35&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stderr setup -----------------------------\n[2025-05-01 11:17:48] Shutting down\n[2025-05-01 11:17:48] Waiting for application shutdown.\n[2025-05-01 11:17:48] Application shutdown complete.\n[2025-05-01 11:17:48] Finished server process [4391]\n[2025-05-01 11:17:50] Started server process [5412]\n[2025-05-01 11:17:50] Waiting for application startup.\n[2025-05-01 11:17:53] Application startup complete.\n[2025-05-01 11:17:53] Uvicorn running on http://0.0.0.0:52585 (Press CTRL+C to quit)\n[2025-05-01 11:17:54] 127.0.0.1:35084 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_trie-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:18:07] 127.0.0.1:52850 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:18:09] 127.0.0.1:52864 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:10] 127.0.0.1:52866 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:11] 127.0.0.1:52872 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:11] 127.0.0.1:52874 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:11] 127.0.0.1:52888 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:11] 127.0.0.1:52900 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:11] 127.0.0.1:52908 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:21,  2.44s/it][2025-05-01 11:18:12] 127.0.0.1:52924 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.13s/it][2025-05-01 11:18:12] 127.0.0.1:52938 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:05,  1.24it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:03,  1.68it/s][2025-05-01 11:18:13] 127.0.0.1:52954 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:06&amp;lt;00:07,  1.60s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:07&amp;lt;00:04,  1.22s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:08&amp;lt;00:03,  1.22s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:12&amp;lt;00:04,  2.02s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:13&amp;lt;00:01,  1.72s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:13&amp;lt;00:00,  1.41s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:13&amp;lt;00:00,  1.39s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     7         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  13.93     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1091      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2058      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    160       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.50      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          78.33     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         147.77    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          226.10    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.79      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   7533.70   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7888.52   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          152.24    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        61.88     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           369.52    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          28.46     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        27.50     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           45.30     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           25.11     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.52     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            47.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 29.077625513076782 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 13.927408038638532\nINFO:sglang_benchmarks.utils:COMPLETED: 7\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1091\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2058\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 160\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5026060829538446\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 78.33474807180635\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 147.7661883884303\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 7533.704498383616\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7888.518583960831\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3127.1388920939958\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10853.421626668423\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 152.23777400595802\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 61.87804229557514\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 137.81244326093508\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 369.52208884060383\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 28.46061861062167\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 27.497093371242038\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 8.01656832996276\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 45.29716321556286\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 25.105235255545097\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.519869402050972\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.845218852540645\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 47.25734209641819\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.7864857080643475\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 29.077625513076782 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 13.927408038638532\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 7\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1091\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2058\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 160\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5026060829538446\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 78.33474807180635\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 147.7661883884303\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 7533.704498383616\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7888.518583960831\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3127.1388920939958\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10853.421626668423\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 152.23777400595802\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 61.87804229557514\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 137.81244326093508\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 369.52208884060383\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 28.46061861062167\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 27.497093371242038\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 8.01656832996276\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 45.29716321556286\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 25.105235255545097\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.519869402050972\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.845218852540645\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 47.25734209641819\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.7864857080643475\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]", "duration": "00:00:27", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:27&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_trie-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:18:37] 127.0.0.1:35114 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:18:38] 127.0.0.1:35124 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:39] 127.0.0.1:35140 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:39] 127.0.0.1:35146 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:39] 127.0.0.1:35152 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:39] 127.0.0.1:35162 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:40] 127.0.0.1:35164 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:18:40] 127.0.0.1:35174 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.28s/it][2025-05-01 11:18:40] 127.0.0.1:35190 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:18:40] 127.0.0.1:35200 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:01&amp;lt;00:02,  2.34it/s][2025-05-01 11:18:40] 127.0.0.1:35206 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:01&amp;lt;00:02,  2.72it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.09s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:02,  1.01it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.12s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:10&amp;lt;00:01,  1.59s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.46s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.15s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.54     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    144       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.55     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         141.79    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          224.34    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.35      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6442.21   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6290.36   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          208.56    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        197.63    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           392.73    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          23.73     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.96     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           29.55     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           22.85     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.71     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            42.40     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 26.922260761260986 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.544893503189087\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 144\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5197102942822814\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.54731840850238\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 141.79429195668246\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6442.211775419612\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6290.359135251492\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3031.3420642165147\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10320.28429233469\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 208.55688443407416\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 197.63341452926397\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 136.68487806307994\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 392.7344045136124\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 23.725816344060863\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.96264343204494\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 3.239872147100894\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 29.547786400316582\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 22.845735462244757\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.708688370883465\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.915661077971262\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 42.39597499370574\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.348083777632106\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 26.922260761260986 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.544893503189087\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 144\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5197102942822814\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.54731840850238\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 141.79429195668246\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6442.211775419612\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6290.359135251492\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3031.3420642165147\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10320.28429233469\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 208.55688443407416\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 197.63341452926397\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 136.68487806307994\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 392.7344045136124\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 23.725816344060863\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.96264343204494\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 3.239872147100894\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 29.547786400316582\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 22.845735462244757\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.708688370883465\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.915661077971262\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 42.39597499370574\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.348083777632106\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]", "duration": "00:00:21", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:21&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_trie-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:18:58] 127.0.0.1:55910 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:19:00] 127.0.0.1:55916 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:00] 127.0.0.1:55918 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:00] 127.0.0.1:55920 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:00] 127.0.0.1:55934 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:00] 127.0.0.1:55942 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:01] 127.0.0.1:55956 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:01] 127.0.0.1:55958 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:01] 127.0.0.1:55964 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:07,  1.21it/s][2025-05-01 11:19:01] 127.0.0.1:55974 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:01] 127.0.0.1:55978 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  2.87it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.15s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:04,  1.36s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:08&amp;lt;00:02,  1.14s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.29s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.12s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.19     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    138       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.54      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          85.15     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         146.26    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          231.41    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.64      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6784.05   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7673.91   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          260.15    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        331.18    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           436.96    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          27.79     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        26.58     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           41.83     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.19     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            44.42     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 21.297402143478394 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.19212519004941\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5360912157535929\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 85.14915476886233\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 146.26355336477192\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6784.046851564199\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7673.909202683717\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2858.1044233522434\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10479.600846488029\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 260.15194070835906\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 331.1808193102479\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 156.92284731739312\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 436.9648517109454\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 27.78501503832462\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 26.579745370232278\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 8.004898047488444\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 41.826092863088995\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.909879079180733\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.187432877719402\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.125222896811707\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 44.42487612366674\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.6368679243843856\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 21.297402143478394 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.19212519004941\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5360912157535929\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 85.14915476886233\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 146.26355336477192\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6784.046851564199\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7673.909202683717\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2858.1044233522434\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10479.600846488029\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 260.15194070835906\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 331.1808193102479\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 156.92284731739312\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 436.9648517109454\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 27.78501503832462\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 26.579745370232278\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 8.004898047488444\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 41.826092863088995\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.909879079180733\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.187432877719402\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.125222896811707\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 44.42487612366674\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.6368679243843856\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]", "duration": "00:00:27", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:27&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_trie-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:19:25] 127.0.0.1:43116 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:19:26] 127.0.0.1:43612 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:26] 127.0.0.1:43616 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:27] 127.0.0.1:43622 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:27] 127.0.0.1:43628 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:27] 127.0.0.1:43630 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:27] 127.0.0.1:43646 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:27] 127.0.0.1:43662 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.23it/s][2025-05-01 11:19:27] 127.0.0.1:43672 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:27] 127.0.0.1:43676 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:27] 127.0.0.1:43684 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00&amp;lt;00:00, 10.20it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.13s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:04,  1.45s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:08&amp;lt;00:02,  1.16s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.12it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.52s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.15s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.49     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    137       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.52      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.97     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         142.52    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          225.49    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.60      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6896.31   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7887.91   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          279.90    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        369.64    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           439.93    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          25.01     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           32.03     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           24.25     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.71     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            45.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 26.761264085769653 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.486226885579526\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 137\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5223647469068147\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.9689339670324\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 142.51851511440927\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6896.309210142742\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7887.912896461785\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3159.3024486025342\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 11043.571415357292\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 279.8976907506585\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 369.63612399995327\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 164.0174428889764\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 439.9274263065309\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 25.009991328441043\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.742233816358556\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 4.742577693116697\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 32.025203232230005\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 24.24780360412219\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.71134466677904\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 15.847730226139213\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 45.74246369302272\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.6023888151473487\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 26.761264085769653 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.486226885579526\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 137\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5223647469068147\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.9689339670324\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 142.51851511440927\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6896.309210142742\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7887.912896461785\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3159.3024486025342\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 11043.571415357292\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 279.8976907506585\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 369.63612399995327\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 164.0174428889764\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 439.9274263065309\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 25.009991328441043\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.742233816358556\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 4.742577693116697\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 32.025203232230005\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 24.24780360412219\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.71134466677904\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 15.847730226139213\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 45.74246369302272\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.6023888151473487\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]", "duration": "00:00:16", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:16&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_trie-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:19:42] 127.0.0.1:55750 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:19:43] 127.0.0.1:55762 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:43] 127.0.0.1:55764 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:43] 127.0.0.1:55780 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:43] 127.0.0.1:55790 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:43] 127.0.0.1:55798 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:43] 127.0.0.1:55802 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:19:44] 127.0.0.1:55810 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:44] 127.0.0.1:55814 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:04,  2.04it/s][2025-05-01 11:19:44] 127.0.0.1:55820 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:19:44] 127.0.0.1:55832 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:00,  5.08it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.12s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:04,  1.49s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:08&amp;lt;00:02,  1.21s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.31s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:11&amp;lt;00:00,  1.11s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  11.12     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    138       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.54      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          85.71     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         147.22    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          232.92    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.71      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6872.17   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 7998.39   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          276.63    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        370.81    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           417.39    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          24.99     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           31.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           24.17     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         20.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            44.88     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 16.224467515945435 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 11.11948767863214\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.5395932054972238\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 85.70538747314238\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 147.21901289982588\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6872.171766590327\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 7998.392383102328\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3143.6484854847467\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 10831.45887758583\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 276.6336048953235\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 370.8102060481906\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 160.34183666576777\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 417.3909238073975\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 24.99037083914157\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.676854433386392\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 4.674696756972322\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 31.910109769043597\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 24.17095366662861\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 20.684474147856236\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.470607106174514\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 44.87645592540502\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.7081771922619935\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 16.224467515945435 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 11.11948767863214\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 138\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.5395932054972238\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 85.70538747314238\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 147.21901289982588\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6872.171766590327\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 7998.392383102328\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3143.6484854847467\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 10831.45887758583\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 276.6336048953235\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 370.8102060481906\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 160.34183666576777\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 417.3909238073975\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 24.99037083914157\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.676854433386392\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 4.674696756972322\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 31.910109769043597\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 24.17095366662861\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 20.684474147856236\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.470607106174514\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 44.87645592540502\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.7081771922619935\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]", "duration": "00:00:19", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:19&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:52585&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_trie-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-05-01 11:19:58] 127.0.0.1:57256 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-05-01 11:20:00] 127.0.0.1:57258 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57268 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57278 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57282 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57292 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57296 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-05-01 11:20:00] 127.0.0.1:57300 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:20:00] 127.0.0.1:57308 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:20:00] 127.0.0.1:57310 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n[2025-05-01 11:20:00] 127.0.0.1:57316 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 503\n\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:01,  4.67it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:01&amp;lt;00:01,  3.32it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.14s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:02,  1.15s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:07&amp;lt;00:00,  1.03it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.89s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:12&amp;lt;00:00,  1.26s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     6         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  12.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      953       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  1637      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    143       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.48      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          75.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         130.23    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          206.05    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             3.14      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   6586.75   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 6334.70   \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          262.41    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        361.04    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           384.71    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          26.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        22.72     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           39.91     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           23.18     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         19.45     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            40.59     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 18.271145343780518 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 12.569740435108542\nINFO:sglang_benchmarks.utils:COMPLETED: 6\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 953\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 1637\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.47733682576621866\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 75.81699915920106\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 130.23339729654998\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 6586.75090642646\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 6334.696568548679\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 3369.578560355146\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 12261.594495596364\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 262.4102615130444\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 361.03858426213264\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 152.16208753812833\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 384.71426577307284\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 26.06692472861006\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 22.718111001470177\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 7.16016083620134\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 39.91232094977462\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 23.178518146717956\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 19.445274956524372\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 14.658624362375246\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 40.59343349188566\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.14409876978637\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:52585\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 18.271145343780518 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 12.569740435108542\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 6\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 953\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 1637\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 143\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.47733682576621866\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 75.81699915920106\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 130.23339729654998\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 6586.75090642646\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 6334.696568548679\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 3369.578560355146\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 12261.594495596364\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 262.4102615130444\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 361.03858426213264\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 152.16208753812833\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 384.71426577307284\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 26.06692472861006\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 22.718111001470177\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 7.16016083620134\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 39.91232094977462\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 23.178518146717956\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 19.445274956524372\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 14.658624362375246\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 40.59343349188566\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.14409876978637\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n--------------------------- Captured stderr teardown ---------------------------\n[2025-05-01 11:20:13] Shutting down\n[2025-05-01 11:20:13] Waiting for application shutdown.\n[2025-05-01 11:20:13] Application shutdown complete.\n[2025-05-01 11:20:13] Finished server process [5412]\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]", "duration": "00:04:26", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:04:26&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 1.003331184387207 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 2.006519317626953 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 3.009495973587036 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 4.012343168258667 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 5.014582633972168 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 6.017545461654663 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 7.020610332489014 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 8.023772239685059 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 9.026538848876953 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 10.028520822525024 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 11.030856132507324 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 12.034181356430054 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 13.037145376205444 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 14.04003357887268 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 15.043487548828125 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 16.045764684677124 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 17.04905652999878 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 18.05157446861267 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 19.053786277770996 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 20.055821418762207 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 21.05784559249878 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 22.059866905212402 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 23.062159776687622 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 24.06423330307007 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 25.066164016723633 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 26.068150758743286 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 27.070050477981567 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 28.072089195251465 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 29.07434391975403 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 30.076231241226196 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 31.078266859054565 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 32.08051323890686 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 33.08272838592529 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 34.0848708152771 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 35.08739256858826 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 36.08966684341431 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 37.091665506362915 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 38.09377837181091 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 39.0957465171814 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 40.09775948524475 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 41.10019826889038 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 42.10222387313843 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 43.104312896728516 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 44.10654592514038 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 45.108641147613525 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 46.11102890968323 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 47.11393642425537 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 48.11619448661804 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 49.11858820915222 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 50.12124752998352 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 51.124449014663696 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 52.12696433067322 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 53.13025665283203 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 54.132933378219604 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 55.13512420654297 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 56.137669801712036 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 57.14016914367676 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 58.142622232437134 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 59.147473096847534 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 60.149481534957886 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 61.15210938453674 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 62.1547577381134 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 63.156864166259766 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 64.15983819961548 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 65.16205358505249 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 66.16437435150146 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 67.16665244102478 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 68.16899728775024 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 69.1713035106659 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 70.17362022399902 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 71.17731714248657 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 72.17974829673767 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 73.1830050945282 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 74.1852297782898 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 75.18787002563477 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 76.19356966018677 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 77.1956787109375 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 78.19854712486267 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 79.20062303543091 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 80.20333933830261 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 81.2060215473175 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 82.2084231376648 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 83.21069312095642 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 84.21273398399353 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 85.21485447883606 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 86.21733140945435 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 87.21998596191406 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 88.22267580032349 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 89.22594785690308 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 90.22868514060974 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 91.23094987869263 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 92.23308491706848 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 93.23546838760376 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 94.23798632621765 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 95.24008250236511 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 96.24219512939453 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 97.2443265914917 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 98.24651050567627 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 99.24863624572754 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 100.25118684768677 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 101.25337481498718 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 102.25538158416748 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 103.25723099708557 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 104.25919127464294 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 105.2614107131958 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 106.26350688934326 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 107.26548981666565 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 108.26746916770935 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 109.2694959640503 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 110.27149772644043 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 111.27375626564026 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 112.27582716941833 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 113.27783608436584 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 114.27985787391663 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 115.28188896179199 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 116.28433275222778 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 117.28669881820679 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 118.28879451751709 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 119.29081797599792 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 120.29301834106445 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 121.29542899131775 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 122.29740262031555 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 123.29987478256226 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 124.30191993713379 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 125.30471920967102 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 126.3074586391449 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 127.3097198009491 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 128.31242990493774 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 129.31601357460022 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 130.3184015750885 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 131.3203639984131 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 132.3232045173645 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 133.32586789131165 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 134.32793354988098 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 135.33101963996887 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 136.33329439163208 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 137.33554577827454 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 138.33921480178833 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 139.3424425125122 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 140.34507989883423 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 141.3485288619995 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 142.35323476791382 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 143.35530734062195 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 144.35748529434204 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 145.3601381778717 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 146.36251020431519 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 147.36458921432495 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 148.367999792099 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 149.37124133110046 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 150.37417650222778 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 151.37650227546692 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 152.37908577919006 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 153.38146686553955 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 154.38399147987366 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 155.38738346099854 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 156.38969492912292 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 157.39196228981018 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 158.39601850509644 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 159.3995053768158 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 160.40194058418274 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 161.404639005661 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 162.40690636634827 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 163.4093840122223 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 164.41196513175964 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 165.41473841667175 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 166.417142868042 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 167.42026019096375 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 168.42324542999268 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 169.42639660835266 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 170.4294204711914 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 171.4323227405548 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 172.43422770500183 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 173.4362826347351 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 174.43822288513184 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 175.4402313232422 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 176.44253277778625 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 177.44446969032288 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 178.44637250900269 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 179.44835305213928 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 180.45030236244202 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 181.45240449905396 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 182.454687833786 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 183.45671153068542 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 184.45864725112915 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 185.46060943603516 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 186.46258902549744 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 187.46495938301086 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 188.4669303894043 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 189.4689154624939 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 190.47087264060974 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 191.47285437583923 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 192.47485399246216 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 193.47729206085205 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 194.47920846939087 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 195.4811496734619 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 196.48317980766296 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 197.48521661758423 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 198.4874701499939 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 199.49000239372253 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 200.49217796325684 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 201.49429368972778 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 202.49613976478577 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 203.49806761741638 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 204.49991011619568 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 205.50211715698242 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 206.5039837360382 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 207.50584626197815 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 208.50788974761963 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 209.50983095169067 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 210.51181721687317 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 211.51409649848938 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 212.51607084274292 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 213.51798939704895 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 214.5200011730194 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 215.5219533443451 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 216.52395915985107 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 217.5262269973755 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 218.52827858924866 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 219.53022646903992 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 220.53218698501587 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359a9-18ecbd4f7c53bdc309aad1bd;9d04b6c3-fef6-45d5-a0df-118f646f82b3)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   1%|          | 4.34M/642M [00:00&amp;lt;00:14, 45.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 12.1M/642M [00:00&amp;lt;00:09, 66.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 19.3M/642M [00:00&amp;lt;00:09, 70.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   4%|\u258d         | 27.4M/642M [00:00&amp;lt;00:08, 76.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258c         | 35.9M/642M [00:00&amp;lt;00:07, 81.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 45.0M/642M [00:00&amp;lt;00:07, 85.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 54.3M/642M [00:00&amp;lt;00:06, 89.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2589         | 63.8M/642M [00:00&amp;lt;00:06, 93.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588\u258f        | 73.4M/642M [00:00&amp;lt;00:06, 95.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 83.2M/642M [00:01&amp;lt;00:06, 97.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 93.0M/642M [00:01&amp;lt;00:05, 99.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 103M/642M [00:01&amp;lt;00:05, 100MB/s]  \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 113M/642M [00:01&amp;lt;00:05, 101MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u2589        | 122M/642M [00:01&amp;lt;00:05, 102MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 132M/642M [00:01&amp;lt;00:05, 102MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 142M/642M [00:01&amp;lt;00:05, 103MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258e       | 152M/642M [00:01&amp;lt;00:04, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258c       | 162M/642M [00:01&amp;lt;00:04, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 172M/642M [00:01&amp;lt;00:04, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 182M/642M [00:02&amp;lt;00:04, 104MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  30%|\u2588\u2588\u2589       | 192M/642M [00:02&amp;lt;00:04, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  32%|\u2588\u2588\u2588\u258f      | 202M/642M [00:02&amp;lt;00:04, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 212M/642M [00:02&amp;lt;00:04, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  35%|\u2588\u2588\u2588\u258d      | 223M/642M [00:02&amp;lt;00:04, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258b      | 233M/642M [00:02&amp;lt;00:04, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 243M/642M [00:02&amp;lt;00:03, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  39%|\u2588\u2588\u2588\u2589      | 253M/642M [00:02&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  41%|\u2588\u2588\u2588\u2588      | 263M/642M [00:02&amp;lt;00:03, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  43%|\u2588\u2588\u2588\u2588\u258e     | 273M/642M [00:02&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  44%|\u2588\u2588\u2588\u2588\u258d     | 283M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  46%|\u2588\u2588\u2588\u2588\u258c     | 293M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 303M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u2589     | 313M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  50%|\u2588\u2588\u2588\u2588\u2588     | 324M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 334M/642M [00:03&amp;lt;00:03, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 344M/642M [00:03&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 354M/642M [00:03&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 364M/642M [00:03&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 374M/642M [00:03&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 384M/642M [00:04&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 394M/642M [00:04&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 404M/642M [00:04&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 415M/642M [00:04&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 425M/642M [00:04&amp;lt;00:02, 106MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 435M/642M [00:04&amp;lt;00:02, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 446M/642M [00:04&amp;lt;00:01, 108MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 456M/642M [00:04&amp;lt;00:01, 109MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 467M/642M [00:04&amp;lt;00:01, 108MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 477M/642M [00:04&amp;lt;00:01, 105MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 487M/642M [00:05&amp;lt;00:01, 103MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 497M/642M [00:05&amp;lt;00:01, 100MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 506M/642M [00:05&amp;lt;00:01, 98.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 516M/642M [00:05&amp;lt;00:01, 95.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 525M/642M [00:05&amp;lt;00:01, 91.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 534M/642M [00:05&amp;lt;00:01, 88.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 542M/642M [00:05&amp;lt;00:01, 84.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 550M/642M [00:05&amp;lt;00:01, 80.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 558M/642M [00:05&amp;lt;00:01, 75.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 565M/642M [00:06&amp;lt;00:01, 69.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 572M/642M [00:06&amp;lt;00:01, 62.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 578M/642M [00:06&amp;lt;00:01, 50.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 583M/642M [00:06&amp;lt;00:01, 35.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 587M/642M [00:07&amp;lt;00:02, 27.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 591M/642M [00:07&amp;lt;00:02, 21.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 593M/642M [00:07&amp;lt;00:03, 15.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 595M/642M [00:08&amp;lt;00:04, 11.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 597M/642M [00:08&amp;lt;00:05, 7.86MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 598M/642M [00:09&amp;lt;00:09, 4.79MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 599M/642M [00:10&amp;lt;00:14, 3.01MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 600M/642M [00:11&amp;lt;00:15, 2.81MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 600M/642M [00:11&amp;lt;00:16, 2.72MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 601M/642M [00:11&amp;lt;00:15, 2.73MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 601M/642M [00:11&amp;lt;00:13, 3.05MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 602M/642M [00:11&amp;lt;00:12, 3.46MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 602M/642M [00:11&amp;lt;00:10, 3.88MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 603M/642M [00:11&amp;lt;00:10, 3.85MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 603M/642M [00:12&amp;lt;00:11, 3.36MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 604M/642M [00:12&amp;lt;00:14, 2.80MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 604M/642M [00:12&amp;lt;00:17, 2.26MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 604M/642M [00:12&amp;lt;00:19, 2.05MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 605M/642M [00:12&amp;lt;00:21, 1.85MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 605M/642M [00:13&amp;lt;00:23, 1.63MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 605M/642M [00:13&amp;lt;00:25, 1.49MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 605M/642M [00:13&amp;lt;00:28, 1.34MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 606M/642M [00:13&amp;lt;00:17, 2.18MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 607M/642M [00:13&amp;lt;00:07, 4.69MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 608M/642M [00:13&amp;lt;00:05, 6.61MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 609M/642M [00:13&amp;lt;00:04, 7.95MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 610M/642M [00:13&amp;lt;00:03, 8.95MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 612M/642M [00:14&amp;lt;00:03, 9.71MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 613M/642M [00:14&amp;lt;00:02, 10.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 614M/642M [00:14&amp;lt;00:02, 11.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 615M/642M [00:14&amp;lt;00:02, 11.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 616M/642M [00:14&amp;lt;00:02, 12.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 618M/642M [00:14&amp;lt;00:02, 12.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 619M/642M [00:14&amp;lt;00:01, 12.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 620M/642M [00:14&amp;lt;00:01, 12.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 622M/642M [00:14&amp;lt;00:01, 13.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 623M/642M [00:14&amp;lt;00:01, 13.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 624M/642M [00:15&amp;lt;00:01, 13.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 626M/642M [00:15&amp;lt;00:01, 13.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 627M/642M [00:15&amp;lt;00:01, 13.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 628M/642M [00:15&amp;lt;00:01, 13.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 630M/642M [00:15&amp;lt;00:00, 13.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 631M/642M [00:15&amp;lt;00:00, 13.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 632M/642M [00:15&amp;lt;00:00, 12.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 633M/642M [00:15&amp;lt;00:00, 12.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 634M/642M [00:15&amp;lt;00:00, 12.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 636M/642M [00:15&amp;lt;00:00, 12.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 637M/642M [00:16&amp;lt;00:00, 12.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 638M/642M [00:16&amp;lt;00:00, 13.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 640M/642M [00:16&amp;lt;00:00, 13.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 641M/642M [00:16&amp;lt;00:00, 13.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:16&amp;lt;00:00, 40.9MB/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:18,  2.10s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:08,  1.05s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:04,  1.55it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:04,  1.34it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:04,  1.11it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:07&amp;lt;00:05,  1.45s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:03,  1.08s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:01,  1.26it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.16it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.55it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.13it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  8.84      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.13      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          221.72    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         313.80    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          535.51    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             3.92      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3464.78   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 3766.58   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          30.26     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        27.52     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           47.80     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          12.27     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        12.73     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           14.28     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           12.43     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.43     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            19.27     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 37.22477984428406 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 8.840109533630311\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.1312077030219063\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 221.71670979229364\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 313.7970168182768\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3464.7785721346736\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 3766.5829956531525\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2008.4276841343756\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6377.116719996557\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 30.262078624218702\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 27.520148549228907\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 9.017979400874594\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 47.80196915380657\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 12.265212350246319\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 12.725825764271072\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.5676947118446378\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 14.284064564196047\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 12.425872269821085\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.432989362627268\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.066525341277505\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 19.266816079615673\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.9193842100639844\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 1.003331184387207 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 2.006519317626953 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 3.009495973587036 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 4.012343168258667 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 5.014582633972168 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 6.017545461654663 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 7.020610332489014 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 8.023772239685059 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 9.026538848876953 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 10.028520822525024 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 11.030856132507324 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 12.034181356430054 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 13.037145376205444 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 14.04003357887268 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 15.043487548828125 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 16.045764684677124 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 17.04905652999878 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 18.05157446861267 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 19.053786277770996 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 20.055821418762207 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 21.05784559249878 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 22.059866905212402 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 23.062159776687622 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 24.06423330307007 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 25.066164016723633 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 26.068150758743286 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 27.070050477981567 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 28.072089195251465 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 29.07434391975403 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 30.076231241226196 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 31.078266859054565 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 32.08051323890686 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 33.08272838592529 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 34.0848708152771 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 35.08739256858826 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 36.08966684341431 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 37.091665506362915 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 38.09377837181091 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 39.0957465171814 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 40.09775948524475 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 41.10019826889038 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 42.10222387313843 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 43.104312896728516 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 44.10654592514038 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 45.108641147613525 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 46.11102890968323 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 47.11393642425537 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 48.11619448661804 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 49.11858820915222 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 50.12124752998352 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 51.124449014663696 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 52.12696433067322 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 53.13025665283203 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 54.132933378219604 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 55.13512420654297 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 56.137669801712036 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 57.14016914367676 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 58.142622232437134 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 59.147473096847534 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 60.149481534957886 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 61.15210938453674 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 62.1547577381134 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 63.156864166259766 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 64.15983819961548 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 65.16205358505249 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 66.16437435150146 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 67.16665244102478 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 68.16899728775024 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 69.1713035106659 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 70.17362022399902 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 71.17731714248657 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 72.17974829673767 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 73.1830050945282 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 74.1852297782898 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 75.18787002563477 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 76.19356966018677 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 77.1956787109375 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 78.19854712486267 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 79.20062303543091 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 80.20333933830261 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 81.2060215473175 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 82.2084231376648 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 83.21069312095642 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 84.21273398399353 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 85.21485447883606 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 86.21733140945435 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 87.21998596191406 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 88.22267580032349 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 89.22594785690308 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 90.22868514060974 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 91.23094987869263 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 92.23308491706848 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 93.23546838760376 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 94.23798632621765 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 95.24008250236511 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 96.24219512939453 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 97.2443265914917 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 98.24651050567627 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 99.24863624572754 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 100.25118684768677 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 101.25337481498718 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 102.25538158416748 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 103.25723099708557 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 104.25919127464294 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 105.2614107131958 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 106.26350688934326 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 107.26548981666565 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 108.26746916770935 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 109.2694959640503 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 110.27149772644043 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 111.27375626564026 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 112.27582716941833 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 113.27783608436584 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 114.27985787391663 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 115.28188896179199 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 116.28433275222778 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 117.28669881820679 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 118.28879451751709 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 119.29081797599792 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 120.29301834106445 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 121.29542899131775 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 122.29740262031555 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 123.29987478256226 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 124.30191993713379 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 125.30471920967102 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 126.3074586391449 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 127.3097198009491 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 128.31242990493774 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 129.31601357460022 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 130.3184015750885 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 131.3203639984131 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 132.3232045173645 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 133.32586789131165 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 134.32793354988098 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 135.33101963996887 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 136.33329439163208 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 137.33554577827454 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 138.33921480178833 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 139.3424425125122 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 140.34507989883423 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 141.3485288619995 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 142.35323476791382 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 143.35530734062195 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 144.35748529434204 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 145.3601381778717 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 146.36251020431519 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 147.36458921432495 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 148.367999792099 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 149.37124133110046 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 150.37417650222778 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 151.37650227546692 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 152.37908577919006 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 153.38146686553955 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 154.38399147987366 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 155.38738346099854 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 156.38969492912292 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 157.39196228981018 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 158.39601850509644 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 159.3995053768158 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 160.40194058418274 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 161.404639005661 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 162.40690636634827 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 163.4093840122223 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 164.41196513175964 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 165.41473841667175 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 166.417142868042 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 167.42026019096375 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 168.42324542999268 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 169.42639660835266 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 170.4294204711914 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 171.4323227405548 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 172.43422770500183 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 173.4362826347351 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 174.43822288513184 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 175.4402313232422 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 176.44253277778625 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 177.44446969032288 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 178.44637250900269 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 179.44835305213928 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 180.45030236244202 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 181.45240449905396 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 182.454687833786 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 183.45671153068542 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 184.45864725112915 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 185.46060943603516 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 186.46258902549744 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 187.46495938301086 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 188.4669303894043 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 189.4689154624939 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 190.47087264060974 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 191.47285437583923 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 192.47485399246216 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 193.47729206085205 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 194.47920846939087 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 195.4811496734619 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 196.48317980766296 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 197.48521661758423 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 198.4874701499939 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 199.49000239372253 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 200.49217796325684 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 201.49429368972778 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 202.49613976478577 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 203.49806761741638 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 204.49991011619568 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 205.50211715698242 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 206.5039837360382 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 207.50584626197815 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 208.50788974761963 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 209.50983095169067 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 210.51181721687317 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 211.51409649848938 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 212.51607084274292 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 213.51798939704895 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 214.5200011730194 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 215.5219533443451 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 216.52395915985107 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 217.5262269973755 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 218.52827858924866 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 219.53022646903992 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 220.53218698501587 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359a9-18ecbd4f7c53bdc309aad1bd;9d04b6c3-fef6-45d5-a0df-118f646f82b3)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    1         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  8.84      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.13      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          221.72    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         313.80    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          535.51    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             3.92      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3464.78   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 3766.58   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          30.26     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        27.52     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           47.80     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          12.27     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        12.73     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           14.28     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           12.43     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.43     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            19.27     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 37.22477984428406 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 8.840109533630311\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.1312077030219063\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 221.71670979229364\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 313.7970168182768\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3464.7785721346736\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 3766.5829956531525\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2008.4276841343756\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6377.116719996557\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 30.262078624218702\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 27.520148549228907\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 9.017979400874594\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 47.80196915380657\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 12.265212350246319\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 12.725825764271072\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.5676947118446378\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 14.284064564196047\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 12.425872269821085\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.432989362627268\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.066525341277505\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 19.266816079615673\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.9193842100639844\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:13", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:13&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359ce-11d23d4057d40d4d3910f019;2473e106-c1fa-42d9-89e1-ee70e129b675)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.28s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:06,  1.04it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.17it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.54it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:06&amp;lt;00:04,  1.17s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:06&amp;lt;00:02,  1.19it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:07&amp;lt;00:00,  1.48it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.52it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.27it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.85      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.27      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          249.74    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         353.46    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          603.21    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             4.68      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3669.29   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4069.10   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          30.97     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        26.69     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           49.30     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.36     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.26     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           15.36     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.16     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.39     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            28.39     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 12.297775268554688 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.848022965714335\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.2742062610783644\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 249.7444271713594\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 353.4648168231383\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3669.2949228920043\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4069.0986872650683\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2030.996737988227\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6567.489186720923\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 30.973302014172077\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 26.689378079026937\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.432938991948308\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 49.303429601714015\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.363466943100496\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.259079293554345\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 0.9091219306676931\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 15.36030675096236\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.16322582435569\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.391691260039806\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.9109515639309858\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 28.39165921323001\nINFO:sglang_benchmarks.utils:CONCURRENCY: 4.675438564492046\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359ce-11d23d4057d40d4d3910f019;2473e106-c1fa-42d9-89e1-ee70e129b675)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    2         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.85      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.27      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          249.74    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         353.46    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          603.21    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             4.68      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3669.29   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4069.10   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          30.97     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        26.69     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           49.30     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.36     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.26     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           15.36     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.16     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.39     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            28.39     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 12.297775268554688 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.848022965714335\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.2742062610783644\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 249.7444271713594\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 353.4648168231383\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3669.2949228920043\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4069.0986872650683\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2030.996737988227\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6567.489186720923\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 30.973302014172077\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 26.689378079026937\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.432938991948308\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 49.303429601714015\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.363466943100496\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.259079293554345\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 0.9091219306676931\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 15.36030675096236\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.16322582435569\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.391691260039806\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.9109515639309858\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 28.39165921323001\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 4.675438564492046\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:13", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:13&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359db-79691e937fde8c5e24aaa879;89b18fbc-1c52-4fc4-a1a1-9eef5c40b56a)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:06,  1.32it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:03,  2.50it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.29s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.16it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.56it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.05s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.74it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.61it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.41it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.08      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.41      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          276.67    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         391.57    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          668.23    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.23      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3704.56   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4180.76   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          30.52     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        26.56     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           48.09     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.86     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.66     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           16.11     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.29     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.51     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            28.68     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 12.158891201019287 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.084341695532203\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4115637598771642\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 276.66649693592416\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 391.5677869899253\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3704.562388267368\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4180.757046211511\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1973.67351969141\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6398.273107511923\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 30.52459340542555\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 26.56075218692422\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 11.661682054131983\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 48.09479077346623\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.855102886025422\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.662009950155818\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.0926425079592477\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 16.106180224614217\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.292447769308163\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.512931764125824\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.7623459223915097\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 28.6840839125216\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.229226013482212\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359db-79691e937fde8c5e24aaa879;89b18fbc-1c52-4fc4-a1a1-9eef5c40b56a)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    4         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.08      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.41      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          276.67    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         391.57    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          668.23    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.23      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3704.56   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4180.76   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          30.52     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        26.56     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           48.09     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.86     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.66     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           16.11     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.29     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.51     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            28.68     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 12.158891201019287 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.084341695532203\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4115637598771642\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 276.66649693592416\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 391.5677869899253\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3704.562388267368\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4180.757046211511\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1973.67351969141\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6398.273107511923\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 30.52459340542555\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 26.56075218692422\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 11.661682054131983\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 48.09479077346623\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.855102886025422\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.662009950155818\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.0926425079592477\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 16.106180224614217\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.292447769308163\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.512931764125824\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.7623459223915097\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 28.6840839125216\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.229226013482212\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359e8-7fde7b0233bed09a22d36824;57cc14bd-fba8-40e9-bb43-c132b7f0e817)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:04,  2.02it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.05it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.40s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.11it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.43it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.06it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.88it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.59it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.43it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.00      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.43      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          279.83    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         396.04    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          675.87    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.48      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3837.19   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4336.94   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          28.80     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        24.83     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           46.46     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.87     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        14.17     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           20.13     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.78     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.41     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            38.33     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.541024684906006 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.004289447329938\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4276965672530906\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 279.82852718160575\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 396.04302775600735\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3837.192672211677\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4336.940856650472\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2011.8539748607693\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6605.746246427298\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 28.801666852086782\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 24.83174204826355\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.35298398590126\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 46.46101892925799\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.873782761912866\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 14.170224498480666\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 2.162831441965338\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 20.131744637340308\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.77853100402375\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.413266744464636\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 4.876719481957615\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 38.32508728839457\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.478346806005325\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359e8-7fde7b0233bed09a22d36824;57cc14bd-fba8-40e9-bb43-c132b7f0e817)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    8         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.00      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.43      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          279.83    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         396.04    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          675.87    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.48      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3837.19   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4336.94   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          28.80     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        24.83     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           46.46     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.87     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        14.17     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           20.13     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.78     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.41     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            38.33     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.541024684906006 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.004289447329938\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4276965672530906\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 279.82852718160575\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 396.04302775600735\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3837.192672211677\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4336.940856650472\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2011.8539748607693\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6605.746246427298\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 28.801666852086782\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 24.83174204826355\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.35298398590126\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 46.46101892925799\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.873782761912866\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 14.170224498480666\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 2.162831441965338\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 20.131744637340308\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.77853100402375\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.413266744464636\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 4.876719481957615\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 38.32508728839457\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.478346806005325\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359f4-1db93d724310f5c868cd3e4a;9337d31d-ba69-43d5-81a5-2e0a82d71d9f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:03,  2.85it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.61it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.32s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.06it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.40it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.09it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05&amp;lt;00:00,  2.02it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&amp;lt;00:00,  1.94it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.57it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.47it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.78      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.47      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          289.00    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         409.03    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          698.03    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.64      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3822.86   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4348.09   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          33.63     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        29.50     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           47.50     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.76     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        14.05     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           20.25     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.71     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.53     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            17.71     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.355754375457764 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.78195081371814\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4745019942893975\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 289.0023908807219\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 409.0268532158789\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3822.8584627620876\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4348.089306615293\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 2012.7084616072066\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6537.151438556612\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 33.63281060010195\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 29.504334554076195\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 9.648094684893568\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 47.49551506713033\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.759257574740023\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 14.052635493418242\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 2.176259495481302\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 20.247664770251138\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.709189054217896\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.528528157621622\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 4.120719104046593\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 17.710254956036803\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.636812427228799\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-681359f4-1db93d724310f5c868cd3e4a;9337d31d-ba69-43d5-81a5-2e0a82d71d9f)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    16        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.78      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.47      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          289.00    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         409.03    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          698.03    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.64      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3822.86   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4348.09   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          33.63     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        29.50     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           47.50     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.76     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        14.05     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           20.25     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.71     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.53     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            17.71     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.355754375457764 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.78195081371814\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4745019942893975\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 289.0023908807219\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 409.0268532158789\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3822.8584627620876\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4348.089306615293\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 2012.7084616072066\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6537.151438556612\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 33.63281060010195\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 29.504334554076195\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 9.648094684893568\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 47.49551506713033\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.759257574740023\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 14.052635493418242\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 2.176259495481302\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 20.247664770251138\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.709189054217896\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.528528157621622\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 4.120719104046593\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 17.710254956036803\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.636812427228799\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-68135a00-1725c43e259dbca056c257f2;662884b6-a458-40d3-a642-a041895bfda5)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.58it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:01,  4.01it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.31s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.05it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.42it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:03,  1.14it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05&amp;lt;00:00,  2.11it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&amp;lt;00:00,  2.02it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.61it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.52it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.59      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.52      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          297.51    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         421.07    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          718.58    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.73      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3772.92   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4293.52   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          54.85     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        52.14     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           82.90     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.01     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.92     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           15.87     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.45     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.51     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            15.96     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.903067588806152 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.587962441146374\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.517920007792257\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 297.5123215272824\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 421.0710101615721\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3772.922381106764\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4293.523591477424\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1977.2880041700262\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6419.909149594605\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 54.85141854733229\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 52.13905731216073\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 20.48905595264503\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 82.90172843262553\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.008145530050609\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.923366492957715\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.0112863782732433\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 15.867682626703752\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.451755296185548\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.514275662600994\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.6166521940768304\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 15.958510544151066\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.72699437012916\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-68135a00-1725c43e259dbca056c257f2;662884b6-a458-40d3-a642-a041895bfda5)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    32        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.59      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.52      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          297.51    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         421.07    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          718.58    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.73      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3772.92   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4293.52   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          54.85     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        52.14     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           82.90     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.01     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.92     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           15.87     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.45     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.51     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            15.96     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.903067588806152 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.587962441146374\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.517920007792257\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 297.5123215272824\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 421.0710101615721\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3772.922381106764\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4293.523591477424\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1977.2880041700262\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6419.909149594605\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 54.85141854733229\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 52.13905731216073\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 20.48905595264503\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 82.90172843262553\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.008145530050609\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.923366492957715\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.0112863782732433\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 15.867682626703752\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.451755296185548\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.514275662600994\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.6166521940768304\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 15.958510544151066\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.72699437012916\n\n"}]}, "renderCollapsed": ["passed"], "initialSort": "result", "title": "shortfin_index.html"}' id="data-container"></div>
<script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
</footer>
</html>