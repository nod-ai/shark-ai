<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title id="head-title">index.html</title>
<style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
</head>
<body>
<h1 id="title">index.html</h1>
<p>Report generated on 20-Mar-2025 at 11:18:22 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
<div id="environment-header">
<h2>Environment</h2>
</div>
<table id="environment"></table>
<!-- TEMPLATES -->
<template id="template_environment_row">
<tr>
<td></td>
<td></td>
</tr>
</template>
<template id="template_results-table__body--empty">
<tbody class="results-table-row">
<tr id="not-found-message">
<td colspan="4">No results found. Check the filters.
</td></tr>
</tbody></template>
<template id="template_results-table__tbody">
<tbody class="results-table-row">
<tr class="collapsible">
</tr>
<tr class="extras-row">
<td class="extra" colspan="4">
<div class="extraHTML"></div>
<div class="media">
<div class="media-container">
<div class="media-container__nav--left">&lt;</div>
<div class="media-container__viewport">
<img src=""/>
<video controls="">
<source src="" type="video/mp4"/>
</video>
</div>
<div class="media-container__nav--right">&gt;</div>
</div>
<div class="media__name"></div>
<div class="media__counter"></div>
</div>
<div class="logwrapper">
<div class="logexpander"></div>
<div class="log"></div>
</div>
</td>
</tr>
</tbody>
</template>
<!-- END TEMPLATES -->
<div class="summary">
<div class="summary__data">
<h2>Summary</h2>
<div class="additional-summary prefix">
</div>
<p class="run-count">18 tests ran in 1105 seconds</p>
<p class="filter">(Un)check the boxes to filter the results.</p>
<div class="summary__reload">
<div class="summary__reload__button hidden" onclick="location.reload()">
<div>There are still tests running. <br/>Reload this page to get the latest results!</div>
</div>
</div>
<div class="summary__spacer"></div>
<div class="controls">
<div class="filters">
<input checked="true" class="filter" data-test-result="failed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="failed">0 Failed,</span>
<input checked="true" class="filter" data-test-result="passed" name="filter_checkbox" type="checkbox"/>
<span class="passed">18 Passed,</span>
<input checked="true" class="filter" data-test-result="skipped" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="skipped">0 Skipped,</span>
<input checked="true" class="filter" data-test-result="xfailed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xfailed">0 Expected failures,</span>
<input checked="true" class="filter" data-test-result="xpassed" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="xpassed">0 Unexpected passes,</span>
<input checked="true" class="filter" data-test-result="error" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="error">0 Errors,</span>
<input checked="true" class="filter" data-test-result="rerun" disabled="" name="filter_checkbox" type="checkbox"/>
<span class="rerun">0 Reruns</span>
</div>
<div class="collapse">
<button id="show_all_details">Show all details</button> / <button id="hide_all_details">Hide all details</button>
</div>
</div>
</div>
<div class="additional-summary summary">
</div>
<div class="additional-summary postfix">
</div>
</div>
<table id="results-table">
<thead id="results-table-head">
<tr>
<th class="sortable" data-column-type="result">Result</th>
<th class="sortable" data-column-type="testId">Test</th>
<th class="sortable" data-column-type="duration">Duration</th>
<th>Links</th>
</tr>
</thead>
</table>
</body>
<footer>
<div data-jsonblob='{"environment": {"Python": "3.11.11", "Platform": "Linux-5.15.0-70-generic-x86_64-with-glibc2.35", "Packages": {"pytest": "8.0.0", "pluggy": "1.5.0"}, "Plugins": {"html": "4.1.1", "xdist": "3.5.0", "anyio": "4.9.0", "timeout": "2.3.1", "asyncio": "0.23.8", "metadata": "3.1.1"}, "CI": "true"}, "tests": {"reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]", "duration": "00:07:40", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:07:40&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stdout setup -----------------------------\nExporting prefill_bs1\nExporting prefill_bs4\nExporting decode_bs1\nExporting decode_bs4\nGENERATED!\nExporting\nSaving to &amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir&amp;#x27;\n\n---------------------------- Captured stderr setup -----------------------------\nINFO:integration_tests.llm.model_management:Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO:integration_tests.llm.model_management:Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO:integration_tests.llm.model_management:Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 1,4\n/home/runner/_work/shark-ai/shark-ai/sharktank/sharktank/types/gguf_interop/base.py:100: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n  data_tensor = torch.as_tensor(data.reshape(logical_shape))\nINFO:integration_tests.llm.model_management:Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO:integration_tests.llm.model_management:Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO:integration_tests.llm.model_management:Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n[2025-03-20 11:11:57] Started server process [4380]\n[2025-03-20 11:11:57] Waiting for application startup.\n[2025-03-20 11:12:00] Application startup complete.\n[2025-03-20 11:12:00] Uvicorn running on http://0.0.0.0:38691 (Press CTRL+C to quit)\n[2025-03-20 11:12:01] 127.0.0.1:37888 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n------------------------------ Captured log setup ------------------------------\nINFO     integration_tests.llm.model_management:model_management.py:176 Downloading model SanctumAI/Meta-Llama-3.1-8B-Instruct-GGUF from HuggingFace\nINFO     integration_tests.llm.model_management:model_management.py:298 Downloading tokenizer NousResearch/Meta-Llama-3.1-8B using transformers\nINFO     integration_tests.llm.model_management:model_management.py:314 Exporting model with following settings:\n  MLIR Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\n  Config Path: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/config.json\n  Batch Sizes: 1,4\nINFO     integration_tests.llm.model_management:model_management.py:336 Model successfully exported to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.mlir\nINFO     integration_tests.llm.model_management:model_management.py:342 Compiling model to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\nINFO     integration_tests.llm.model_management:model_management.py:353 Model successfully compiled to /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/model.vmfb\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_none-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   1%|          | 7.55M/642M [00:00&amp;lt;00:08, 79.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 15.6M/642M [00:00&amp;lt;00:07, 82.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   4%|\u258e         | 23.8M/642M [00:00&amp;lt;00:07, 84.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258c         | 32.4M/642M [00:00&amp;lt;00:07, 86.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258b         | 40.7M/642M [00:00&amp;lt;00:07, 85.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 49.0M/642M [00:00&amp;lt;00:07, 85.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u2589         | 57.2M/642M [00:00&amp;lt;00:07, 86.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 65.4M/642M [00:00&amp;lt;00:07, 82.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588\u258f        | 73.4M/642M [00:00&amp;lt;00:07, 83.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 81.3M/642M [00:01&amp;lt;00:07, 82.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 91.7M/642M [00:01&amp;lt;00:06, 90.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 104M/642M [00:01&amp;lt;00:05, 100MB/s]  \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 116M/642M [00:01&amp;lt;00:05, 109MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  20%|\u2588\u2588        | 128M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 140M/642M [00:01&amp;lt;00:04, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258e       | 152M/642M [00:01&amp;lt;00:04, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258c       | 163M/642M [00:01&amp;lt;00:04, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 174M/642M [00:01&amp;lt;00:04, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  29%|\u2588\u2588\u2589       | 186M/642M [00:01&amp;lt;00:04, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588       | 197M/642M [00:02&amp;lt;00:03, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 209M/642M [00:02&amp;lt;00:03, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  34%|\u2588\u2588\u2588\u258d      | 221M/642M [00:02&amp;lt;00:03, 120MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258b      | 234M/642M [00:02&amp;lt;00:03, 125MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 246M/642M [00:02&amp;lt;00:03, 122MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  40%|\u2588\u2588\u2588\u2588      | 258M/642M [00:02&amp;lt;00:03, 124MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  42%|\u2588\u2588\u2588\u2588\u258f     | 270M/642M [00:02&amp;lt;00:03, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  44%|\u2588\u2588\u2588\u2588\u258d     | 282M/642M [00:02&amp;lt;00:03, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  46%|\u2588\u2588\u2588\u2588\u258c     | 293M/642M [00:02&amp;lt;00:03, 113MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 304M/642M [00:02&amp;lt;00:03, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u2589     | 315M/642M [00:03&amp;lt;00:02, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  51%|\u2588\u2588\u2588\u2588\u2588     | 327M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 339M/642M [00:03&amp;lt;00:02, 120MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 350M/642M [00:03&amp;lt;00:02, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 362M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 373M/642M [00:03&amp;lt;00:02, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 384M/642M [00:03&amp;lt;00:02, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 396M/642M [00:03&amp;lt;00:02, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 406M/642M [00:03&amp;lt;00:02, 107MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 417M/642M [00:04&amp;lt;00:02, 109MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 432M/642M [00:04&amp;lt;00:01, 122MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 444M/642M [00:04&amp;lt;00:01, 120MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 455M/642M [00:04&amp;lt;00:01, 121MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 467M/642M [00:04&amp;lt;00:01, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 478M/642M [00:04&amp;lt;00:01, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 490M/642M [00:04&amp;lt;00:01, 115MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 501M/642M [00:04&amp;lt;00:01, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 513M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 524M/642M [00:04&amp;lt;00:01, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 536M/642M [00:05&amp;lt;00:00, 120MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 548M/642M [00:05&amp;lt;00:00, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 559M/642M [00:05&amp;lt;00:00, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 570M/642M [00:05&amp;lt;00:00, 118MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 582M/642M [00:05&amp;lt;00:00, 119MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 593M/642M [00:05&amp;lt;00:00, 111MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 606M/642M [00:05&amp;lt;00:00, 117MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 617M/642M [00:05&amp;lt;00:00, 112MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 629M/642M [00:05&amp;lt;00:00, 116MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 642M/642M [00:06&amp;lt;00:00, 120MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:06&amp;lt;00:00, 112MB/s]\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:12:12] 127.0.0.1:58832 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:12:13] 127.0.0.1:58836 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:14] 127.0.0.1:58852 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:15] 127.0.0.1:32978 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:15] 127.0.0.1:32988 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:15] 127.0.0.1:32996 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:16] 127.0.0.1:33004 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:16] 127.0.0.1:33006 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:16] 127.0.0.1:33020 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:26,  2.93s/it][2025-03-20 11:12:16] 127.0.0.1:33026 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:17] 127.0.0.1:33030 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 30%|\u2588\u2588\u2588       | 3/10 [00:10&amp;lt;00:25,  3.65s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:15&amp;lt;00:23,  4.00s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:17&amp;lt;00:09,  2.47s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:19&amp;lt;00:07,  2.45s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:20&amp;lt;00:03,  1.95s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:21&amp;lt;00:01,  1.73s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  2.15s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  21.50     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    220       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          91.15     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         129.01    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          220.16    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             5.91      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   12715.68  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 14722.20  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          72.98     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        69.29     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           155.01    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          47.47     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        46.53     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           62.87     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           45.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         39.65     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            103.34    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 34.068315505981445 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 21.50210952712223\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 220\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4650706474816458\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 91.15384690640258\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 129.01059761140854\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 12715.67520298995\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 14722.202832461335\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6406.151000983393\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 19301.307556212414\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 72.98218593932688\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 69.28530684672296\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 39.51191597567455\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 155.01269979402423\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 47.46958788637762\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 46.531296032381086\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 8.235024958513637\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 62.867369655877\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 45.57301175025867\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 39.64761912357062\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 20.46799161410795\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 103.33549633854997\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.913687299820844\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-1...\n::group::Benchmark run on llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 34.068315505981445 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 21.50210952712223\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 220\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4650706474816458\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 91.15384690640258\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 129.01059761140854\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 12715.67520298995\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 14722.202832461335\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6406.151000983393\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 19301.307556212414\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 72.98218593932688\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 69.28530684672296\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 39.51191597567455\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 155.01269979402423\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 47.46958788637762\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 46.531296032381086\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 8.235024958513637\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 62.867369655877\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 45.57301175025867\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 39.64761912357062\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 20.46799161410795\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 103.33549633854997\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.913687299820844\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]", "duration": "00:00:27", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:27&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_none-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:12:39] 127.0.0.1:42190 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:12:41] 127.0.0.1:42206 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:41] 127.0.0.1:42220 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42222 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42234 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42246 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42254 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42268 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42274 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:42] 127.0.0.1:42280 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:12:43] 127.0.0.1:42288 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:18,  2.03s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:10,  1.30s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:12&amp;lt;00:35,  5.03s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:12&amp;lt;00:18,  3.12s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:15&amp;lt;00:15,  3.11s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:15&amp;lt;00:08,  2.19s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:17&amp;lt;00:06,  2.13s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:19&amp;lt;00:03,  1.82s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:19&amp;lt;00:01,  1.29s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  2.11s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  21.14     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    217       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          92.71     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         131.22    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          223.93    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.08      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   12843.46  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 14863.93  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          73.43     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        63.63     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           168.69    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          53.97     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        50.37     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           86.90     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           46.03     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         39.18     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            108.91    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 27.178351163864136 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 21.140365758910775\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 217\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.47302871265531193\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 92.71362768044114\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 131.21816489058352\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 12843.455958599225\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 14863.934842986055\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6215.0213099757\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 19236.021549561992\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 73.42988844029605\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 63.6291530681774\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 44.66521890229783\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 168.6916864127852\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 53.96750132158442\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 50.367321560009906\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 14.84666468142662\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 86.89668177048443\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 46.03342411318819\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 39.17929844465107\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 20.758839941864355\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 108.9098482672125\nINFO:sglang_benchmarks.utils:CONCURRENCY: 6.075323438141386\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-2...\n::group::Benchmark run on llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 27.178351163864136 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 21.140365758910775\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 217\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.47302871265531193\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 92.71362768044114\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 131.21816489058352\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 12843.455958599225\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 14863.934842986055\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6215.0213099757\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 19236.021549561992\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 73.42988844029605\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 63.6291530681774\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 44.66521890229783\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 168.6916864127852\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 53.96750132158442\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 50.367321560009906\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 14.84666468142662\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 86.89668177048443\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 46.03342411318819\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 39.17929844465107\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 20.758839941864355\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 108.9098482672125\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 6.075323438141386\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]", "duration": "00:00:29", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:29&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_none-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:13:06] 127.0.0.1:41636 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:13:07] 127.0.0.1:41642 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41654 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41658 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41670 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41682 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41686 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41698 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41712 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41714 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:08] 127.0.0.1:41730 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:15,  1.70s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:10,  1.33s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:11&amp;lt;00:31,  4.57s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:14&amp;lt;00:24,  4.07s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:14&amp;lt;00:13,  2.74s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:15&amp;lt;00:08,  2.12s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:18&amp;lt;00:06,  2.18s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:18&amp;lt;00:03,  1.63s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:19&amp;lt;00:01,  1.40s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:23&amp;lt;00:00,  2.28s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:23&amp;lt;00:00,  2.37s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  23.69     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    228       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.42      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.73     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         117.08    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          199.81    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             5.72      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13542.70  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 15093.99  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          119.53    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        127.51    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           185.93    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          60.39     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        49.41     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           115.26    \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           48.39     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         43.11     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            111.57    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 29.157594680786133 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 23.692739946069196\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 228\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.42207022162749375\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.72576343898878\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 117.08227947946676\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13542.695466266014\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 15093.987303902395\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6662.848567041674\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 22693.121217491574\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 119.52897827140987\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 127.51422286964953\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 51.09708980617416\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 185.92909970553592\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 60.39196167936901\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 49.41471533675351\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 23.978262684483045\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 115.25508830868638\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 48.38679247218833\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 43.10674453154206\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 23.180765985209895\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 111.57161565031855\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.715968476880551\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-4...\n::group::Benchmark run on llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 29.157594680786133 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 23.692739946069196\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 228\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.42207022162749375\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.72576343898878\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 117.08227947946676\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13542.695466266014\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 15093.987303902395\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6662.848567041674\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 22693.121217491574\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 119.52897827140987\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 127.51422286964953\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 51.09708980617416\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 185.92909970553592\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 60.39196167936901\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 49.41471533675351\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 23.978262684483045\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 115.25508830868638\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 48.38679247218833\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 43.10674453154206\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 23.180765985209895\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 111.57161565031855\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.715968476880551\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]", "duration": "00:00:29", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:29&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_none-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:13:37] 127.0.0.1:52358 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:13:39] 127.0.0.1:52370 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52372 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52380 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52384 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52398 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52408 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52414 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:39] 127.0.0.1:52418 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:40] 127.0.0.1:52424 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:13:40] 127.0.0.1:52428 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:12,  1.41s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:07,  1.05it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:08&amp;lt;00:23,  3.32s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:12&amp;lt;00:22,  3.70s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:13&amp;lt;00:12,  2.57s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:16&amp;lt;00:11,  2.90s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:19&amp;lt;00:08,  2.75s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:19&amp;lt;00:01,  1.57s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  1.60s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  2.13s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  21.31     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    238       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          91.99     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         130.20    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          222.20    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.11      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13010.40  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 14665.31  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          147.88    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        152.48    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           236.72    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          55.47     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        50.45     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           110.28    \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           46.37     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         40.28     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            106.63    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 29.318361043930054 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 21.30557854194194\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 238\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4693606409379639\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 91.99468562384092\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 130.20064179619118\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13010.403939592652\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 14665.305997943506\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6850.405756267827\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 20714.985850478988\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 147.87886280100793\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 152.4789014365524\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 68.55756442199767\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 236.71791350468993\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 55.470507435387574\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 50.44535201654968\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 21.45373681176997\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 110.27642830568367\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 46.3662861042979\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 40.27825046796352\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 22.065488005230097\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 106.62960381712765\nINFO:sglang_benchmarks.utils:CONCURRENCY: 6.106571531949018\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-8...\n::group::Benchmark run on llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 29.318361043930054 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 21.30557854194194\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 238\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4693606409379639\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 91.99468562384092\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 130.20064179619118\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13010.403939592652\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 14665.305997943506\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6850.405756267827\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 20714.985850478988\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 147.87886280100793\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 152.4789014365524\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 68.55756442199767\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 236.71791350468993\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 55.470507435387574\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 50.44535201654968\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 21.45373681176997\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 110.27642830568367\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 46.3662861042979\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 40.27825046796352\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 22.065488005230097\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 106.62960381712765\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 6.106571531949018\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]", "duration": "00:00:31", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:31&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_none-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:14:10] 127.0.0.1:33426 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:14:11] 127.0.0.1:33438 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33450 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33454 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33456 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33468 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33482 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33496 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33512 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33526 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:11] 127.0.0.1:33538 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.24s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.18s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:13&amp;lt;00:39,  5.70s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:14&amp;lt;00:24,  4.01s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:15&amp;lt;00:13,  2.67s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:15&amp;lt;00:07,  1.95s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:17&amp;lt;00:05,  1.92s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:19&amp;lt;00:03,  1.94s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20&amp;lt;00:00,  1.26s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20&amp;lt;00:00,  2.06s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  20.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    235       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.49      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          95.29     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         134.87    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          230.16    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.75      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13877.34  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 15316.15  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          245.56    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        255.41    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           448.96    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          59.10     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        57.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           93.90     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           49.14     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         42.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            107.30    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 31.310502767562866 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 20.568131319945678\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 235\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.48618903897713983\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 95.2930516395194\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 134.86883941225858\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13877.343405550346\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 15316.154013038613\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6482.352568880774\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 20309.845121642575\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 245.56399995926768\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 255.40555804036558\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 151.24354652138283\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 448.9565917220898\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 59.09794324943175\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 57.68051395227177\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 17.972193882073828\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 93.89562048813094\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 49.139865504701305\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 42.82320255879313\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 24.948387993606907\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 107.29514558566731\nINFO:sglang_benchmarks.utils:CONCURRENCY: 6.747012253900271\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-16...\n::group::Benchmark run on llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 31.310502767562866 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 20.568131319945678\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 235\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.48618903897713983\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 95.2930516395194\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 134.86883941225858\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13877.343405550346\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 15316.154013038613\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6482.352568880774\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 20309.845121642575\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 245.56399995926768\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 255.40555804036558\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 151.24354652138283\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 448.9565917220898\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 59.09794324943175\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 57.68051395227177\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 17.972193882073828\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 93.89562048813094\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 49.139865504701305\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 42.82320255879313\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 24.948387993606907\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 107.29514558566731\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 6.747012253900271\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]", "duration": "00:00:32", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_none-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:32&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_none-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:38691&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_none-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:14:40] 127.0.0.1:50704 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:14:42] 127.0.0.1:50714 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50726 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50732 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50744 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50760 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50772 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50776 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50788 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50796 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:14:42] 127.0.0.1:50804 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:08,  1.05it/s]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.21s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:08&amp;lt;00:25,  3.69s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:10&amp;lt;00:17,  2.96s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:15&amp;lt;00:10,  2.73s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:18&amp;lt;00:07,  2.66s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:18&amp;lt;00:04,  2.05s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:21&amp;lt;00:02,  2.11s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  1.61s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  2.15s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  21.51     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    235       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.46      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          91.10     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         128.93    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          220.03    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.00      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   12901.69  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 13297.48  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          343.84    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        418.49    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           446.27    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          49.07     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        49.16     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           72.14     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           45.27     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         39.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            98.53     \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 31.87238121032715 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 21.514908478129655\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 235\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4647939827476006\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 91.09962061852971\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 128.9338508141844\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 12901.685494813137\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 13297.475607483648\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 7010.734478970294\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 21362.03242680058\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 343.84475010447204\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 418.4866489376873\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 158.41160853877417\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 446.2667140737176\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 49.067184224418995\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 49.164655741788195\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 10.116128180886093\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 72.13750885415357\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 45.267535799949094\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 39.73545343615115\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 19.654736505890334\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 98.53055032435803\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.996625785291146\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_none-32...\n::group::Benchmark run on llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_none-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:38691\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 31.87238121032715 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 21.514908478129655\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 235\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4647939827476006\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 91.09962061852971\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 128.9338508141844\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 12901.685494813137\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 13297.475607483648\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 7010.734478970294\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 21362.03242680058\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 343.84475010447204\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 418.4866489376873\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 158.41160853877417\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 446.2667140737176\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 49.067184224418995\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 49.164655741788195\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 10.116128180886093\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 72.13750885415357\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 45.267535799949094\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 39.73545343615115\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 19.654736505890334\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 98.53055032435803\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.996625785291146\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]", "duration": "00:00:43", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-1]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:43&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "---------------------------- Captured stderr setup -----------------------------\n[2025-03-20 11:15:04] Shutting down\n[2025-03-20 11:15:04] Waiting for application shutdown.\n[2025-03-20 11:15:04] Application shutdown complete.\n[2025-03-20 11:15:04] Finished server process [4380]\n[2025-03-20 11:15:06] Started server process [6106]\n[2025-03-20 11:15:06] Waiting for application startup.\n[2025-03-20 11:15:10] Application startup complete.\n[2025-03-20 11:15:10] Uvicorn running on http://0.0.0.0:40437 (Press CTRL+C to quit)\n[2025-03-20 11:15:11] 127.0.0.1:46198 - &amp;quot;GET /health HTTP/1.1&amp;quot; 200\n\n----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=1, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_1_llama31_8b_trie-1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:15:20] 127.0.0.1:37644 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:15:21] 127.0.0.1:37656 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:22] 127.0.0.1:37660 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:23] 127.0.0.1:37668 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:23] 127.0.0.1:37684 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:24] 127.0.0.1:37692 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:24] 127.0.0.1:37700 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:24] 127.0.0.1:37716 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:24] 127.0.0.1:37724 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:24] 127.0.0.1:37732 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:03&amp;lt;00:27,  3.08s/it][2025-03-20 11:15:25] 127.0.0.1:37736 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 20%|\u2588\u2588        | 2/10 [00:03&amp;lt;00:13,  1.75s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:10&amp;lt;00:28,  4.07s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:10&amp;lt;00:15,  2.53s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:11&amp;lt;00:08,  1.79s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:17&amp;lt;00:13,  3.40s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:18&amp;lt;00:07,  2.53s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:19&amp;lt;00:04,  2.01s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:21&amp;lt;00:02,  2.05s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:24&amp;lt;00:00,  2.41s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:24&amp;lt;00:00,  2.49s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  24.89     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    220       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.40      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          78.75     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         111.45    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          190.20    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             4.91      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   12222.63  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 13327.09  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          90.12     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        98.34     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           170.71    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          49.59     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        44.16     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           77.86     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           43.73     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         39.35     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            109.04    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 35.42036175727844 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 24.890192409045994\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 220\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4017646724324091\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 78.74587579675219\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 111.4495201327503\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 12222.629287000746\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 13327.092553023249\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6623.030477233371\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 22151.34093949804\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 90.11881968472153\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 98.34178944583982\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 48.9134175784459\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 170.71455274475738\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 49.59103265306827\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 44.15665635674916\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 12.68318682488517\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 77.8552149077761\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 43.734048669046516\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 39.35139602981508\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 20.769950936394885\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 109.04478254495189\nINFO:sglang_benchmarks.utils:CONCURRENCY: 4.910620651754625\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-1...\n::group::Benchmark run on llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 1\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 35.42036175727844 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 24.890192409045994\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 220\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4017646724324091\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 78.74587579675219\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 111.4495201327503\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 12222.629287000746\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 13327.092553023249\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6623.030477233371\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 22151.34093949804\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 90.11881968472153\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 98.34178944583982\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 48.9134175784459\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 170.71455274475738\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 49.59103265306827\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 44.15665635674916\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 12.68318682488517\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 77.8552149077761\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 43.734048669046516\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 39.35139602981508\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 20.769950936394885\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 109.04478254495189\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 4.910620651754625\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]", "duration": "00:00:30", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-2]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:30&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=2, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_2_llama31_8b_trie-2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:15:53] 127.0.0.1:52726 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:15:55] 127.0.0.1:52730 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:55] 127.0.0.1:43312 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43326 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43332 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43348 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43352 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43356 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43362 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:56] 127.0.0.1:43374 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:15:57] 127.0.0.1:43384 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:20,  2.25s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:10,  1.26s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:11&amp;lt;00:31,  4.54s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:14&amp;lt;00:23,  3.88s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:16&amp;lt;00:15,  3.17s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:16&amp;lt;00:08,  2.23s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:20&amp;lt;00:08,  2.76s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:20&amp;lt;00:04,  2.08s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:21&amp;lt;00:01,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  1.20s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:21&amp;lt;00:00,  2.16s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  21.63     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    230       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.46      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          90.59     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         128.22    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          218.81    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.31      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13660.96  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 15338.95  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          86.85     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        93.34     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           152.06    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          58.80     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        55.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           110.62    \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           48.93     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         42.98     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            110.12    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 30.1977276802063 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 21.634759751148522\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 230\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.46221913786073504\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 90.59495102070406\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 128.2195888425679\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13660.961005301215\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 15338.952811434865\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6769.236160529912\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 20265.500940848142\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 86.84719821903855\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 93.3432140154764\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 41.69254561218376\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 152.05966872395948\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 58.80168067014962\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 55.67790429813854\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 20.87797936036156\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 110.62234477356542\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 48.92717042231829\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 42.97742899507284\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 20.595466159388074\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 110.12042368063702\nINFO:sglang_benchmarks.utils:CONCURRENCY: 6.314357618219447\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-2...\n::group::Benchmark run on llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 2\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 30.1977276802063 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 21.634759751148522\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 230\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.46221913786073504\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 90.59495102070406\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 128.2195888425679\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13660.961005301215\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 15338.952811434865\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6769.236160529912\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 20265.500940848142\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 86.84719821903855\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 93.3432140154764\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 41.69254561218376\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 152.05966872395948\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 58.80168067014962\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 55.67790429813854\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 20.87797936036156\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 110.62234477356542\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 48.92717042231829\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 42.97742899507284\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 20.595466159388074\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 110.12042368063702\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 6.314357618219447\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]", "duration": "00:00:32", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-4]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:32&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=4, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_4_llama31_8b_trie-4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:16:23] 127.0.0.1:35174 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:16:25] 127.0.0.1:35188 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:35202 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:44574 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:44576 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:44580 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:44586 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:25] 127.0.0.1:44592 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:26] 127.0.0.1:44602 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:26] 127.0.0.1:44618 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:26] 127.0.0.1:44634 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:14,  1.63s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.25s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:10&amp;lt;00:30,  4.34s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:12&amp;lt;00:21,  3.53s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:15&amp;lt;00:16,  3.32s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:15&amp;lt;00:05,  1.67s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:16&amp;lt;00:02,  1.28s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:19&amp;lt;00:01,  1.88s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:23&amp;lt;00:00,  2.51s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:23&amp;lt;00:00,  2.38s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  23.78     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    227       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.42      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          82.44     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         116.68    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          199.11    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             5.47      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13006.94  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 15244.91  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          106.76    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        113.52    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           165.77    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          57.05     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        44.12     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           107.91    \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           46.50     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         40.03     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            117.89    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 32.13774013519287 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 23.775355122052133\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 227\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.42060360186690937\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 82.43830596591424\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 116.67543915788066\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13006.935542705469\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 15244.911968475208\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6548.9060821511575\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 22787.541474960744\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 106.75935689359903\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 113.5166350286454\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 44.15876178514245\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 165.7729206024669\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 57.05416647424376\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 44.11875221735653\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 21.45669694786586\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 107.90809589502169\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 46.50023413485315\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 40.02551198936999\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 23.386238616677886\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 117.88558826316148\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.470763938512644\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-4...\n::group::Benchmark run on llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 4\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 32.13774013519287 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 23.775355122052133\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 227\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.42060360186690937\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 82.43830596591424\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 116.67543915788066\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13006.935542705469\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 15244.911968475208\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6548.9060821511575\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 22787.541474960744\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 106.75935689359903\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 113.5166350286454\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 44.15876178514245\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 165.7729206024669\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 57.05416647424376\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 44.11875221735653\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 21.45669694786586\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 107.90809589502169\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 46.50023413485315\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 40.02551198936999\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 23.386238616677886\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 117.88558826316148\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.470763938512644\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]", "duration": "00:00:32", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-8]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:32&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=8, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_8_llama31_8b_trie-8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:16:57] 127.0.0.1:53938 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:16:58] 127.0.0.1:53954 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:58] 127.0.0.1:53956 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:58] 127.0.0.1:53970 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:58] 127.0.0.1:53976 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:58] 127.0.0.1:53982 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:59] 127.0.0.1:53988 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:59] 127.0.0.1:53998 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:59] 127.0.0.1:54014 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:59] 127.0.0.1:54016 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:16:59] 127.0.0.1:54030 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:12,  1.35s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.18s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:12&amp;lt;00:35,  5.13s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:12&amp;lt;00:18,  3.16s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:13&amp;lt;00:11,  2.29s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:16&amp;lt;00:10,  2.53s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:17&amp;lt;00:03,  1.69s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:18&amp;lt;00:01,  1.37s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:22&amp;lt;00:00,  2.10s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:22&amp;lt;00:00,  2.23s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  22.32     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    234       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.45      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          87.82     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         124.29    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          212.10    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             5.80      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   12954.53  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 14319.08  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          165.00    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        149.05    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           439.12    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          56.80     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        47.43     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           106.74    \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           46.10     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         39.10     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            108.61    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 31.862276315689087 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 22.319299340015277\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 234\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4480427386029742\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 87.81637676618294\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 124.28705568846505\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 12954.527461179532\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 14319.08272812143\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6332.730794057359\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 21641.277227743994\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 165.00464263372123\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 149.04596516862512\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 115.26676399950239\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 439.1232045576908\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 56.803143283008154\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 47.42977891051725\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 21.063989582343208\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 106.74123680017657\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 46.10214981399194\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 39.096433436498046\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 22.974510334602336\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 108.60547843854873\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.804181961014312\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-8...\n::group::Benchmark run on llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 8\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 31.862276315689087 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 22.319299340015277\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 234\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4480427386029742\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 87.81637676618294\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 124.28705568846505\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 12954.527461179532\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 14319.08272812143\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6332.730794057359\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 21641.277227743994\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 165.00464263372123\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 149.04596516862512\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 115.26676399950239\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 439.1232045576908\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 56.803143283008154\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 47.42977891051725\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 21.063989582343208\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 106.74123680017657\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 46.10214981399194\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 39.096433436498046\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 22.974510334602336\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 108.60547843854873\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.804181961014312\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]", "duration": "00:00:31", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-16]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:31&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=16, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_16_llama31_8b_trie-16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:17:29] 127.0.0.1:59342 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:17:30] 127.0.0.1:59354 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59362 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59368 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59376 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59384 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59400 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59410 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:30] 127.0.0.1:59414 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:31] 127.0.0.1:59422 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:31] 127.0.0.1:59430 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:10,  1.21s/it]\r 20%|\u2588\u2588        | 2/10 [00:01&amp;lt;00:07,  1.12it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:12&amp;lt;00:37,  5.38s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:13&amp;lt;00:20,  3.48s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:14&amp;lt;00:13,  2.73s/it]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:15&amp;lt;00:08,  2.10s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:15&amp;lt;00:04,  1.47s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:20&amp;lt;00:05,  2.53s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:20&amp;lt;00:01,  1.90s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:20&amp;lt;00:00,  2.10s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  20.98     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    232       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.48      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          93.44     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         132.25    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          225.68    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             6.46      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13546.84  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 14907.43  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          385.48    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        533.66    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           619.84    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          51.38     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        54.32     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           65.26     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           47.44     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         41.74     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            100.23    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 30.84380865097046 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 20.976155958138406\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 232\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.47673177201565203\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 93.4394273150678\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 132.24539355714188\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13546.839966578409\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 14907.425378914922\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6738.000396019913\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 20832.0455714711\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 385.4816785780713\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 533.6575544206426\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 245.42631167596033\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 619.8358126031235\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 51.37805090791046\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 54.31506724656247\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 9.342805624450607\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 65.25773592445137\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 47.443660179327\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 41.73966345842928\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 22.09971694229319\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 100.2297864994034\nINFO:sglang_benchmarks.utils:CONCURRENCY: 6.458209022479381\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-16...\n::group::Benchmark run on llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 16\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 30.84380865097046 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 20.976155958138406\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 232\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.47673177201565203\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 93.4394273150678\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 132.24539355714188\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13546.839966578409\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 14907.425378914922\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6738.000396019913\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 20832.0455714711\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 385.4816785780713\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 533.6575544206426\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 245.42631167596033\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 619.8358126031235\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 51.37805090791046\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 54.31506724656247\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 9.342805624450607\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 65.25773592445137\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 47.443660179327\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 41.73966345842928\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 22.09971694229319\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 100.2297864994034\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 6.458209022479381\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n"}], "reports/shortfin_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]", "duration": "00:00:30", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/shortfin_benchmark_test.py::test_shortfin_benchmark[llama31_8b_trie-32]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:30&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Running SGLang Benchmark with the following settings:\nINFO:sglang_benchmarks.shortfin_benchmark_test:Test parameterization: llama31_8b_trie-32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO:sglang_benchmarks.shortfin_benchmark_test:Fail to load tokenizer config with error=None is not a local folder and is not a valid model identifier listed on &amp;#x27;https://huggingface.co/models&amp;#x27;\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=&amp;lt;your_token&amp;gt;`\nINFO:sglang_benchmarks.shortfin_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:40437&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF&amp;#x27;, request_rate=32, backend=&amp;#x27;shortfin&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF/shortfin_10_32_llama31_8b_trie-32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=None, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.shortfin_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.shortfin_benchmark_test:Starting initial single prompt test run...\n[2025-03-20 11:17:57] 127.0.0.1:49920 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\nINFO:sglang_benchmarks.shortfin_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s][2025-03-20 11:17:59] 127.0.0.1:49936 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49940 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49954 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49962 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49964 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49968 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49976 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49992 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:49994 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n[2025-03-20 11:17:59] 127.0.0.1:50002 - &amp;quot;POST /generate HTTP/1.1&amp;quot; 200\n\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:10,  1.12s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:09,  1.25s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:11&amp;lt;00:33,  4.84s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:15&amp;lt;00:25,  4.30s/it]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:15&amp;lt;00:14,  2.99s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:16&amp;lt;00:04,  1.58s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:17&amp;lt;00:02,  1.41s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:18&amp;lt;00:01,  1.37s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:22&amp;lt;00:00,  2.18s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:22&amp;lt;00:00,  2.26s/it]\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.shortfin_benchmark_test:Backend:                                 shortfin  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.shortfin_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark duration (s):                  22.57     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total generated tokens (retokenized):    227       \nINFO:sglang_benchmarks.shortfin_benchmark_test:Request throughput (req/s):              0.44      \nINFO:sglang_benchmarks.shortfin_benchmark_test:Input token throughput (tok/s):          86.85     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Output token throughput (tok/s):         122.93    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Total token throughput (tok/s):          209.78    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Concurrency:                             5.99      \nINFO:sglang_benchmarks.shortfin_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean E2E Latency (ms):                   13508.07  \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median E2E Latency (ms):                 15655.61  \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TTFT (ms):                          279.97    \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TTFT (ms):                        330.19    \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TTFT (ms):                           456.26    \nINFO:sglang_benchmarks.shortfin_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean TPOT (ms):                          56.21     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median TPOT (ms):                        48.97     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 TPOT (ms):                           89.38     \nINFO:sglang_benchmarks.shortfin_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.shortfin_benchmark_test:Mean ITL (ms):                           47.68     \nINFO:sglang_benchmarks.shortfin_benchmark_test:Median ITL (ms):                         44.41     \nINFO:sglang_benchmarks.shortfin_benchmark_test:P99 ITL (ms):                            105.95    \nINFO:sglang_benchmarks.shortfin_benchmark_test:==================================================\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run completed in 30.129435300827026 seconds\nINFO:sglang_benchmarks.shortfin_benchmark_test:\n\n======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: shortfin\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 22.566446967888623\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 227\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 0.4431357765017107\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 86.8546121943353\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 122.92586440157454\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 13508.074843417853\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 15655.608983943239\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 6449.373272660158\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 22105.858841966838\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 279.9707958009094\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 330.18861047457904\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 155.02399621013512\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 456.26374787651\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 56.211422623311236\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 48.971994478870876\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 16.489917385121252\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 89.38328195763752\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 47.68421409962861\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 44.40725548192859\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 22.725253022223917\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 105.94675720203666\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.985911234781194\nINFO:sglang_benchmarks.shortfin_benchmark_test:Benchmark run successful\n::endgroup::\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:87 Starting benchmark run on llama31_8b_trie-32...\n::group::Benchmark run on llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:91 Running SGLang Benchmark with the following settings:\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:92 Test parameterization: llama31_8b_trie-32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:93 Benchmark Args: Backend: shortfin\nBase URL: http://localhost:40437\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/model_cache0/SanctumAI_Meta-Llama-3.1-8B-Instruct-GGUF\nRequest Rate: 32\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:104 Benchmark run completed in 30.129435300827026 seconds\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:105 \n\n======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: shortfin\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 22.566446967888623\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 227\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 0.4431357765017107\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 86.8546121943353\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 122.92586440157454\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 13508.074843417853\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 15655.608983943239\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 6449.373272660158\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 22105.858841966838\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 279.9707958009094\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 330.18861047457904\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 155.02399621013512\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 456.26374787651\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 56.211422623311236\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 48.971994478870876\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 16.489917385121252\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 89.38328195763752\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 47.68421409962861\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 44.40725548192859\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 22.725253022223917\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 105.94675720203666\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.985911234781194\nINFO     sglang_benchmarks.shortfin_benchmark_test:shortfin_benchmark_test.py:107 Benchmark run successful\n::endgroup::\n\n--------------------------- Captured stderr teardown ---------------------------\n[2025-03-20 11:18:22] Shutting down\n[2025-03-20 11:18:22] Waiting for application shutdown.\n[2025-03-20 11:18:22] Application shutdown complete.\n[2025-03-20 11:18:22] Finished server process [6106]\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]", "duration": "00:03:59", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[1-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:03:59&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 1.00266695022583 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 2.004866600036621 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 3.0071165561676025 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 4.0092198848724365 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 5.011314392089844 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 6.013783693313599 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 7.0159149169921875 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 8.01796841621399 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 9.020066976547241 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 10.02217411994934 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 11.02425241470337 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 12.027359247207642 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 13.029553174972534 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 14.03156590461731 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 15.034062623977661 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 16.03642773628235 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 17.0384738445282 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 18.04106616973877 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 19.04327416419983 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 20.04538655281067 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 21.04768657684326 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 22.049915313720703 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 23.05325198173523 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 24.056416511535645 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 25.05891990661621 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 26.06113910675049 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 27.063483238220215 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 28.065561056137085 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 29.06821346282959 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 30.070515394210815 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 31.07270121574402 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 32.075226068496704 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 33.077229261398315 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 34.07929015159607 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 35.081684589385986 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 36.08431792259216 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 37.08643865585327 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 38.088993310928345 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 39.09138631820679 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 40.0938196182251 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 41.0965850353241 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 42.09892129898071 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 43.10166049003601 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 44.104382276535034 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 45.107157945632935 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 46.10989737510681 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 47.11316633224487 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 48.11527371406555 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 49.117371797561646 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 50.119621992111206 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 51.121819496154785 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 52.12413573265076 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 53.12658333778381 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 54.128745555877686 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 55.131009101867676 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 56.13321042060852 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 57.13540291786194 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 58.13743615150452 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 59.14023494720459 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 60.142250061035156 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 61.14427638053894 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 62.14622926712036 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 63.14827513694763 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 64.15071272850037 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 65.15289258956909 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 66.15527868270874 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 67.15727686882019 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 68.15942931175232 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 69.16214060783386 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 70.16529583930969 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 71.16796445846558 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 72.17095112800598 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 73.17346096038818 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 74.17697429656982 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 75.17975354194641 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 76.1827745437622 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 77.18604969978333 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 78.18822622299194 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 79.19027042388916 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 80.19232654571533 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 81.19458770751953 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 82.1974847316742 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 83.20026755332947 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 84.20270133018494 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 85.2052390575409 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 86.2080545425415 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 87.21006631851196 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 88.21247172355652 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 89.2151095867157 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 90.21756768226624 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 91.21995568275452 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 92.22266221046448 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 93.22488069534302 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 94.22727346420288 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 95.22935891151428 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 96.23134183883667 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 97.23350977897644 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 98.2359893321991 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 99.238924741745 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 100.24143290519714 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 101.24347591400146 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 102.24587512016296 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 103.2485179901123 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 104.2510404586792 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 105.25359392166138 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 106.25572633743286 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 107.25790691375732 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 108.26028442382812 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 109.26243138313293 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 110.26462292671204 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 111.26705527305603 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 112.26914978027344 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 113.27115249633789 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 114.27318835258484 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 115.27524447441101 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 116.27727937698364 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 117.27965188026428 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 118.28166723251343 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 119.28366827964783 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 120.28574967384338 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 121.28773331642151 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 122.28977870941162 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 123.29219603538513 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 124.2945294380188 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 125.29674291610718 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 126.29903149604797 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 127.30121874809265 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 128.30334997177124 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 129.30635452270508 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 130.30845046043396 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 131.31066608428955 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 132.31287670135498 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 133.31501245498657 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 134.3171570301056 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 135.31994700431824 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 136.3220181465149 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 137.32411885261536 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 138.32633328437805 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 139.3283805847168 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 140.33047342300415 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 141.33301615715027 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 142.3356535434723 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 143.33824062347412 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 144.34106588363647 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 145.34375762939453 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 146.34704065322876 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 147.34966039657593 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 148.35227870941162 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 149.3551061153412 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 150.35749435424805 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 151.35957551002502 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 152.36202549934387 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 153.36413955688477 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 154.36625170707703 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 155.3686535358429 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 156.37088871002197 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 157.37326979637146 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 158.37596154212952 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 159.3780825138092 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 160.38034749031067 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 161.38255381584167 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 162.3849663734436 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 163.38712859153748 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 164.38980793952942 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 165.3919813632965 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 166.39442205429077 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 167.39674639701843 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 168.39870619773865 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 169.40070486068726 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 170.40306687355042 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 171.40518236160278 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 172.40724754333496 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 173.4092733860016 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 174.41147875785828 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 175.4135901927948 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 176.41632342338562 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 177.41907954216003 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 178.42167472839355 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 179.42413878440857 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 180.42642259597778 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 181.42872047424316 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 182.43167352676392 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 183.43361568450928 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 184.43560004234314 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 185.43760633468628 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 186.4396517276764 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 187.44195342063904 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 188.44398665428162 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 189.44601774215698 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 190.44811940193176 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 191.45009064674377 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 192.45208930969238 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 193.45431756973267 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 194.4562954902649 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server has not started yet; waited 195.45825457572937 seconds; timeout: 600 seconds.\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf915-5ac002b40a72a71f3123ecf8;4e13be12-4c7f-4577-98a0-4eb5fc4995f1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\n\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 0.00/642M [00:00&amp;lt;?, ?B/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   0%|          | 3.19M/642M [00:00&amp;lt;00:20, 33.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   1%|          | 7.32M/642M [00:00&amp;lt;00:17, 39.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 11.0M/642M [00:00&amp;lt;00:18, 36.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   2%|\u258f         | 14.6M/642M [00:00&amp;lt;00:18, 36.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 18.0M/642M [00:00&amp;lt;00:19, 34.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   3%|\u258e         | 21.3M/642M [00:00&amp;lt;00:19, 32.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   4%|\u258d         | 24.5M/642M [00:00&amp;lt;00:20, 30.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   4%|\u258d         | 27.4M/642M [00:00&amp;lt;00:21, 29.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258d         | 30.2M/642M [00:01&amp;lt;00:23, 27.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   5%|\u258c         | 32.9M/642M [00:01&amp;lt;00:25, 25.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258c         | 35.3M/642M [00:01&amp;lt;00:26, 23.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258c         | 37.6M/642M [00:01&amp;lt;00:28, 22.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   6%|\u258c         | 39.7M/642M [00:01&amp;lt;00:29, 21.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 41.8M/642M [00:01&amp;lt;00:30, 20.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 43.7M/642M [00:01&amp;lt;00:31, 19.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 45.6M/642M [00:01&amp;lt;00:32, 19.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   7%|\u258b         | 47.4M/642M [00:01&amp;lt;00:33, 18.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 49.2M/642M [00:02&amp;lt;00:33, 18.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 51.0M/642M [00:02&amp;lt;00:33, 18.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 52.8M/642M [00:02&amp;lt;00:33, 18.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   8%|\u258a         | 54.5M/642M [00:02&amp;lt;00:33, 18.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u2589         | 56.3M/642M [00:02&amp;lt;00:33, 18.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u2589         | 58.0M/642M [00:02&amp;lt;00:33, 18.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:   9%|\u2589         | 59.7M/642M [00:02&amp;lt;00:35, 17.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2589         | 61.4M/642M [00:02&amp;lt;00:36, 16.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2589         | 63.0M/642M [00:02&amp;lt;00:37, 16.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 64.7M/642M [00:03&amp;lt;00:35, 16.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  10%|\u2588         | 66.6M/642M [00:03&amp;lt;00:34, 17.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588         | 68.7M/642M [00:03&amp;lt;00:31, 19.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588         | 71.1M/642M [00:03&amp;lt;00:28, 20.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  11%|\u2588\u258f        | 73.4M/642M [00:03&amp;lt;00:27, 21.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 75.6M/642M [00:03&amp;lt;00:27, 21.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 77.7M/642M [00:03&amp;lt;00:27, 21.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  12%|\u2588\u258f        | 79.7M/642M [00:03&amp;lt;00:28, 20.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 81.7M/642M [00:03&amp;lt;00:29, 19.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 83.6M/642M [00:03&amp;lt;00:32, 18.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  13%|\u2588\u258e        | 85.4M/642M [00:04&amp;lt;00:34, 16.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258e        | 87.0M/642M [00:04&amp;lt;00:39, 14.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 88.5M/642M [00:04&amp;lt;00:43, 13.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 89.9M/642M [00:04&amp;lt;00:42, 13.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 91.3M/642M [00:04&amp;lt;00:41, 13.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  14%|\u2588\u258d        | 92.8M/642M [00:04&amp;lt;00:40, 14.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258d        | 94.3M/642M [00:04&amp;lt;00:38, 14.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258d        | 95.8M/642M [00:04&amp;lt;00:38, 15.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258c        | 97.3M/642M [00:05&amp;lt;00:37, 15.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  15%|\u2588\u258c        | 98.7M/642M [00:05&amp;lt;00:38, 14.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 100M/642M [00:05&amp;lt;00:40, 14.0MB/s] \r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 101M/642M [00:05&amp;lt;00:42, 13.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 103M/642M [00:05&amp;lt;00:47, 11.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258c        | 104M/642M [00:05&amp;lt;00:52, 10.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  16%|\u2588\u258b        | 105M/642M [00:05&amp;lt;01:03, 8.90MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 106M/642M [00:06&amp;lt;01:17, 7.24MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 107M/642M [00:06&amp;lt;01:23, 6.71MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 107M/642M [00:06&amp;lt;01:21, 6.87MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 108M/642M [00:06&amp;lt;01:18, 7.10MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 109M/642M [00:06&amp;lt;01:15, 7.39MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 110M/642M [00:06&amp;lt;01:09, 8.06MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 111M/642M [00:06&amp;lt;01:02, 8.93MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  17%|\u2588\u258b        | 112M/642M [00:06&amp;lt;00:53, 10.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 114M/642M [00:06&amp;lt;00:46, 11.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 115M/642M [00:07&amp;lt;00:40, 13.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  18%|\u2588\u258a        | 118M/642M [00:07&amp;lt;00:34, 16.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u258a        | 120M/642M [00:07&amp;lt;00:29, 18.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  19%|\u2588\u2589        | 123M/642M [00:07&amp;lt;00:25, 21.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  20%|\u2588\u2589        | 125M/642M [00:07&amp;lt;00:23, 23.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  20%|\u2588\u2589        | 128M/642M [00:07&amp;lt;00:22, 24.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  20%|\u2588\u2588        | 131M/642M [00:07&amp;lt;00:21, 25.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 133M/642M [00:07&amp;lt;00:20, 26.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  21%|\u2588\u2588        | 136M/642M [00:07&amp;lt;00:19, 26.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 139M/642M [00:07&amp;lt;00:19, 27.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 141M/642M [00:08&amp;lt;00:18, 27.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  22%|\u2588\u2588\u258f       | 144M/642M [00:08&amp;lt;00:18, 28.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  23%|\u2588\u2588\u258e       | 147M/642M [00:08&amp;lt;00:18, 28.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  23%|\u2588\u2588\u258e       | 150M/642M [00:08&amp;lt;00:18, 28.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258e       | 152M/642M [00:08&amp;lt;00:18, 27.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  24%|\u2588\u2588\u258d       | 155M/642M [00:08&amp;lt;00:19, 26.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258d       | 157M/642M [00:08&amp;lt;00:19, 26.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258d       | 160M/642M [00:08&amp;lt;00:19, 26.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  25%|\u2588\u2588\u258c       | 163M/642M [00:08&amp;lt;00:18, 27.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  26%|\u2588\u2588\u258c       | 166M/642M [00:08&amp;lt;00:16, 30.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 170M/642M [00:09&amp;lt;00:15, 32.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 173M/642M [00:09&amp;lt;00:14, 32.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  27%|\u2588\u2588\u258b       | 176M/642M [00:09&amp;lt;00:14, 32.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 180M/642M [00:09&amp;lt;00:15, 31.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  28%|\u2588\u2588\u258a       | 183M/642M [00:09&amp;lt;00:15, 30.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  29%|\u2588\u2588\u2589       | 186M/642M [00:09&amp;lt;00:16, 29.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  29%|\u2588\u2588\u2589       | 188M/642M [00:09&amp;lt;00:16, 28.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  30%|\u2588\u2588\u2589       | 191M/642M [00:09&amp;lt;00:17, 27.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  30%|\u2588\u2588\u2588       | 194M/642M [00:09&amp;lt;00:18, 25.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588       | 196M/642M [00:10&amp;lt;00:30, 15.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588       | 198M/642M [00:10&amp;lt;00:27, 17.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  31%|\u2588\u2588\u2588\u258f      | 201M/642M [00:10&amp;lt;00:24, 18.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  32%|\u2588\u2588\u2588\u258f      | 204M/642M [00:10&amp;lt;00:21, 21.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  32%|\u2588\u2588\u2588\u258f      | 207M/642M [00:10&amp;lt;00:19, 23.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 210M/642M [00:10&amp;lt;00:16, 26.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  33%|\u2588\u2588\u2588\u258e      | 214M/642M [00:10&amp;lt;00:15, 29.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  34%|\u2588\u2588\u2588\u258d      | 217M/642M [00:10&amp;lt;00:13, 32.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  34%|\u2588\u2588\u2588\u258d      | 221M/642M [00:11&amp;lt;00:12, 34.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  35%|\u2588\u2588\u2588\u258c      | 225M/642M [00:11&amp;lt;00:11, 36.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258c      | 229M/642M [00:11&amp;lt;00:11, 38.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  36%|\u2588\u2588\u2588\u258b      | 233M/642M [00:11&amp;lt;00:10, 39.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  37%|\u2588\u2588\u2588\u258b      | 238M/642M [00:11&amp;lt;00:10, 40.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 241M/642M [00:11&amp;lt;00:10, 39.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  38%|\u2588\u2588\u2588\u258a      | 245M/642M [00:11&amp;lt;00:10, 39.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  39%|\u2588\u2588\u2588\u2589      | 251M/642M [00:11&amp;lt;00:09, 44.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  40%|\u2588\u2588\u2588\u2589      | 256M/642M [00:11&amp;lt;00:08, 47.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  41%|\u2588\u2588\u2588\u2588      | 261M/642M [00:12&amp;lt;00:08, 49.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  42%|\u2588\u2588\u2588\u2588\u258f     | 267M/642M [00:12&amp;lt;00:07, 52.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  43%|\u2588\u2588\u2588\u2588\u258e     | 273M/642M [00:12&amp;lt;00:06, 56.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  44%|\u2588\u2588\u2588\u2588\u258e     | 279M/642M [00:12&amp;lt;00:06, 58.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  45%|\u2588\u2588\u2588\u2588\u258d     | 286M/642M [00:12&amp;lt;00:05, 62.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  46%|\u2588\u2588\u2588\u2588\u258c     | 293M/642M [00:12&amp;lt;00:05, 66.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  47%|\u2588\u2588\u2588\u2588\u258b     | 300M/642M [00:12&amp;lt;00:05, 68.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  48%|\u2588\u2588\u2588\u2588\u258a     | 307M/642M [00:12&amp;lt;00:05, 65.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  49%|\u2588\u2588\u2588\u2588\u2589     | 313M/642M [00:12&amp;lt;00:05, 66.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  50%|\u2588\u2588\u2588\u2588\u2589     | 320M/642M [00:12&amp;lt;00:04, 67.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  51%|\u2588\u2588\u2588\u2588\u2588     | 327M/642M [00:13&amp;lt;00:04, 68.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 333M/642M [00:13&amp;lt;00:04, 68.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 340M/642M [00:13&amp;lt;00:04, 68.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 346M/642M [00:13&amp;lt;00:04, 68.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 353M/642M [00:13&amp;lt;00:04, 67.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 359M/642M [00:13&amp;lt;00:04, 67.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 366M/642M [00:13&amp;lt;00:04, 66.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 372M/642M [00:13&amp;lt;00:04, 66.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 379M/642M [00:13&amp;lt;00:04, 66.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 385M/642M [00:13&amp;lt;00:04, 65.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 391M/642M [00:14&amp;lt;00:04, 65.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 397M/642M [00:14&amp;lt;00:03, 64.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 403M/642M [00:14&amp;lt;00:03, 63.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 409M/642M [00:14&amp;lt;00:03, 63.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 416M/642M [00:14&amp;lt;00:03, 64.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 422M/642M [00:14&amp;lt;00:03, 65.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 429M/642M [00:14&amp;lt;00:03, 66.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 435M/642M [00:14&amp;lt;00:03, 66.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 442M/642M [00:14&amp;lt;00:03, 66.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 448M/642M [00:14&amp;lt;00:02, 67.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 455M/642M [00:15&amp;lt;00:02, 69.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 463M/642M [00:15&amp;lt;00:02, 71.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 470M/642M [00:15&amp;lt;00:02, 72.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 477M/642M [00:15&amp;lt;00:02, 74.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 484M/642M [00:15&amp;lt;00:02, 74.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 492M/642M [00:15&amp;lt;00:02, 71.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 499M/642M [00:15&amp;lt;00:02, 72.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 506M/642M [00:15&amp;lt;00:01, 72.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 513M/642M [00:15&amp;lt;00:01, 73.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 520M/642M [00:15&amp;lt;00:01, 73.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 527M/642M [00:16&amp;lt;00:01, 72.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 534M/642M [00:16&amp;lt;00:01, 72.7MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 541M/642M [00:16&amp;lt;00:01, 72.5MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 547M/642M [00:16&amp;lt;00:01, 72.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 554M/642M [00:16&amp;lt;00:01, 71.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 561M/642M [00:16&amp;lt;00:01, 72.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 568M/642M [00:16&amp;lt;00:01, 72.1MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 575M/642M [00:16&amp;lt;00:00, 72.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 582M/642M [00:16&amp;lt;00:00, 73.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 589M/642M [00:16&amp;lt;00:00, 72.6MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 596M/642M [00:17&amp;lt;00:00, 72.4MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 603M/642M [00:17&amp;lt;00:00, 71.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 610M/642M [00:17&amp;lt;00:00, 71.3MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 617M/642M [00:17&amp;lt;00:00, 70.9MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 624M/642M [00:17&amp;lt;00:00, 70.2MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 630M/642M [00:17&amp;lt;00:00, 69.8MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 637M/642M [00:17&amp;lt;00:00, 69.0MB/s]\r/tmp/ShareGPT_V3_unfiltered_cleaned_split.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 642M/642M [00:17&amp;lt;00:00, 37.9MB/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:02&amp;lt;00:18,  2.09s/it]\r 20%|\u2588\u2588        | 2/10 [00:02&amp;lt;00:07,  1.01it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:04,  1.52it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:04,  1.43it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:04&amp;lt;00:04,  1.15it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:06&amp;lt;00:05,  1.40s/it]\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:07&amp;lt;00:03,  1.06s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:07&amp;lt;00:01,  1.28it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:08&amp;lt;00:00,  1.18it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.61it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:08&amp;lt;00:00,  1.17it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    1         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  8.58      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.17      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          228.48    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         323.38    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          551.86    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             3.86      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3312.36   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 3600.66   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          30.14     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        25.73     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           47.64     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          11.68     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        12.12     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           13.28     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           11.87     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.11     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            14.30     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 40.29664969444275 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 1\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 8.578271247912198\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.1657360452939542\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 228.48426487761503\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 323.3751789645429\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3312.3579101171345\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 3600.6605725269765\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1926.2381540923516\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6121.07301609125\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 30.13788848184049\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 25.72560403496027\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 9.818946591227613\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 47.643962809816\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 11.677639983440558\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 12.119519966059833\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.4310267682373232\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 13.279755221835565\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 11.874874702327267\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.108348473906517\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.875125741040975\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 14.299514270387585\nINFO:sglang_benchmarks.utils:CONCURRENCY: 3.8613350107380957\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 0 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 1.00266695022583 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 2.004866600036621 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 3.0071165561676025 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 4.0092198848724365 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 5.011314392089844 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 6.013783693313599 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 7.0159149169921875 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 8.01796841621399 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 9.020066976547241 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 10.02217411994934 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 11.02425241470337 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 12.027359247207642 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 13.029553174972534 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 14.03156590461731 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 15.034062623977661 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 16.03642773628235 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 17.0384738445282 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 18.04106616973877 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 19.04327416419983 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 20.04538655281067 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 21.04768657684326 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 22.049915313720703 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 23.05325198173523 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 24.056416511535645 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 25.05891990661621 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 26.06113910675049 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 27.063483238220215 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 28.065561056137085 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 29.06821346282959 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 30.070515394210815 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 31.07270121574402 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 32.075226068496704 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 33.077229261398315 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 34.07929015159607 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 35.081684589385986 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 36.08431792259216 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 37.08643865585327 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 38.088993310928345 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 39.09138631820679 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 40.0938196182251 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 41.0965850353241 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 42.09892129898071 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 43.10166049003601 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 44.104382276535034 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 45.107157945632935 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 46.10989737510681 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 47.11316633224487 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 48.11527371406555 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 49.117371797561646 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 50.119621992111206 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 51.121819496154785 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 52.12413573265076 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 53.12658333778381 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 54.128745555877686 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 55.131009101867676 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 56.13321042060852 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 57.13540291786194 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 58.13743615150452 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 59.14023494720459 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 60.142250061035156 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 61.14427638053894 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 62.14622926712036 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 63.14827513694763 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 64.15071272850037 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 65.15289258956909 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 66.15527868270874 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 67.15727686882019 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 68.15942931175232 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 69.16214060783386 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 70.16529583930969 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 71.16796445846558 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 72.17095112800598 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 73.17346096038818 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 74.17697429656982 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 75.17975354194641 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 76.1827745437622 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 77.18604969978333 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 78.18822622299194 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 79.19027042388916 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 80.19232654571533 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 81.19458770751953 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 82.1974847316742 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 83.20026755332947 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 84.20270133018494 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 85.2052390575409 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 86.2080545425415 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 87.21006631851196 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 88.21247172355652 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 89.2151095867157 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 90.21756768226624 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 91.21995568275452 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 92.22266221046448 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 93.22488069534302 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 94.22727346420288 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 95.22935891151428 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 96.23134183883667 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 97.23350977897644 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 98.2359893321991 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 99.238924741745 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 100.24143290519714 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 101.24347591400146 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 102.24587512016296 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 103.2485179901123 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 104.2510404586792 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 105.25359392166138 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 106.25572633743286 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 107.25790691375732 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 108.26028442382812 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 109.26243138313293 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 110.26462292671204 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 111.26705527305603 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 112.26914978027344 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 113.27115249633789 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 114.27318835258484 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 115.27524447441101 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 116.27727937698364 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 117.27965188026428 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 118.28166723251343 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 119.28366827964783 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 120.28574967384338 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 121.28773331642151 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 122.28977870941162 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 123.29219603538513 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 124.2945294380188 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 125.29674291610718 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 126.29903149604797 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 127.30121874809265 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 128.30334997177124 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 129.30635452270508 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 130.30845046043396 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 131.31066608428955 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 132.31287670135498 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 133.31501245498657 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 134.3171570301056 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 135.31994700431824 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 136.3220181465149 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 137.32411885261536 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 138.32633328437805 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 139.3283805847168 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 140.33047342300415 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 141.33301615715027 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 142.3356535434723 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 143.33824062347412 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 144.34106588363647 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 145.34375762939453 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 146.34704065322876 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 147.34966039657593 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 148.35227870941162 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 149.3551061153412 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 150.35749435424805 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 151.35957551002502 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 152.36202549934387 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 153.36413955688477 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 154.36625170707703 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 155.3686535358429 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 156.37088871002197 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 157.37326979637146 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 158.37596154212952 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 159.3780825138092 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 160.38034749031067 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 161.38255381584167 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 162.3849663734436 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 163.38712859153748 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 164.38980793952942 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 165.3919813632965 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 166.39442205429077 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 167.39674639701843 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 168.39870619773865 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 169.40070486068726 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 170.40306687355042 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 171.40518236160278 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 172.40724754333496 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 173.4092733860016 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 174.41147875785828 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 175.4135901927948 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 176.41632342338562 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 177.41907954216003 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 178.42167472839355 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 179.42413878440857 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 180.42642259597778 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 181.42872047424316 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 182.43167352676392 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 183.43361568450928 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 184.43560004234314 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 185.43760633468628 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 186.4396517276764 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 187.44195342063904 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 188.44398665428162 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 189.44601774215698 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 190.44811940193176 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 191.45009064674377 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 192.45208930969238 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 193.45431756973267 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 194.4562954902649 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:54 Server has not started yet; waited 195.45825457572937 seconds; timeout: 600 seconds.\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0\nRequest Rate: 1\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf915-5ac002b40a72a71f3123ecf8;4e13be12-4c7f-4577-98a0-4eb5fc4995f1)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0&amp;#x27;, request_rate=1, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test0/sglang_10_1.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Downloading from https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json to /tmp/ShareGPT_V3_unfiltered_cleaned_split.json\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    1         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  8.58      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.17      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          228.48    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         323.38    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          551.86    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             3.86      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3312.36   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 3600.66   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          30.14     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        25.73     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           47.64     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          11.68     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        12.12     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           13.28     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           11.87     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.11     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            14.30     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 40.29664969444275 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 1\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 8.578271247912198\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.1657360452939542\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 228.48426487761503\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 323.3751789645429\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3312.3579101171345\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 3600.6605725269765\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1926.2381540923516\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6121.07301609125\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 30.13788848184049\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 25.72560403496027\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 9.818946591227613\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 47.643962809816\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 11.677639983440558\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 12.119519966059833\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.4310267682373232\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 13.279755221835565\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 11.874874702327267\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.108348473906517\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.875125741040975\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 14.299514270387585\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 3.8613350107380957\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:13", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[2-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:13&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf93e-6d3cd6961022be0760c43900;d78ea698-c360-4f4c-8007-07da1eeb13de)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:01&amp;lt;00:11,  1.28s/it]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:06,  1.06it/s]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.19it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.56it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.13s/it]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:06&amp;lt;00:01,  1.60it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.48it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.54it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:07&amp;lt;00:00,  1.33it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    2         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  7.53      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.33      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          260.15    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         368.19    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          628.34    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             4.71      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3546.63   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 3954.50   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          28.14     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        21.98     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           48.36     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.03     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        12.95     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           15.18     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           12.73     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.24     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            27.91     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 12.232987403869629 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 2\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 7.534137615002692\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.3272919225801036\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 260.1492168257003\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 368.1907793237208\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3546.6322272550315\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 3954.503254732117\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1934.53057894452\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6256.093019274995\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 28.141577215865254\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 21.98053477331996\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 11.11223622497831\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 48.361238641664386\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.030834273726564\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 12.95019947276076\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 0.9424368524963915\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 15.1819491121867\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 12.72969133259025\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.236684957519174\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.8375144747971945\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 27.910512373782694\nINFO:sglang_benchmarks.utils:CONCURRENCY: 4.707416307597886\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1\nRequest Rate: 2\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf93e-6d3cd6961022be0760c43900;d78ea698-c360-4f4c-8007-07da1eeb13de)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1&amp;#x27;, request_rate=2, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test1/sglang_10_2.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    2         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  7.53      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.33      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          260.15    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         368.19    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          628.34    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             4.71      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3546.63   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 3954.50   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          28.14     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        21.98     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           48.36     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.03     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        12.95     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           15.18     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           12.73     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.24     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            27.91     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 12.232987403869629 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 2\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 7.534137615002692\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.3272919225801036\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 260.1492168257003\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 368.1907793237208\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3546.6322272550315\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 3954.503254732117\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1934.53057894452\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6256.093019274995\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 28.141577215865254\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 21.98053477331996\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 11.11223622497831\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 48.361238641664386\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.030834273726564\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 12.95019947276076\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 0.9424368524963915\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 15.1819491121867\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 12.72969133259025\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.236684957519174\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.8375144747971945\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 27.910512373782694\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 4.707416307597886\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[4-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf94b-3b1876b735b6ae1a4f759b19;3cab2176-926c-4b46-9aa6-a4dbabf97702)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:06,  1.31it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:03,  2.51it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:08,  1.27s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.18it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.59it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:04,  1.03s/it]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06&amp;lt;00:00,  1.77it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.64it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.43it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    4         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.97      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.43      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          281.18    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         397.96    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          679.14    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.22      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3635.74   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4095.19   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          31.00     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        26.49     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           53.64     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.68     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.38     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           16.57     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.04     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.26     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            28.63     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 11.265276432037354 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 4\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.970601992215961\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.4345963248463982\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 281.18087966989407\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 397.9570205123909\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3635.736527480185\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4095.1919134240597\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1932.782098808797\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6286.875084945932\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 30.99737288430333\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 26.49038122035563\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 12.145588135093945\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 53.640570966526866\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.684464672708474\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.379467107048796\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 1.2743857204160336\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 16.56705779789481\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.041732656397464\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.263910310342908\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 2.8463498342965754\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 28.628017739392817\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.21581426043288\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2\nRequest Rate: 4\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf94b-3b1876b735b6ae1a4f759b19;3cab2176-926c-4b46-9aa6-a4dbabf97702)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2&amp;#x27;, request_rate=4, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test2/sglang_10_4.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    4         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.97      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.43      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          281.18    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         397.96    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          679.14    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.22      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3635.74   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4095.19   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          31.00     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        26.49     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           53.64     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.68     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.38     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           16.57     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.04     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.26     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            28.63     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 11.265276432037354 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 4\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.970601992215961\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.4345963248463982\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 281.18087966989407\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 397.9570205123909\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3635.736527480185\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4095.1919134240597\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1932.782098808797\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6286.875084945932\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 30.99737288430333\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 26.49038122035563\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 12.145588135093945\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 53.640570966526866\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.684464672708474\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.379467107048796\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 1.2743857204160336\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 16.56705779789481\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.041732656397464\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.263910310342908\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 2.8463498342965754\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 28.628017739392817\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.21581426043288\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[8-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf957-19588b563e186fb11401b648;de90cd42-0c86-4bd7-ad0a-d58fbc2639c7)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:04,  2.00it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.05it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.31s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.19it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.52it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:05&amp;lt;00:03,  1.10it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&amp;lt;00:00,  1.97it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.69it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.51it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    8         \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.62      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.51      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          296.03    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         418.98    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          715.01    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.50      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3639.98   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4115.60   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          28.44     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        22.86     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           51.03     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.24     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.44     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           19.82     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.07     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.21     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            24.42     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 10.943174839019775 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 8\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.620881195645779\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.5103729706819837\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 296.0331022536688\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 418.9774620671823\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3639.982203254476\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4115.602237870917\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1901.0924798901913\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6230.871478030458\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 28.440125659108162\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 22.861354518681765\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 12.190465560339884\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 51.03413179516792\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.241066020139476\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.44301447759013\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 2.328987581545324\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 19.81525727987755\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.066344202378854\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.214727863669395\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.3998437727432838\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 24.41754781641019\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.497730733559015\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3\nRequest Rate: 8\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf957-19588b563e186fb11401b648;de90cd42-0c86-4bd7-ad0a-d58fbc2639c7)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3&amp;#x27;, request_rate=8, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test3/sglang_10_8.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    8         \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.62      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.51      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          296.03    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         418.98    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          715.01    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.50      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3639.98   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4115.60   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          28.44     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        22.86     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           51.03     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.24     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.44     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           19.82     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.07     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.21     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            24.42     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 10.943174839019775 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 8\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.620881195645779\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.5103729706819837\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 296.0331022536688\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 418.9774620671823\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3639.982203254476\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4115.602237870917\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1901.0924798901913\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6230.871478030458\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 28.440125659108162\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 22.861354518681765\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 12.190465560339884\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 51.03413179516792\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.241066020139476\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.44301447759013\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 2.328987581545324\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 19.81525727987755\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.066344202378854\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.214727863669395\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.3998437727432838\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 24.41754781641019\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.497730733559015\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:12", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[16-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:12&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf962-43ea13043503cb3a0124d6d8;f1764748-c8ab-450d-a752-a9f86822295b)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:03,  2.91it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:02,  3.68it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:03&amp;lt;00:09,  1.29s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.11it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.47it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:03,  1.15it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05&amp;lt;00:00,  2.14it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&amp;lt;00:00,  2.04it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.64it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.54it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    16        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.49      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.54      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          301.95    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         427.35    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          729.30    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.64      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3658.70   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4156.39   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          33.30     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        31.60     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           46.75     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          14.17     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.52     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           19.54     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           13.12     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.30     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            14.06     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 10.98160719871521 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 16\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.49115967284888\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.5405567732107779\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 301.9491275493125\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 427.3504488886698\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3658.7022996041924\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4156.390079529956\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1916.4906505429503\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6249.113982436247\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 33.30205390229821\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 31.600447604432702\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 10.16979934543416\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 46.750304233282804\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 14.174794525952244\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.523927642860645\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 2.1486738842378834\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 19.542253587790768\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 13.116482176073973\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.304025400429964\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.471583120338111\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 14.055514326319097\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.6364386088170875\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4\nRequest Rate: 16\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf962-43ea13043503cb3a0124d6d8;f1764748-c8ab-450d-a752-a9f86822295b)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4&amp;#x27;, request_rate=16, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test4/sglang_10_16.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    16        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.49      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.54      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          301.95    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         427.35    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          729.30    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.64      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3658.70   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4156.39   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          33.30     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        31.60     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           46.75     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          14.17     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.52     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           19.54     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           13.12     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.30     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            14.06     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 10.98160719871521 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 16\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.49115967284888\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.5405567732107779\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 301.9491275493125\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 427.3504488886698\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3658.7022996041924\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4156.390079529956\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1916.4906505429503\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6249.113982436247\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 33.30205390229821\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 31.600447604432702\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 10.16979934543416\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 46.750304233282804\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 14.174794525952244\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.523927642860645\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 2.1486738842378834\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 19.542253587790768\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 13.116482176073973\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.304025400429964\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.471583120338111\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 14.055514326319097\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.6364386088170875\n\n"}], "reports/sglang_index.html:app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]": [{"extras": [], "result": "Passed", "testId": "app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]", "duration": "00:00:11", "resultsTableRow": ["&lt;td class=\"col-result\"&gt;Passed&lt;/td&gt;", "&lt;td class=\"col-testId\"&gt;app_tests/benchmark_tests/llm/sglang_benchmarks/sglang_benchmark_test.py::test_sglang_benchmark[32-NousResearch/Meta-Llama-3-8B]&lt;/td&gt;", "&lt;td class=\"col-duration\"&gt;00:00:11&lt;/td&gt;", "&lt;td class=\"col-links\"&gt;&lt;/td&gt;"], "log": "----------------------------- Captured stderr call -----------------------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO:sglang_benchmarks.sglang_benchmark_test:Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO:sglang_benchmarks.sglang_benchmark_test:Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO:sglang_benchmarks.sglang_benchmark_test:Beginning SGLang benchmark test...\nINFO:sglang_benchmarks.sglang_benchmark_test:Waiting for server to start at http://localhost:30000...\nINFO:sglang_benchmarks.sglang_benchmark_test:Server successfully started\nINFO:sglang_benchmarks.sglang_benchmark_test:Running SGLang Benchmark with the following args:\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO:sglang_benchmarks.sglang_benchmark_test:Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf96e-5dcbbe284cbbd715161e8432;d9a485b0-f3e3-4efa-9b67-3950a3ba8d61)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO:sglang_benchmarks.sglang_benchmark_test:\nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO:sglang_benchmarks.sglang_benchmark_test:Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO:sglang_benchmarks.sglang_benchmark_test:#Input tokens: 1960\nINFO:sglang_benchmarks.sglang_benchmark_test:#Output tokens: 2774\nINFO:sglang_benchmarks.sglang_benchmark_test:Starting initial single prompt test run...\nINFO:sglang_benchmarks.sglang_benchmark_test:Initial test run completed. Starting main benchmark run...\n\r  0%|          | 0/10 [00:00&amp;lt;?, ?it/s]\r 10%|\u2588         | 1/10 [00:00&amp;lt;00:02,  3.71it/s]\r 20%|\u2588\u2588        | 2/10 [00:00&amp;lt;00:01,  4.17it/s]\r 30%|\u2588\u2588\u2588       | 3/10 [00:02&amp;lt;00:08,  1.26s/it]\r 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03&amp;lt;00:05,  1.10it/s]\r 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03&amp;lt;00:03,  1.47it/s]\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04&amp;lt;00:03,  1.19it/s]\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:04&amp;lt;00:00,  2.19it/s]\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:05&amp;lt;00:00,  2.09it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.65it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06&amp;lt;00:00,  1.57it/s]\nINFO:sglang_benchmarks.sglang_benchmark_test:\n============ Serving Benchmark Result ============\nINFO:sglang_benchmarks.sglang_benchmark_test:Backend:                                 sglang    \nINFO:sglang_benchmarks.sglang_benchmark_test:Traffic request rate:                    32        \nINFO:sglang_benchmarks.sglang_benchmark_test:Max reqeuest concurrency:                not set   \nINFO:sglang_benchmarks.sglang_benchmark_test:Successful requests:                     10        \nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark duration (s):                  6.37      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total input tokens:                      1960      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens:                  2774      \nINFO:sglang_benchmarks.sglang_benchmark_test:Total generated tokens (retokenized):    362       \nINFO:sglang_benchmarks.sglang_benchmark_test:Request throughput (req/s):              1.57      \nINFO:sglang_benchmarks.sglang_benchmark_test:Input token throughput (tok/s):          307.59    \nINFO:sglang_benchmarks.sglang_benchmark_test:Output token throughput (tok/s):         435.33    \nINFO:sglang_benchmarks.sglang_benchmark_test:Total token throughput (tok/s):          742.92    \nINFO:sglang_benchmarks.sglang_benchmark_test:Concurrency:                             5.70      \nINFO:sglang_benchmarks.sglang_benchmark_test:----------------End-to-End Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean E2E Latency (ms):                   3632.79   \nINFO:sglang_benchmarks.sglang_benchmark_test:Median E2E Latency (ms):                 4129.51   \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Time to First Token----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TTFT (ms):                          53.45     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TTFT (ms):                        50.48     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TTFT (ms):                           80.05     \nINFO:sglang_benchmarks.sglang_benchmark_test:-----Time per Output Token (excl. 1st token)------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean TPOT (ms):                          13.47     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median TPOT (ms):                        13.38     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 TPOT (ms):                           15.20     \nINFO:sglang_benchmarks.sglang_benchmark_test:---------------Inter-token Latency----------------\nINFO:sglang_benchmarks.sglang_benchmark_test:Mean ITL (ms):                           12.95     \nINFO:sglang_benchmarks.sglang_benchmark_test:Median ITL (ms):                         13.22     \nINFO:sglang_benchmarks.sglang_benchmark_test:P99 ITL (ms):                            13.74     \nINFO:sglang_benchmarks.sglang_benchmark_test:==================================================\nINFO:sglang_benchmarks.sglang_benchmark_test:Benchmark run completed in 10.785272359848022 seconds\nINFO:sglang_benchmarks.sglang_benchmark_test:======== RESULTS ========\nINFO:sglang_benchmarks.utils:BACKEND: sglang\nINFO:sglang_benchmarks.utils:DATASET_NAME: sharegpt\nINFO:sglang_benchmarks.utils:REQUEST_RATE: 32\nINFO:sglang_benchmarks.utils:MAX_CONCURRENCY: None\nINFO:sglang_benchmarks.utils:SHAREGPT_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_INPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_OUTPUT_LEN: None\nINFO:sglang_benchmarks.utils:RANDOM_RANGE_RATIO: 0.0\nINFO:sglang_benchmarks.utils:DURATION: 6.372122602071613\nINFO:sglang_benchmarks.utils:COMPLETED: 10\nINFO:sglang_benchmarks.utils:TOTAL_INPUT_TOKENS: 1960\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS: 2774\nINFO:sglang_benchmarks.utils:TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO:sglang_benchmarks.utils:REQUEST_THROUGHPUT: 1.5693357809451036\nINFO:sglang_benchmarks.utils:INPUT_THROUGHPUT: 307.58981306524026\nINFO:sglang_benchmarks.utils:OUTPUT_THROUGHPUT: 435.3337456341717\nINFO:sglang_benchmarks.utils:MEAN_E2E_LATENCY_MS: 3632.7949879225343\nINFO:sglang_benchmarks.utils:MEDIAN_E2E_LATENCY_MS: 4129.508885089308\nINFO:sglang_benchmarks.utils:STD_E2E_LATENCY_MS: 1907.6543276648388\nINFO:sglang_benchmarks.utils:P99_E2E_LATENCY_MS: 6208.044861233794\nINFO:sglang_benchmarks.utils:MEAN_TTFT_MS: 53.45029593445361\nINFO:sglang_benchmarks.utils:MEDIAN_TTFT_MS: 50.48442631959915\nINFO:sglang_benchmarks.utils:STD_TTFT_MS: 19.41811759920831\nINFO:sglang_benchmarks.utils:P99_TTFT_MS: 80.05108614917845\nINFO:sglang_benchmarks.utils:MEAN_TPOT_MS: 13.468651119442875\nINFO:sglang_benchmarks.utils:MEDIAN_TPOT_MS: 13.383273391438959\nINFO:sglang_benchmarks.utils:STD_TPOT_MS: 0.9418808353365906\nINFO:sglang_benchmarks.utils:P99_TPOT_MS: 15.19918827447109\nINFO:sglang_benchmarks.utils:MEAN_ITL_MS: 12.949856524470272\nINFO:sglang_benchmarks.utils:MEDIAN_ITL_MS: 13.219444314017892\nINFO:sglang_benchmarks.utils:STD_ITL_MS: 3.3676791048329657\nINFO:sglang_benchmarks.utils:P99_ITL_MS: 13.737927605397998\nINFO:sglang_benchmarks.utils:CONCURRENCY: 5.701075159384868\n\n------------------------------ Captured log call -------------------------------\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:32 Preparing tokenizer_path: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:34 Downloading tokenizer NousResearch/Meta-Llama-3-8B from Hugging Face...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:39 Tokenizer saved to /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/tokenizer.json\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:71 Beginning SGLang benchmark test...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:45 Waiting for server to start at http://localhost:30000...\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:51 Server successfully started\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:93 Running SGLang Benchmark with the following args:\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:94 Backend: sglang\nBase URL: http://localhost:30000\nNum Prompt: 10\nTokenizer: /tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5\nRequest Rate: 32\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Fail to load tokenizer config with error=You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n401 Client Error. (Request ID: Root=1-67dbf96e-5dcbbe284cbbd715161e8432;d9a485b0-f3e3-4efa-9b67-3950a3ba8d61)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \nWARNING It is recommended to use the `Chat` or `Instruct` model for benchmarking.\nBecause when the tokenizer counts the output tokens, if there is gibberish, it might count incorrectly.\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Namespace(num_prompts=10, base_url=&amp;#x27;http://localhost:30000&amp;#x27;, tokenizer=&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5&amp;#x27;, request_rate=32, backend=&amp;#x27;sglang&amp;#x27;, output_file=PosixPath(&amp;#x27;/tmp/pytest-of-runner/pytest-0/sglang_benchmark_test5/sglang_10_32.jsonl&amp;#x27;), seed=1, extra_request_body=None, port=8000, model=&amp;#x27;meta-llama/Llama-3.1-8B-Instruct&amp;#x27;, dataset_name=&amp;#x27;sharegpt&amp;#x27;, random_input_len=None, random_output_len=None, random_range_ratio=0.0, dataset_path=&amp;#x27;&amp;#x27;, sharegpt_output_len=None, multi=False, disable_tqdm=False, disable_stream=False, disable_ignore_eos=False, lora_name=None, profile=False, sharegpt_context_len=None, apply_chat_template=False, return_logprob=False, max_concurrency=None)\n\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Input tokens: 1960\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 #Output tokens: 2774\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Starting initial single prompt test run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Initial test run completed. Starting main benchmark run...\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 \n============ Serving Benchmark Result ============\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Backend:                                 sglang    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Traffic request rate:                    32        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Max reqeuest concurrency:                not set   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Successful requests:                     10        \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Benchmark duration (s):                  6.37      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total input tokens:                      1960      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens:                  2774      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total generated tokens (retokenized):    362       \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Request throughput (req/s):              1.57      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Input token throughput (tok/s):          307.59    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Output token throughput (tok/s):         435.33    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Total token throughput (tok/s):          742.92    \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Concurrency:                             5.70      \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ----------------End-to-End Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean E2E Latency (ms):                   3632.79   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median E2E Latency (ms):                 4129.51   \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Time to First Token----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TTFT (ms):                          53.45     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TTFT (ms):                        50.48     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TTFT (ms):                           80.05     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 -----Time per Output Token (excl. 1st token)------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean TPOT (ms):                          13.47     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median TPOT (ms):                        13.38     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 TPOT (ms):                           15.20     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ---------------Inter-token Latency----------------\nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Mean ITL (ms):                           12.95     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 Median ITL (ms):                         13.22     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 P99 ITL (ms):                            13.74     \nINFO     sglang_benchmarks.sglang_benchmark_test:mock.py:1189 ==================================================\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:102 Benchmark run completed in 10.785272359848022 seconds\nINFO     sglang_benchmarks.sglang_benchmark_test:sglang_benchmark_test.py:103 ======== RESULTS ========\nINFO     sglang_benchmarks.utils:utils.py:74 BACKEND: sglang\nINFO     sglang_benchmarks.utils:utils.py:74 DATASET_NAME: sharegpt\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_RATE: 32\nINFO     sglang_benchmarks.utils:utils.py:74 MAX_CONCURRENCY: None\nINFO     sglang_benchmarks.utils:utils.py:74 SHAREGPT_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_INPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_OUTPUT_LEN: None\nINFO     sglang_benchmarks.utils:utils.py:74 RANDOM_RANGE_RATIO: 0.0\nINFO     sglang_benchmarks.utils:utils.py:74 DURATION: 6.372122602071613\nINFO     sglang_benchmarks.utils:utils.py:74 COMPLETED: 10\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_INPUT_TOKENS: 1960\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS: 2774\nINFO     sglang_benchmarks.utils:utils.py:74 TOTAL_OUTPUT_TOKENS_RETOKENIZED: 362\nINFO     sglang_benchmarks.utils:utils.py:74 REQUEST_THROUGHPUT: 1.5693357809451036\nINFO     sglang_benchmarks.utils:utils.py:74 INPUT_THROUGHPUT: 307.58981306524026\nINFO     sglang_benchmarks.utils:utils.py:74 OUTPUT_THROUGHPUT: 435.3337456341717\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_E2E_LATENCY_MS: 3632.7949879225343\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_E2E_LATENCY_MS: 4129.508885089308\nINFO     sglang_benchmarks.utils:utils.py:74 STD_E2E_LATENCY_MS: 1907.6543276648388\nINFO     sglang_benchmarks.utils:utils.py:74 P99_E2E_LATENCY_MS: 6208.044861233794\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TTFT_MS: 53.45029593445361\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TTFT_MS: 50.48442631959915\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TTFT_MS: 19.41811759920831\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TTFT_MS: 80.05108614917845\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_TPOT_MS: 13.468651119442875\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_TPOT_MS: 13.383273391438959\nINFO     sglang_benchmarks.utils:utils.py:74 STD_TPOT_MS: 0.9418808353365906\nINFO     sglang_benchmarks.utils:utils.py:74 P99_TPOT_MS: 15.19918827447109\nINFO     sglang_benchmarks.utils:utils.py:74 MEAN_ITL_MS: 12.949856524470272\nINFO     sglang_benchmarks.utils:utils.py:74 MEDIAN_ITL_MS: 13.219444314017892\nINFO     sglang_benchmarks.utils:utils.py:74 STD_ITL_MS: 3.3676791048329657\nINFO     sglang_benchmarks.utils:utils.py:74 P99_ITL_MS: 13.737927605397998\nINFO     sglang_benchmarks.utils:utils.py:74 CONCURRENCY: 5.701075159384868\n\n"}]}, "renderCollapsed": ["passed"], "initialSort": "result", "title": "shortfin_index.html"}' id="data-container"></div>
<script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
</footer>
</html>