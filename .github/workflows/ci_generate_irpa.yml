# Copyright 2025 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: Release Generate IRPA for models

on:
  workflow_dispatch:
  schedule:
    # Runs on Saturday only
    - cron: "0 9 * * 5"

concurrency:
  # A PR number if a pull request and otherwise the commit hash. This cancels
  # queued and in-progress runs for the same PR (presubmit) or commit
  # (postsubmit). The workflow name is prepended to avoid conflicts between
  # different workflows.
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  test_sdxl_flux_serving:
    if: ${{ github.repository_owner == 'nod-ai' || github.event_name != 'schedule' }}
    timeout-minutes: 240
    name: "Release: Generate IRPA for models"
    strategy:
      matrix:
        version: [3.11]
      fail-fast: false
    runs-on: linux-mi325-1gpu-ossci-nod-ai
    defaults:
      run:
        shell: bash
    env:
      VENV_DIR: ${{ github.workspace }}/.venv
      HF_HOME: "/amdshark-cache/data/huggingface"
      HF_TOKEN: ${{ secrets.HF_FLUX_TOKEN }}
      MODEL_TAG: ""
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: ${{matrix.version}}
      - name: Create Python venv
        run: |
          python -m venv ${VENV_DIR}
          source ${VENV_DIR}/bin/activate

      - name: Install pip deps
        run: |
          bash scripts/setenv.sh --nightly
          mkdir -p output_artifacts

      # Llama 8B FP16 irpa export, compile and validate
      - name: Export 8B-FP16 instruct model
        id: export_irpa_llama_8b_fp16
        continue-on-error: true
        run: |
          set -e  # Exit on any error
          export MODEL_TAG="llama3_8b_fp16"
          echo $MODEL_TAG
          # Export 8B-FP16 instruct model
          echo "=== Exporting 8B-FP16 instruct model ==="
          bash scripts/download_export_irpa.sh \
                  --model Llama-3.1-8B-Instruct \
                  --hf-token ${HF_TOKEN} || { echo "Export failed"; exit 1; }

          # Run export and compile
          echo "=== Running export and compile ==="
          bash scripts/export_and_compile.sh \
                --irpa  /shark-dev/8b/instruct/weights/llama3.1_8b_instruct_fp16.irpa \
                --bs-prefill 4 --bs-decode 4 2>&1 | tee "$(pwd)/output_artifacts/${MODEL_TAG}_export_and_compilation.log" || { echo "Compilation failed"; exit 1; }

          # Validate VMFB Responses
          echo "=== Validating VMFB Responses ==="
          bash scripts/validate_numerics.sh \
            --irpa /shark-dev/8b/instruct/weights/llama3.1_8b_instruct_fp16.irpa \
            --vmfb $(pwd)/output_artifacts/output.vmfb \
            --config $(pwd)/output_artifacts/config_attn.json \
            --tokenizer /shark-dev/8b/instruct/tokenizer.json \
            --tokenizer_config /shark-dev/8b/instruct/tokenizer_config.json \
            --steps 64 \
            --kv-cache-dtype float16 | tee "$(pwd)/output_artifacts/${MODEL_TAG}_run_llm_vmfb.log" || { echo "Validation failed"; }

          # Check for IRPA changes
          echo "=== Checking for IRPA changes ==="
          echo "Downloading latest IRPA file from Azure"
          az storage blob download \
            --account-name sharkpublic \
            --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
            --container-name ossci \
            --name ossci-models/llama_3_1/instruct_8b_fp16.irpa \
            --file instruct_8b_fp16_previous.irpa \
            --no-progress || echo "No previous IRPA file found, will upload new file"

          UPLOAD_REQUIRED=false
          if [ -f instruct_8b_fp16_previous.irpa ]; then
            echo "Comparing IRPA files"
            if ! diff -q /shark-dev/8b/instruct/weights/llama3.1_8b_instruct_fp16.irpa instruct_8b_fp16_previous.irpa > /dev/null 2>&1; then
              echo "IRPA files differ, upload required"
              UPLOAD_REQUIRED=true
            else
              echo "IRPA files are identical, skipping upload"
            fi
          else
            echo "No previous IRPA file found, upload required"
            UPLOAD_REQUIRED=true
          fi

          # Upload IRPA file if required
          if [ "$UPLOAD_REQUIRED" = true ]; then
            echo "=== Uploading new IRPA for llama3-8b-fp8 ==="
            az storage blob upload \
              --account-name sharkpublic \
              --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
              --container-name ossci \
              --name ossci-models/llama_3_1/instruct_8b_fp16-${{ env.date }}.irpa \
              --file /shark-dev/8b/instruct/weights/llama3.1_8b_instruct_fp16.irpa

            az storage blob upload \
              --account-name sharkpublic \
              --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
              --container-name ossci \
              --name ossci-models/llama_3_1/instruct_8b_fp16.irpa \
              --file /shark-dev/8b/instruct/weights/llama3.1_8b_instruct_fp16.irpa \
              --overwrite
          fi

          echo "=== Completed llama-8b-fp16 workflow ==="

      # Llama 8B FP8 irpa export, compile and validate
      - name: Export 8B-FP8 instruct model
        id: export_irpa_llama_8b_fp8
        continue-on-error: true
        run: |
            set -e  # Exit on any error
            MODEL_TAG="llama3_8b_fp8"
            echo $MODEL_TAG
            # Export 8B-FP8 instruct model
            echo "=== Exporting 8B-FP8 instruct model ==="
            bash scripts/download_export_irpa.sh \
              --model Llama-3.1-8B-Instruct-FP8-KV \
              --hf-token ${HF_TOKEN} || { echo "Export failed"; exit 1; }

            # Run export and compile
            echo "=== Running export and compile ==="
            bash scripts/export_and_compile.sh \
              --irpa instruct_8b_fp8_e4m3fn.irpa \
              --dtype fp8 --bs-prefill 4 --bs-decode 4 2>&1 | tee "$(pwd)/output_artifacts/${MODEL_TAG}_export_and_compilation.log" || { echo "Compilation failed"; exit 1; }

            # Validate VMFB Responses
            echo "=== Validating VMFB Responses ==="
            bash scripts/validate_numerics.sh \
              --irpa instruct_8b_fp8_e4m3fn.irpa \
              --vmfb $(pwd)/output_artifacts/output.vmfb \
              --config $(pwd)/output_artifacts/config_attn.json \
              --tokenizer /shark-dev/8b/instruct/tokenizer.json \
              --tokenizer_config /shark-dev/8b/instruct/tokenizer_config.json \
              --steps 64 \
              --kv-cache-dtype float8_e4m3fnuz | tee "$(pwd)/output_artifacts/${MODEL_TAG}_run_llm_vmfb.log" || { echo "Validation failed "; }

            # Check for IRPA changes
            echo "=== Checking for IRPA changes ==="
            echo "Downloading latest IRPA file from Azure"
            az storage blob download \
              --account-name sharkpublic \
              --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
              --container-name ossci \
              --name ossci-models/llama_3_1/instruct_8b_fp8_e4m3fn.irpa \
              --file instruct_8b_fp8_e4m3fn_previous.irpa \
              --no-progress || echo "No previous IRPA file found, will upload new file"

            UPLOAD_REQUIRED=false
            if [ -f instruct_8b_fp8_e4m3fn_previous.irpa ]; then
              echo "Comparing IRPA files"
              if ! diff -q instruct_8b_fp8_e4m3fn.irpa instruct_8b_fp8_e4m3fn_previous.irpa > /dev/null 2>&1; then
                echo "IRPA files differ, upload required"
                UPLOAD_REQUIRED=true
              else
                echo "IRPA files are identical, skipping upload"
              fi
            else
              echo "No previous IRPA file found, upload required"
              UPLOAD_REQUIRED=true
            fi

            # Upload IRPA file if required
            if [ "$UPLOAD_REQUIRED" = true ]; then
              echo "=== Uploading new IRPA for llama3-8b-fp8 ==="
              az storage blob upload \
                --account-name sharkpublic \
                --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
                --container-name ossci \
                --name ossci-models/llama_3_1/instruct_8b_fp8_e4m3fn-${{ env.date }}.irpa \
                --file instruct_8b_fp8_e4m3fn.irpa

              az storage blob upload \
                --account-name sharkpublic \
                --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
                --container-name ossci \
                --name ossci-models/llama_3_1/instruct_8b_fp8_e4m3fn.irpa \
                --file instruct_8b_fp8_e4m3fn.irpa \
                --overwrite
            fi

            echo "=== Completed llama-8b-fp8 workflow ==="

      # Llama 70B FP16 irpa export, compile and validate
      - name: Export 70B-FP16 instruct model
        run: |
          set -e  # Exit on any error
          export MODEL_TAG="llama3_70b_fp16"
          echo $MODEL_TAG
          # Export 70B-FP16 instruct model
          echo "=== Exporting 70B-FP16 instruct model ==="
          bash scripts/download_export_irpa.sh \
                  --model Llama-3.1-70B-Instruct \
                  --hf-token ${HF_TOKEN} || { echo "Export failed"; exit 1; }

          # Run export and compile
          echo "=== Running export and compile ==="
          bash scripts/export_and_compile.sh \
                --irpa  /shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa \
                --bs-prefill 4 --bs-decode 4 2>&1 | tee "$(pwd)/output_artifacts/${MODEL_TAG}_export_and_compilation.log" || { echo "Compilation failed"; exit 1; }

          # Validate VMFB Responses
          echo "=== Validating VMFB Responses ==="
          bash scripts/validate_numerics.sh \
            --irpa /shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa \
            --vmfb $(pwd)/output_artifacts/output.vmfb \
            --config $(pwd)/output_artifacts/config_attn.json \
            --tokenizer /shark-dev/70b/instruct/tokenizer.json \
            --tokenizer_config /shark-dev/70b/instruct/tokenizer_config.json \
            --steps 64 \
            --kv-cache-dtype float16 | tee "$(pwd)/output_artifacts/${MODEL_TAG}_run_llm_vmfb.log" || { echo "Validation failed"; }

          # Check for IRPA changes
          echo "=== Checking for IRPA changes ==="
          echo "Downloading latest IRPA file from Azure"
          az storage blob download \
            --account-name sharkpublic \
            --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
            --container-name ossci \
            --name ossci-models/llama_3_1/70b/instruct_70b_fp16.irpa \
            --file instruct_70b_fp16_previous.irpa \
            --no-progress || echo "No previous IRPA file found, will upload new file"

          UPLOAD_REQUIRED=false
          if [ -f instruct_70b_fp16_previous.irpa ]; then
            echo "Comparing IRPA files"
            if ! diff -q /shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa instruct_70b_fp16_previous.irpa > /dev/null 2>&1; then
              echo "IRPA files differ, upload required"
              UPLOAD_REQUIRED=true
            else
              echo "IRPA files are identical, skipping upload"
            fi
          else
            echo "No previous IRPA file found, upload required"
            UPLOAD_REQUIRED=true
          fi

          # Upload IRPA file if required
          if [ "$UPLOAD_REQUIRED" = true ]; then
            echo "=== Uploading new IRPA for llama3-8b-fp8 ==="
            az storage blob upload \
              --account-name sharkpublic \
              --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
              --container-name ossci \
              --name ossci-models/llama_3_1/70b/instruct_70b_fp16-${{ env.date }}.irpa \
              --file /shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa

            az storage blob upload \
              --account-name sharkpublic \
              --sas-token "$AZURE_WRITE_ACCESS_OSSCI" \
              --container-name ossci \
              --name ossci-models/llama_3_1/70b/instruct_70b_fp16.irpa \
              --file /shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa \
              --overwrite
          fi

          echo "=== Completed llama-70b-fp16 workflow ==="

      # Mistral-Nemo-Instruct-2407-FP8 irpa export
      - name: Export Mistral-Nemo-Instruct-2407-FP8
        run: |
          bash scripts/download_export_irpa.sh \
            --model Mistral-Nemo-Instruct-2407-FP8 \
            --hf-token ${HF_TOKEN}

      - name: Cleanup download Directory
        run: |
          rm -rf Llama-3.1-8B-Instruct Llama-3.1-70B-Instruct Llama-3.1-8B-Instruct-FP8-KV output_artifacts
          rm -f instruct_8b_fp8_e4m3fn.irpa instruct_8b_fp8_e4m3fn_previous.irpa instruct_70b_fp16_previous.irpa instruct_8b_fp16_previous.irpa
          test ! -d Llama-3.1-8B-Instruct  && echo "Llama-3.1-8B-Instruct downloaded artifacts removed"
          test ! -d Llama-3.1-8B-Instruct-FP8-KV  && echo "Llama-3.1-8B-Instruct-FP8-KV downloaded artifacts removed"
          test ! -d Llama-3.1-70B-Instruct  && echo "Llama-3.1-70B-Instruct downloaded artifacts removed"
          test ! -d Mistral-Nemo-Instruct-2407-FP8  && echo "Mistral-Nemo-Instruct-2407-FP8 downloaded artifacts removed"
