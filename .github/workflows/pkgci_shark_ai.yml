# Copyright 2024 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: PkgCI - shark-ai

on:
  workflow_call:
    inputs:
      artifact_run_id:
        type: string
        default: ""
  workflow_dispatch:
    inputs:
      artifact_run_id:
        type: string
        description: "Id for a workflow run that produced dev packages"
        default: ""

jobs:
  test_shortfin_llm_server:
    name: "Integration Tests - Shortfin LLM Server"
    runs-on: ${{ matrix.runs-on }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: cpu
            runs-on: azure-cpubuilder-linux-scale
            test_device: cpu
            python-version: 3.11
          - name: amdgpu_rocm_mi300_gfx942
            runs-on: linux-mi300-1gpu-ossci
            test_device: gfx942
            python-version: 3.11
          # temporarily disable mi250 because the cluster is unsable & slow
          # - name: amdgpu_rocm_mi250_gfx90a
          #   runs-on: nodai-amdgpu-mi250-x86-64
          #   test_device: gfx90a

    defaults:
      run:
        shell: bash
    env:
      PACKAGE_DOWNLOAD_DIR: ${{ github.workspace }}/.packages
      VENV_DIR: ${{ github.workspace }}/.venv
    steps:
      - name: Run rocminfo
        if: contains(matrix.test_device, 'gfx')
        run: rocminfo
      - name: "Checkout Code"
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Set up environment and install PkgCI Artifacts"
        uses: ./.github/actions/pkgci-install
        with:
          python-version: ${{matrix.python-version}}
          artifact-run-id: ${{ inputs.artifact_run_id }}

      - name: Run LLM Smoke Test
        run: |
          source ${VENV_DIR}/bin/activate
          pytest -v -s --test_device=${{ matrix.test_device }} app_tests/integration_tests/llm/shortfin/tinystories_llama2_25m_test.py --log-cli-level=INFO

      - name: Run LLM Integration Tests
        run: |
          source ${VENV_DIR}/bin/activate
          pytest -v -s --test_device=${{ matrix.test_device }} app_tests/integration_tests/llm/shortfin/open_llama_3b_llm_server_test.py --log-cli-level=INFO
