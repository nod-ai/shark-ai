# Copyright 2024 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: CI - sharktank nightly

on:
  workflow_dispatch:
  schedule:
    # Weekdays at 11:00 AM UTC = 03:00 AM PST / 04:00 AM PDT
    - cron: "0 11 * * 1-5"

concurrency:
  # A PR number if a pull request and otherwise the commit hash. This cancels
  # queued and in-progress runs for the same PR (presubmit) or commit
  # (postsubmit). The workflow name is prepended to avoid conflicts between
  # different workflows.
  group: ${{ github.workflow }}-${{ github.event.number || github.sha }}
  cancel-in-progress: true

jobs:
  flux-test:
    if: ${{ github.repository_owner == 'nod-ai' || github.event_name != 'schedule' }}
    name: "Flux evaluation"
    strategy:
      matrix:
        python-version: [3.11]
        runs-on: [linux-mi300-1gpu-ossci-nod-ai]
      fail-fast: false
    runs-on: ${{matrix.runs-on}}
    defaults:
      run:
        shell: bash
    env:
      VENV_DIR: ${{ github.workspace }}/.venv
      HF_HOME: "/shark-cache/data/huggingface"
      HF_TOKEN: ${{ secrets.HF_FLUX_TOKEN }}
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: ${{matrix.python-version}}

      - name: Create Python venv
        run: python -m venv ${VENV_DIR}

      - name: Install sharktank deps
        run: |
          source ${VENV_DIR}/bin/activate
          python -m pip install --no-compile --upgrade pip

          # Note: We install in three steps in order to satisfy requirements
          # from non default locations first.
          pip install --no-compile -r pytorch-cpu-requirements.txt
          pip install -r requirements-iree-unpinned.txt
          pip install --no-compile \
            -r sharktank/requirements-tests.txt \
            -e sharktank/

          pip freeze

      - name: Run tests
      # TODO: unify with-*-data flags into a single flag and make it possible to run
      # only tests that require data.
      # We would still want the separate flags as we may endup with data being
      # scattered on different CI machines.
        run: |
          source ${VENV_DIR}/bin/activate
          pytest \
            -v \
            --log-cli-level=info \
            --with-clip-data \
            --with-flux-data \
            --with-t5-data \
            --with-vae-data \
            --iree-hal-target-device=hip \
            --iree-hip-target=gfx942 \
            --iree-device=hip://0 \
            sharktank/tests \
            --durations=0 \
            -m "expensive" \
            --timeout=800

  llm-test:
    if: ${{ github.repository_owner == 'nod-ai' || github.event_name != 'schedule' }}
    name: "LLM evaluation"
    strategy:
      matrix:
        version: [3.11]
        runs-on: [linux-mi300-1gpu-ossci-nod-ai]
      fail-fast: false
    runs-on: ${{matrix.runs-on}}
    defaults:
      run:
        shell: bash
    env:
      VENV_DIR: ${{ github.workspace }}/.venv
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: ${{matrix.version}}
      - name: Create Python venv
        run: python -m venv ${VENV_DIR}

      - name: Install sharktank deps
        run: |
          source ${VENV_DIR}/bin/activate
          python -m pip install --no-compile --upgrade pip

          # Note: We install in three steps in order to satisfy requirements
          # from non default locations first.
          pip install --no-compile -r pytorch-rocm-requirements.txt
          pip install -r requirements-iree-unpinned.txt
          pip install --no-compile \
            -r sharktank/requirements-tests.txt \
            -e sharktank/

          pip freeze

      - name: Run Perplexity tests
        run: |
          source ${VENV_DIR}/bin/activate
          mkdir perplexity_ci_artifacts
          python -m sharktank.models.deepseek.toy_deepseek -o "perplexity_ci_artifacts/toy_deepseek.irpa"
          python -m sharktank.examples.sharding.shard_llm_dataset --irpa-file=perplexity_ci_artifacts/toy_deepseek.irpa --output-irpa=perplexity_ci_artifacts/toy_deepseek_tp2.irpa --tensor-parallelism-size=2
          pytest \
            -n 8 \
            -v \
            -s \
            sharktank/tests/evaluate/ \
            --run-nightly-test \
            --bs=32 \
            --device='cuda:0' \
            --iree-device=hip://0 \
            --iree-hip-target=gfx942 \
            --iree-hal-target-device=hip \
            --llama3-8b-f16-model-path=/shark-dev/data/llama3.1/weights/8b/fp16/llama3.1_8b_fp16_instruct.irpa \
            --llama3-8b-f16-tp2-model-path=/shark-dev/data/llama3.1/weights/8b/fp16/tp2/llama3.1_8b_instruct_fp16_tp2.irpa \
            --llama3-8b-f8-model-path=/shark-dev/8b/fp8/attnf8/native_fp8_e4m3fnuz_llama3_8b.irpa \
            --llama3-8b-tokenizer-path=/shark-dev/data/llama3.1/weights/8b/fp16/tokenizer_config.json \
            --deepseek-v3-model-path=perplexity_ci_artifacts/toy_deepseek.irpa \
            --deepseek-v3-tp2-model-path=perplexity_ci_artifacts/toy_deepseek_tp2.irpa \
            --html=out/llm/llama/perplexity/index.html \
            --log-cli-level=INFO

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@4f9cc6602d3f66b9c108549d475ec49e8ef4d45e # v4.0.0
        with:
          github_token: ${{ secrets.SHARK_PLATFORM_GH_TOKEN }}
          publish_dir: ./out/llm/llama/perplexity
          destination_dir: ./llm/llama/perplexity
          keep_files: true

  sharded-test:
    if: ${{ github.repository_owner == 'nod-ai' || github.event_name != 'schedule' }}
    name: "Sharded LLM evaluation"
    strategy:
      matrix:
        version: [3.11]
        runs-on: [linux-mi300-8gpu-ossci-nod-ai]
      fail-fast: false
    runs-on: ${{matrix.runs-on}}
    defaults:
      run:
        shell: bash
    env:
      VENV_DIR: ${{ github.workspace }}/.venv
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: "Setting up Python"
        id: setup_python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: ${{matrix.version}}
      - name: Create Python venv
        run: python -m venv ${VENV_DIR}

      - name: Install sharktank deps
        run: |
          source ${VENV_DIR}/bin/activate
          python -m pip install --no-compile --upgrade pip

          # Note: We install in three steps in order to satisfy requirements
          # from non default locations first.
          pip install --no-compile -r pytorch-rocm-requirements.txt
          pip install -r requirements-iree-unpinned.txt
          pip install --no-compile \
            -r sharktank/requirements-tests.txt \
            -e sharktank/

          pip freeze

      - name: Run Perplexity tests
        run: |
          source ${VENV_DIR}/bin/activate
          pytest \
            -v \
            -s \
            sharktank/tests/evaluate/ \
            --run-sharded-test \
            --bs=32 \
            --iree-device=hip://0 \
            --iree-hip-target=gfx942 \
            --iree-hal-target-device=hip \
            --llama3-70b-tokenizer-path=/shark-dev/70b/instruct/tokenizer_config.json \
            --llama3-70b-f16-model-path=/shark-dev/70b/instruct/weights/llama3.1_70b_instruct_fp16.irpa \
            --llama3-405b-tokenizer-path=/shark-dev/405b/tokenizer_config.json \
            --llama3-405b-f16-tp8-model-path=/shark-dev/405b/instruct/weights/tp8/llama3_405b_instruct_fp16_tp8.irpa \
            --html=out/llm/llama/perplexity/sharded/index.html \
            --log-cli-level=INFO

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@4f9cc6602d3f66b9c108549d475ec49e8ef4d45e # v4.0.0
        with:
          github_token: ${{ secrets.SHARK_PLATFORM_GH_TOKEN }}
          publish_dir: ./out/llm/llama/perplexity/sharded
          destination_dir: ./llm/llama/perplexity/sharded
          keep_files: true
